{
  "timestamp": "2025-06-27_11-12-55",
  "active_window": "Cursor",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "from dotenv import load_dotenv\n   load_dotenv()",
  "vscode_text": "import json\nimport time\nimport os\nfrom typing import Dict, Any, List\nimport subprocess\nimport signal\n\n# Import Google Gemini\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\nfrom dotenv import load_dotenv\nload_dotenv()\n\n# Google Gemini API key setup\nimport os\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # Set this externally\n\n# Initialize Google Gemini LLM\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",\n    temperature=0.3,\n    convert_system_message_to_human=True\n)\n\ndef read_latest_user_data() -> Dict[str, Any]:\n    \"\"\"Read the latest user data from live_output.json\"\"\"\n    try:\n        with open(\"output/live_output.json\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return {}\n    except json.JSONDecodeError:\n        return {}\n\ndef read_user_data_file(filename: str) -> Dict[str, Any]:\n    \"\"\"Read a specific user data file\"\"\"\n    try:\n        with open(f\"output/{filename}\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return {}\n    except json.JSONDecodeError:\n        return {}\n\ndef get_all_user_data_files() -> List[str]:\n    \"\"\"Get list of all user data files in output directory\"\"\"\n    try:\n        files = [f for f in os.listdir(\"output\") if f.startswith(\"user_data_\") and f.endswith(\".json\")]\n        return sorted(files)\n    except FileNotFoundError:\n        return []\n\ndef analyze_user_activity_from_json(user_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Analyze user data from JSON to determine what the user is doing\n    Returns JSON format with activity classification\n    \"\"\"\n    if not user_data:\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": \"No user data available\",\n            \"timestamp\": time.time()\n        }\n\n    # Extract relevant information from user data\n    active_window = user_data.get(\"active_window\", \"\")\n    focused_text = user_data.get(\"focused_text\", \"\")\n    clipboard_content = user_data.get(\"clipboard\", \"\")\n    vscode_text = user_data.get(\"vscode_text\", \"\")\n    ocr_text = user_data.get(\"ocr_text\", \"\")\n    timestamp = user_data.get(\"timestamp\", \"\")\n\n    # Combine all text sources for analysis\n    combined_text = f\"\"\"\nActive Window: {active_window}\nFocused Text: {focused_text}\nClipboard: {clipboard_content}\nVS Code Text: {vscode_text}\nScreen OCR: {ocr_text}\n    \"\"\".strip()\n\n    if not combined_text or combined_text.strip() == \"\":\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": \"No meaningful text data available\",\n            \"timestamp\": time.time()\n        }\n\n    system_prompt = \"\"\"You are an AI assistant that analyzes user activity data to determine what the user is currently doing. \n    \n    You have access to multiple data sources:\n    - Active Window: The currently active application\n    - Focused Text: Text from the focused element\n    - Clipboard: Content in the clipboard\n    - VS Code Text: Text from VS Code editor (if available)\n    - Screen OCR: Text extracted from screen capture\n    \n    Analyze this data and classify the user's activity into one of these categories:\n    - coding: Writing, editing, or reviewing code (Python, JavaScript, etc.)\n    - researching: Reading articles, papers, documentation, or searching for information\n    - browsing: General web browsing, social media, or casual internet use\n    - emailing: Composing, reading, or managing emails\n    - messaging: Using chat applications, messaging apps, or communication tools\n    - gaming: Playing video games or game-related activities\n    - watching: Watching videos, streams, or multimedia content\n    - writing: Writing documents, notes, or creative content\n    - designing: Working on design, graphics, or creative projects\n    - working: General work activities not covered by other categories\n    - unknown: Unable to determine the activity\n    \n    Consider the following patterns:\n    - Coding: Look for code syntax, function definitions, imports, IDE elements\n    - Messaging: Look for chat interfaces, message bubbles, contact names\n    - Researching: Look for articles, documentation, search results\n    - Browsing: Look for web browser elements, URLs, navigation\n    \n    Return your response in valid JSON format with these fields:\n    - activity: The classified activity (string)\n    - confidence: Confidence level 0.0-1.0 (float)\n    - description: Brief description of what you observed (string)\n    - details: Additional context or specific tools/applications detected (string)\n    - data_sources: Which data sources were most useful for classification (string)\n    - timestamp: Current timestamp (float)\n    \n    Example response:\n    {\n        \"activity\": \"coding\",\n        \"confidence\": 0.85,\n        \"description\": \"User appears to be writing Python code in Cursor IDE\",\n        \"details\": \"Detected Python imports, function definitions, and Cursor IDE interface\",\n        \"data_sources\": \"VS Code text and active window\",\n        \"timestamp\": 1234567890.123\n    }\n    \n    Only return valid JSON, no additional text.\"\"\"\n\n    human_prompt = f\"Here's the user activity data to analyze:\\n\\n{combined_text}\\n\\nPlease analyze this data and determine what the user is doing.\"\n\n    try:\n        messages = [\n            SystemMessage(content=system_prompt),\n            HumanMessage(content=human_prompt)\n        ]\n        \n        response = llm(messages)\n        response_text = response.content.strip()\n        \n        # Try to parse the JSON response\n        try:\n            result = json.loads(response_text)\n            # Ensure timestamp is current\n            result[\"timestamp\"] = time.time()\n            return result\n        except json.JSONDecodeError:\n            # Fallback if JSON parsing fails\n            return {\n                \"activity\": \"unknown\",\n                \"confidence\": 0.0,\n                \"description\": \"Failed to parse LLM response\",\n                \"details\": response_text,\n                \"data_sources\": \"LLM response parsing failed\",\n                \"timestamp\": time.time()\n            }\n            \n    except Exception as e:\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": f\"Error analyzing user data: {str(e)}\",\n            \"details\": \"\",\n            \"data_sources\": \"Error occurred during analysis\",\n            \"timestamp\": time.time()\n        }\n\ndef analyze_historical_data(num_files: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"Analyze the most recent user data files\"\"\"\n    files = get_all_user_data_files()\n    if not files:\n        return []\n    \n    # Get the most recent files\n    recent_files = files[-num_files:] if len(files) > num_files else files\n    results = []\n    \n    for filename in recent_files:\n        user_data = read_user_data_file(filename)\n        if user_data:\n            analysis = analyze_user_activity_from_json(user_data)\n            analysis[\"source_file\"] = filename\n            results.append(analysis)\n    \n    return results\n\ndef main():\n    \"\"\"Main function to continuously monitor and analyze user activity\"\"\"\n    print(\"\ud83d\udd0d User Activity Monitor Started\")\n    print(\"Using Google Gemini LLM for activity analysis\")\n    print(\"Analyzing data from gatheruserdata.py JSON files\")\n    print(\"Press Ctrl+C to stop\\n\")\n\n    # Start gatheruserdata.py as a subprocess\n    gather_proc = subprocess.Popen([\n        \"python\", \"gatheruserdata.py\"\n    ])\n    print(\"\ud83d\ude80 Started gatheruserdata.py in the background (PID: {}), collecting user data...\".format(gather_proc.pid))\n\n    try:\n        last_timestamp = None\n        while True:\n            print(\"\ud83d\udcca Reading latest user data...\")\n            user_data = read_latest_user_data()\n\n            # Only analyze if new data is available\n            if user_data and user_data.get(\"timestamp\") != last_timestamp:\n                last_timestamp = user_data.get(\"timestamp\")\n                print(\"\ud83e\udd16 Analyzing user activity from JSON data...\")\n                result = analyze_user_activity_from_json(user_data)\n                # Pretty print the JSON result\n                print(\"\ud83d\udcca Activity Analysis:\")\n                print(json.dumps(result, indent=2))\n                print(\"=\" * 60)\n            else:\n                print(\"\u23f3 Waiting for new user data...\")\n\n            # Wait before next check\n            time.sleep(5)\n\n    except KeyboardInterrupt:\n        print(\"\\n\ud83d\udc4b Activity monitor stopped by user\")\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n    finally:\n        print(\"\ud83d\uded1 Terminating gatheruserdata.py subprocess...\")\n        gather_proc.terminate()\n        try:\n            gather_proc.wait(timeout=5)\n        except subprocess.TimeoutExpired:\n            gather_proc.kill()\n        print(\"\u2705 gatheruserdata.py stopped.\")\n\ndef analyze_single_file(filename: str):\n    \"\"\"Analyze a specific user data file\"\"\"\n    print(f\"\ud83d\udd0d Analyzing file: {filename}\")\n    user_data = read_user_data_file(filename)\n    \n    if user_data:\n        result = analyze_user_activity_from_json(user_data)\n        print(\"\ud83d\udcca Activity Analysis:\")\n        print(json.dumps(result, indent=2))\n    else:\n        print(f\"\u274c Could not read file: {filename}\")\n\ndef analyze_recent_files(num_files: int = 5):\n    \"\"\"Analyze the most recent user data files\"\"\"\n    print(f\"\ud83d\udd0d Analyzing {num_files} most recent files...\")\n    results = analyze_historical_data(num_files)\n    \n    for result in results:\n        print(f\"\\n\ud83d\udcc1 File: {result.get('source_file', 'Unknown')}\")\n        print(f\"\ud83c\udfaf Activity: {result.get('activity', 'Unknown')}\")\n        print(f\"\ud83d\udcc8 Confidence: {result.get('confidence', 0.0):.2f}\")\n        print(f\"\ud83d\udcdd Description: {result.get('description', 'No description')}\")\n        print(\"-\" * 40)\n\nif __name__ == \"__main__\":\n    import sys\n    \n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"--file\" and len(sys.argv) > 2:\n            analyze_single_file(sys.argv[2])\n        elif sys.argv[1] == \"--recent\" and len(sys.argv) > 2:\n            analyze_recent_files(int(sys.argv[2]))\n        elif sys.argv[1] == \"--recent\":\n            analyze_recent_files()\n        else:\n            print(\"Usage:\")\n            print(\"  python activity_analyzer.py                    # Monitor live data\")\n            print(\"  python activity_analyzer.py --file <filename>  # Analyze specific file\")\n            print(\"  python activity_analyzer.py --recent [num]     # Analyze recent files\")\n    else:\n        main()",
  "ocr_text": "ee > | 2 text-extractor Cod &\n\nO 9 Pp v 2 {} user_data_2025-06-2711-10-59.json X @\u00ae Fo] a\noutput > {} user_data_2025-06-27 11-10-59.json > vscode_text\nV O rs) V V Vzer 2) STiaMme\n> __pycache__ P - . .\nee recent files\\\")\\n else:\\n main()\",\n> SHAMS \"ocr_text\": \"&\\n\\nChats G \\u@@a9 Gy Arun Kapoor\\n\\nQ Ask Meta Al or Search\\n\\nArun Kapoor: On this work two coating... <\\n\\n& Jayant A Msaaadt AM 13/06/\n\\ output 25\\n\\nMyself and my Babu 10:07 AM\\nArun Kapoor: @ Photo <\\n\\nJayant Kapoor Airtel (You) Wednesday\\nW +919310762323 a\\n\\nBhuvan Arora BITS 10:52 AM\\nclipboard =\n{} live_output.json textbox text vaherha\\n\\nBITSBuddies'25 10:43 AM\\n~DNA: Greetings of the day! The Google...\\n\\nArun Kapoor 10:34 AM (\\u@@a5\\n& Voice call\\nPaytm 10:24 AM\\n\\n@\n\nImportant Update: Your credit score h...\\n\\nHPC 23-24 10:13AM\\nGovind Bhageria HPC BITS: Guys updat...\\n\\n0e 86d!\\n\\nShiprocket 10:03 AM\\nfies Dear Hi\u20149313093406\nSeller, \\n\\nBranchWise'24 8:17 AM\\nSajal BITS: Let's show our love and supp...\\n\\nBPPC: Batch Of '24 8:17 AM\\nSajal BITS: Let's show our love and supp...\n\\n\\nJayant Yadav 5:@1AM\\nW Sorry bhai so raha tha\\n\\n2023 Batch 10:54AM\\n~Samarth joined using this group's invit...\\n\\nGPT 4|| Linkedin Rollout -Bits...\n\nla screenshot_2025-...\nla screenshot_2025-...\n\nlai screenshot_2026-... Yesterday\\nAdhik: @ GOOGLE 100 GB STORAGE - ...\\n\\n> P\\u@@aeA66@\\n\\nCulinary Club 2024 Yesterday\\n\\n3\\n\\n3\\n\\nYes. \\n\\n3\\n\\n3\\n\\n3\\n\\n+\\n\\nMissed voice\n\nI] screenshot_2025-... call\\n\\nClick to call back\\n\\n4:38PM\\nMissed voice call\\nClick to call back\\n\\n5:11PM\\n\\n10:@6 AM\\n\\nMissed voice call\\nClick to call back\\n\\n10:0@7 AM\\nMissed\n\ni) screenshot_2025-... voice call\\nClick to call back\\n\\n10:08 AM\\nVoice call\\nAnswered on other device\\n\\n10:34 AM\\n\\nToday\\n\\n55DUE77\\n\\nSPARE PART NAME\\n\\nClaim aaya car ka? r\nlx screenshot_2025-... \\n\\nKitne paise?\\n\\n10:@6AM 4\\n\\n10:06AM 4\" .\nla screenshot_2025-... ,\n\n{} user_data_2025-0... .\n{} user_data_2025-0...\n\n{} user_data_2025-0...\n\n{} user_data_2025-0...\n\n{} user_data_2025-0...\n\n{} user_data_2025-0...\n\n{} user_data_2025-0...\n\n> text Problems Output DebugConsole Terminal Ports Python +v ({] WW A x\nEa @ along with an AI agent assisting.\\\",\\n \\\"data_sources\\\": \\\"Active Window, Clipboard, VS Code Text, Screen OCR\\\",\\n \\\"timestamp\\\": 1751002673.881529\\n}\\n\u00b0**\", .\n@ activity_analyzer.py \"data_sources\": \"LLM response parsing failed\",\n\n\"timestamp\": 1751002691.902564\n\n@ gatheruserdata.py\n\n= requirements.txt = ;\nIl Reading latest user data...\n\n% Waiting for new user data...\n\nfl Reading latest user data...\n\n% Waiting for new user data...\n\n\u201cZ\n\nzsh: suspended /Users/jayantkapoor/Desktop/text-extractor/.venv/bin/python\n\u00a9 (.venv) jayantkapoor@Jayants-MacBook-Pro text-extractor % /Users/jayantkapoor/Desktop/text\u2014extractor/.venv/bi\n\nn/python /Users/jayantkapoor/Desktop/text-extractor/activity_analyzer.py\n\n\u00ae. User Activity Monitor Started\n\nUsing Google Gemini LLM for activity analysis\n\nAnalyzing data from gatheruserdata.py JSON files\n\nPress Ctrl+C to stop\n\n# Started gatheruserdata.py in the background (PID: 94935), collecting user data...\nfl Reading latest user data...\n\n% Waiting for new user data...\n\nIl Reading latest user data...\n\nAnalyzing user activity from JSON data...\n\n3K to generate a command\n\n@\u00aeoAo0 Wo Cursor Tab @ Ln6,Col8645 Spaces:2 UTF-8 LF {} JSON QQ"
}