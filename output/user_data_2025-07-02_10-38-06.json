{
  "timestamp": "2025-07-02_10-38-06",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ Code File Edit Selection View Go Run Terminal Window Help 6 \u00a38 \u00a9 GD O S wt F Q S \u00a9 Wed Jul2 10:38AM\n\n= List of research @ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence [| Al-05-BBLEN4 \u00a9 Openal coy API keys - Open/ [G) Gemini API refer: +\u201d Get API key | G X\no<erca O @& 2 aistudio.google.com/apikey Intelligent Excuse Generator Plan > y=\nBhuvan\nv Oo . : - . . 7\nSy) eee \u00a9 > P excuse-generator 8 0 (No duplicate genai. configure lines elsewhere in the file.)\n2) | o EXPLORER J Welcome \u00ae excuse_api.py 4,U X %.env U Dy\n\\ EXCUSE-GENERATOR \u00ae excuse_api.py > \u00a9 generate | Save the file (38S / Ctrl S).\n\u00a9 P| > \u2014pyeache_ 37. # ---------- /generate ---------- '\nv venv\nu iT} \u2014\neo 38 @app.post(\"/generate\")\n> include PROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS. tye A xX\nhi SS SCT 5 Restart FastAPI\n& \u00a9 pyvenv.cfg U sync Seis\nPa 7 return await get_async_backend().run_sync_in_worker_thread( >.) zsh\n.env AAAAAAAAA AAA AAAAAAAAAAAAAAAAARAAAAAAAAAAAAAAAAAAAAAA 1: bash oO Copy\n=5 \u00ae excuse_api.py 4,U File \"/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 245\n. 7 7@, in run_sync_in_worker_thread\n{} history.json U return await future a q\nA = requirements.txt U A0DDLAAALL AAS uvicorn excuse_api:app --reload\n: File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 96\n7, in run\nresult = context.run(func, *args) i. You should see:\nFile \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 42, in generate 2 .\nout = json. loads(model.generate_content(full_prompt) . text) INFO: Uvicorn running on http ://127.0.0.1:8000\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/generativeai/generative_models \u00ae\n-py\", line 331, in generate_content\nresponse = self._client.generate_content(\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/ai/generat ive language_vibeta/s .\nervices/generative_service/client.py\", line 835, in generate_content 6 Smoke-test from another terminal tab\nresponse = rpc( 1\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method. py\",\nline 131, in __call_ bash O) Copy\n\nreturn wrapped_func(xargs, **kwargs)\n\nrite Se EES ASIC REIS ASABE IONS EE STIRS ATARI LAL curl -X POST http : //127 .0.0. 1:8000/generate \\\n\" \u201creturn retry_target( -H \"Content-Type: application/json\" \\\n\n\u2014 1 u\" + nell 7 u u nell + u\" 1\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\", d { scenario\":\"missed class gr Wlbste leita y 5 [keine }\n\n, line 156, in retry_target\nnext_sleep = _retry_error_helper(\n\nExpected outcomes\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\", \u00bb\"\nline 214, in _retry_error_helper\nraise final_exc from source_exc\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\"\n, line 147, in retry_target If you get... It means... What tc\nresult = target()\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/timeout.py\", line 130, 5 A _ a\na ily lume. ately STI JSON response with excuse, Success \u2014 you're done V7) Go to st\nTEND GME STS, LCE) believability_score, chat_log |\n@ File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py\", lin v\ne 78, in error_remapped_callable\nraise exceptions. from_grpc_error(exc) from exc 29 tae lad vi hit the f limit (~BO Imin 1000\n> OUTLINE google.api_core.exceptions.NotFound: 404 models/gemini-pro is not found for API version vibeta, or is not supported\n$03 for generateContent. Call ListModels to see the list of available models and their supported methods. A\n> TIMELINE 0 \u00a9 excuse_api.py x\n\nGE & maine @0A4\n\nLn 42, Col63 Space:\n\nUTF-8 LF {} Python 8 3.13.264-bit\n\nQ\n= : _\u2014 Message Bhuvan\n\nB file.pdf ITRV (1).pdf ITRV.pdf JETIR2101184 Iko to mtj Iko to MTJ (1).pdf = Iko to MTJ-s.-=. were rere\n\nS80veee20\n\n\u00a9\n\n{ | f \u00a2\nSe : \u00a9)\n/ ~~\n. . . ."
}