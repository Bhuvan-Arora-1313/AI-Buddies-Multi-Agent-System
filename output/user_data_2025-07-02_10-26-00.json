{
  "timestamp": "2025-07-02_10-26-00",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "pip show google-generativeai",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"gemini-pro\")\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\n{prompt}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "\u00e9\n\nCode File Edit Selection\n\nView Go\n\nRun Terminal Window Help 6 \u20ac8 \u00a9OGD O 8 2h F\n\nQ S \u00a9 Wed Jul 2 10:26AM\n\no\nS\n\n\u00a9\n\n= List of research 5\n\n\u20ac > CG @\nee@\n\n| oO EXPLORER\n\n\\Y EXCUSE-GENERATOR\n\nP > __pycache__\n\nv venv\npa > bin\n\n> include\nS > lib\n& \u00a9 pyvenv.cfg\nBR  .env\n\n@ excuse_api.py\n{} history.json\n= requirements.txt\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nUE & mains @ @0A4\n\n4\n\nU\nU\nU\nU\nU\n\n@ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence [| Al-05-BBLEN4 \u00a9 Openal coy API keys - Open/ (S) Gemini API refer\n\nO @& = aistudio.google.com/apikey\n\n<> \u00a3 excuse-generator By 08 Oo la\n\nx Welcome @ excuse_api.py 4,U X % .env U Dy %\n\n96 Get API key | G X\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\npip show google-generativeai should now say 0.3.x (or newer).\n\n\u00ae excuse_api.py > \u00a9 generate\n\n1 # excuse_api.py\n2 import os, json, time, hashlib 2 Use the canonical model name\n3 from pathlib import Path\n4 from dotenv import load_dotenv With the new SDK (>= 0.3) simply use:\n5 load_dotenv() # \u2014 NEW: pulls OPENAI_API_KEY from .env\n6 from fastapi import FastAPI python\n7 from pydantic import BaseModel\n8 ecceeeneanaes model = genai.GenerativeModel(\"gemini-pro\" )\n\u00b0 import poco ead lenabear as genat \u2014 If you must stay on the old SDK (not recommended), prepend models/:\n1@ genai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\n11 model = genai.GenerativeModel(\"gemini-pro\") python\n12 # ---------- simple \u201cDB\u201d -\u2014---------\n13 DATA = Path(\"history. json\") model = genai.GenerativeModel(\"models/gemini-pro\")\n14 if not DATA.exists():\n15 DATA.write_text(\"[]\") # seed empty list\n16\n17 Updated top-of-file snippet\n18\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS. tye A xX python\ngenerativeai) (2.33.2) na) PJzsh\nRequirenent already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic->goog 5) 76h hzon GeceaM Cmaeae TleatLcotcae, (fad cecca\nDownloading google_generativeai-@.8.5-py3-none-any.whl (155 kB) 7 load_dotenv(find_dotenv( \u00bb) 1 override=True)\n\nInstalling collected packages: google-generativeai\n\nSuccessfully installed google-generativeai-0.8.5\n\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % pip show google-generativeai\nName: google-generativeai.\nVersion:\n\nimport google.generativeai as genai\n\n0.8.5 I\" genai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\n\nSummary: Google Generative AI High level API client library and tools.\n\nHome-page: https://github.com/google/generative-ai-python 3 9 oer)\n\nAuthor: Google LLC [ model = genai.GenerativeModel(\"gemini-pro\" )\nAuthor-email: googleapis\u2014packages@google. com\n\nLicense: Apache 2.0\n\nLocation:\nRequires:\n\n/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages\ngoogle-ai-generativelanguage, google-api-core, google-api-python-client, google-auth, protobuf, pydantic,\n\ntqdm, typing-extensions v\nRequired-by: '\n\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % | |\n\nt\nQ Ln 39, Col 63 Seco UTF-8 LF {} Python & 3.13.264-bit (&\n\nMessage Bhuvan\n+ \u00ae &\n\nfile.pdf ITRV (1).pdf ITRV.pdf AIEUTIR EAI EY Iko to mtj Iko to MTJ (1).pdf = Iko to MTJ-s. were weer ee\n\nS80\u00b0G8880 eee 7a ae\n\n\u00a9) Copy\n\n\u00a9) Copy\n\n\u00a9) Copy"
}