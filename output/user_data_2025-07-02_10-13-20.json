{
  "timestamp": "2025-07-02_10-13-20",
  "active_window": "ChatGPT",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"missed class\", \"urgency\":\"panic\"}'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ = ChatGPT File Edit View Window Help 6 \u20ac8 \u00a9GD O 8S wD F Q S \u00a9 Wed Jul2 10:13AM\n= List of research pape X * Artificial Intelligence X CO NLP_1.ipynb - Colab X CO NLP_1.ipynb - Colab X ca LAUNCHED Global X \u2122@ Launched - Artificial X Artificial_Intelligence_Ce X (i al-05-BBLEN4 x \u00a9 Opendl x So API keys - OpenAl A! X\nO<\u00abv7 Ce \u00a9 @G = platform.openai.com/settings/organization/api-keys eee OG Intelligent Excuse Generator Plan > CS y=\n\u2014\u2014\u2014\u2014_ \u2014\u2014\u2014\u2014_ Bhuvan\n<> P excuse-generator By BOWL . .\nKS) O \u00b0 2. Upload your excuse_api.py and .env (minus secrets).\no | o EXPLORER J Welcome \u00ae excuse_api.py 4,U X %.env U Dy\nwl \\ EXCUSE-GENERATOR @ excuse_api.py > ... 3. Start ngrok and FastAPI:\n\u00a9) SET > \u2014pycache_ 1 # excuse_api.py =\nv venv . . . . =\n> ot 2 import os, json, time, hashlib prensa O) Copy\nes > include 3 from pathlib import Path Sen preeeels nees\u00ae wees, eau!\nle) i . '\n\u00a9 2 ovenveta u 4 from dotenv import load_dotenv conf.get_default().region = \"in\"\nony u 5 load_dotenv() # <\u2014 NEW: pulls OPENAI_API_KEY from .env pee tCTbubli Se ee ee \"http\")\n- a 4 rint ublic 3 ublic_ur\nA ES @ excuse_apipy 4,U 6 from fastapi import FastAPI P VP 7\nA 0 ee ne ; 7 from pydantic import BaseModel\n= requirements.tx' PEER RRREDAREDASA . <\n5 import subprocess, os, time\n8 from openai import OpenAI ~ : ' Nie . o -, non \" o4\nwee . server = subprocess.Popen([\"uvicorn\", \"\u201cexcuse_api:app\", host\", \"0.0.0.\n9 # \u2014---\u2014---\u2014\u2014 OpenAI client -\u2014-------\u2014\u2014 time.sleep(2)\n= = LLL\n1@ client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\") )\n11\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS tye A Xx .\nOO 4. Hit public_url + \"/generate\" from curl or Postman.\nsync P >.) python3.11\nreturn await get_async_backend().run_sync_in_worker_thread( , BJzsh\nAAA AAAAARAAAAAAAAAAAAAAAAAAAAAAAAARARAAAAAAARARAAAAA 1\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1ib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 24 Drawbacks\n70, in run_sync_in_worker_thread\nreturn await future\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 96 + Notebook dies > URL dies.\n7, in run\nDEST? & GTS SE) - Any file you write (history. json) is wiped when the VM restarts.\nP File \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 38, in generate\n= client.chat. letions. te ( . A . + os\na oS + Exposing secrets in notebook environments is risky.\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 287, i\nn wrapper\nreturn func(*args, +kkwargs) b\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/com\npletions.py\", line 1087, in create .\nreturn self._post( A pragmatic workflow most capstone teams use\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1249, i\nn post a 3 3 aaa 3\nreturn cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls) ) 1 1. Keep coding in VS Code locally (easier debugging, Git integration).\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARAAAA 1\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nWE & maine @0A4\n\nt\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1037, i\n\nn request\n\nraise self._make_status_error_from_response(err.response) from None\n\nopenai.RateLimitError: Error code: 429 - {'error': {'message': \u2018You exceeded your current quota, please check your p\nlan and billing details. For more information on this error, read the docs: https://platform. openai.com/docs/guides/\nerror-codes/api-errors.', \u2018type': \u2018insufficient_quota', \u2018param': None, \u2018code': \u2018insufficient_quota'}}\nQ  Ln10,Col53 Spaces:4 UTF-8 LF\n\n() Python @ 3.13.264-bit 0)\n\n2. Use a Gemini key (free) so you can test wit | \u2018t worrying about cost.\n\n\u20ac Work with Code Tab x\n\nMessage Bhuvan\n\n+ @\u00ae ov\n\n=]\n\n920068629 80920 Af"
}