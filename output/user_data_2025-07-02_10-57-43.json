{
  "timestamp": "2025-07-02_10-57-43",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "source .venv/bin/activate\npip install --upgrade langchain_google_genai langchain-core",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# --- Gemini via LangChain (REST v1) ---\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\n# expose key for LangChain wrapper\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # must be in .env\n\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",          # free\u2011tier model\n    temperature=0.8,\n    convert_system_message_to_human=True\n)\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    messages = [\n        SystemMessage(content=SYSTEM_PROMPT),\n        HumanMessage(content=full_prompt)\n    ]\n    response_text = llm(messages).content.strip()\n    # LangChain may wrap JSON in ``` blocks \u2013 strip them\n    if response_text.startswith(\"```\"):\n        response_text = response_text.strip(\"`\").lstrip(\"json\").strip()\n    out = json.loads(response_text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ Code File Edit Selection\n\nView Go Run\n\nTerminal Window\u2019 Help\n\n6 8 \u00a9D S 323%G&) FF Q S \u00a9 Wed Jul2 10:57AM\n\n= List of research\n\n\u20ac > C\n\n@ O\n\nGoogle Al Studio\n\n@ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence\n\nee eee eT oe\n\nO G = aistue-\n\n| \\Y EXCUSE-GENERATOR\n\nP > __pycache__\n\nVv env\n> bin\n\n\u00a9\n\nEXPLORER\n\nne > include\n> lib\ng \u00a9 pyvenv.cfg U\n .env\nBS @ excuse_api.py 5,U\n{} history.json U\nA = requirements.txt U\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\n& maint @ @O0AS\nView status\n\nria | PyCharm Q_ Search projects New |\n\u20ac- > PP excuse-generator By ic oe\nx Welcome @ excuse_api.py 5,U X % .env U Py 8\n\n\u00ae excuse_api.py > \u00a9 generate\n\n49 def generate(r: Req):\n\n58 if response_text.startswith(\"***\"):\n59 response_text = response_text.strip(\"\").lstrip(\"json\").strip|\n60 out = json. loads(response_text) -\n61 entry = { |\n62 \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n\nPROBLEMS e OUTPUT DEBUG CONSOLE EGTA, PORTS + vrs A XK\n\nreturn wrapped_func(xargs, **kwargs) pena\n\nAAAAAAARAAAAAAAAAAAAAAAAAAAAA, >| zsh W\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\"\n, line 294, in retry_wrapped_func .\nreturn retry-target(\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\" =\n, line 156, in retry_target\nnext_sleep = _retry_error_helper(\n\nt\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1ib/python3.11/site-packages/google/api_core/retry/retry_base. py\",\nline 214, in _retry_error_helper i.\nraise final_exc from source_exc =)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\"\n, line 147, in retry_target\nresult = target()\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/timeout.py\", line 130!\n, in func_with_timeout \"\nreturn func(*args, +kkwargs)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py\", lin\ne 78, in error_remapped_callable\nraise exceptions. from_grpc_error(exc) from exc\ngoogle.api_core.exceptions.NotFound: 404 models/gemini-pro is not found for API version vibeta, or is not supported\nfor generateContent. Call ListModels to see the list of available models and their supported methods.\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\\n-H \"Content-Type: application/json\" \\\n-d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}'\nInternal Server Errorg\n@ (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\\n-H \"Content-Type: application/json\" \\\n-d '{\"scenari missed class\",\"urgency\":\nInternal Server Errorg\n@ (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\\n-H \"Content-Type: application/json\" \\\n-d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}'\n\npanic\"\n\nInternal Server Errorg b\n@ (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\\n-H \"Content-Type: application/json\" \\ .\n\n-d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}'\nInternal Server Errorg\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % o\n\nQ_Ln61,Col14 Spaces:4 UTF-8 LF {} Python & 3.13.264-bit O\n\na |\n\nLT omy Tt Tie eseon |\n\n[| Al-05-BBLEN4 \u00a9 OpenAl coy API keys - Open/ (S) Gemini API refere +\u201d Get API key | GX\nIntelligent Excuse Generator Plan > \u2014\nBhuvan\n\n= out = json.loads(model.generate_content([full_promp+?. +ov+)\nReview \u00a7 Revert\n\n52 messages = [\n\n53 SystemMessage(content=SYSTEM_PROMPT) ,\n\n54 HumanMessage(content=full_prompt)\n\n55 ]\n\n56 response_text = 1lm(messages).content.strip()\n\n57\n\n58 if response_text.startswith(\"***\"):\n\n59 response_text =\nresponse_text.strip(\"\"\").1strip(\"json\").strip()\n\n60 out = json.loads(response_text)\n\n61 entry = {\n\n62 \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n\nAll set! The FastAPI service now uses the LangChain Gemini wrapper (same approach as your\nactivity-analyzer script).\n\n1. Restart the server:\n\nbash O) Copy\nCtr1-C\nuvicorn excuse_api:app --reload\n2. Test:\nbash O) Copy\n\ncurl -X POST http://127.0.0.1:8000/generate \\\n-H \"Content-Type: application/json\" \\\n-d '{\"scenario\":\"missed class\", \"urgency\":\"panic\"}'\n\nYou should finally receive a JSON excuse. v\n\n\u00a9 excuse_api.py x\nMessage Bhuvan\n+ \u00ae &"
}