{
  "timestamp": "2025-07-02_10-42-42",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "python - <<'PY'\nimport os, google.generativeai as genai, dotenv, json\ndotenv.load_dotenv('.env', override=True)\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nm = genai.GenerativeModel(\"models/gemini-pro\")\nprint(json.loads(m.generate_content(\"Respond with JSON: {\\\"hello\\\":\\\"world\\\"}\").text))\nPY",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\nprint(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ Code File Edit Selection View Go Run Terminal Window Help 6 \u20ac8 OGD O S wt F Q S \u00a9 Wed Jul2 10:42AM\n= List of research @ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence [| Al-05-BBLEN4 \u00a9 OpenAl coy API keys - Open/ (S) Gemini API refer +\u201d Get API key | GX\nO<\u00abvr cea O 8 & aistudio.google.com/apikey Intelligent Excuse Generator Plan > \u2014\nBhuvan\n6 0e@8@ <> PP excuse-generator By ic oe -\na | a EXPLORER J Welcome @ excuse_api.py 4,U @ env U Dy bash \u00a9 Copy .\n= Vv EXCUSE-GENERATOR @ excuse_api.py > ...\n) P > __pycache__ 7\nY SEY 8 pkill -f \"uvicorn.xexcuse_api\" 2>/dev/null\n> bin\nC > include 9 from fastapi import FastAPI source .venv/bin/activate\nPl 2 ver 10 from pydantic import BaseModel uvicorn excuse_api:app \u2014\u2014reload\npyvenv.cfg U ILL\n .env U 1 Q A . .\nES @ excuse_apipy 4, 12 import google.generativeai as genai Watch for the temporary >>> model being used: line; confirm it shows\nA 0 ee ne ; 13 genai.configure(api_key=os.getenv(\"GEMINI_KEY\") ) models/gemini-pro.\n= requirements.tx' . . . .\n14 model = genai.GenerativeModel(\"models/gemini-pro\")\n15 print(\"'>>> model being used:\", model._name)\n7 a\u201c nu\n16 # simple \u201cDB 4 \u2014 Quick direct test (bypasses FastAP1)\n17 DATA = Path(\"history. json\")\n18 if not DATA.exists(): . . .\n. ram . With the server running in one terminal, open a second:\n19 DATA.write_text(\"[]\") # seed empty list\n20 bash O) Copy\n21\n~~ python \u2014- <<'PyY'\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS. tv A xX \u00e9 q : : :\n\u2014_\u2014 import os, google.generativeai as genai, dotenv, json\nentemel pene Error k 1 b \"BJ python3.11 dotenv.load_dotenv('.env', override=True)\ne BI \u2014MacBook-P = -X POST 1//127.0.0.1:8000 7 7 + =\nee Pc ae oo aay ISRERED \\ j | Glzsh genai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\na ee ieee class\",\"urgency\":\"panic\"}' L = genai.GenerativeModel(\"models/gemini-pro\" )\nInternal Server Errorg . . . . .\n\u00a9 bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\ print (j son.loads(m. generate_content ( \"Respond with JSON: {\\\"hello\\\":\\\"worl\n-H \"Content-Type: application/json\" \\ I PY\n-d '{\"scenario\":\"missed class\", \"\u201curgency\":\"panic\"}'\nInternal Server Errorg I\n@ bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\ .\n-H \"Content-Type: application/json\" \\ If that succeeds, the model + key are fine; the problem was the wrong name\n-d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}' I : .\nInternal Server Errorg being used in FastAPI.\n\u00ae bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % python - <<'PY' |\nimport os, google.generativeai as genai, dotenv, json\ndotenv. load_dotenv('.env', override=True) |\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\nm = genai.GenerativeModel(\"models/gemini-pro\") I\n\n@\n\nprint (json. loads(m.generate_content(\"Respond with JSON: {\\\"hello\\\":\\\"world\\\"}\"). text) )\nPY\nTraceback (most recent call last):\n\n> OUTLINE File \"<stdin>\", line 1, in <module>\n$03 ModuleNotFoundError: No module named \u2018google\u2019\n> TIMELINE bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % ff\n\nUE & maine @ @0A4 Q\n\nfile.pdf\n\nITRV (1).pdf ITRV.pdf AIEUTIR EAI EY\n\nLn15,Col45 Spaces:4 UTF-8 LF\n\nIko to mtj\n\n() Python @ 3.13.264-bit\n\nIko to MTJ (1).pdf = Iko to MTJ-s.\n\nb\n5 \u2014 Remove the temporary print, freez<, commit\n\n\u00a9 excuse_api.py x\n\nMessage Bhuvan\n\n+ @ &\n\nS80\u00b0G8880 eee 7a ae"
}