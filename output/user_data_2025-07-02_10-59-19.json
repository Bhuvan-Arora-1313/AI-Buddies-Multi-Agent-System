{
  "timestamp": "2025-07-02_10-59-19",
  "active_window": "ChatGPT",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "(.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % uvicorn excuse_api:app --reload \nINFO:     Will watch for changes in these directories: ['/Users/bhuvanarora/excuse-generator']\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [5920] using StatReload\nProcess SpawnProcess-1:\nTraceback (most recent call last):\n  File \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/_subprocess.py\", line 80, in subprocess_started\n    target(sockets=sockets)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 67, in run\n    return asyncio.run(self.serve(sockets=sockets))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/runners.py\", line 190, in run\n    return runner.run(main)\n           ^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 71, in serve\n    await self._serve(sockets)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 78, in _serve\n    config.load()\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/config.py\", line 436, in load\n    self.loaded_app = import_from_string(self.app)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/importer.py\", line 22, in import_from_string\n    raise exc from None\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/importer.py\", line 19, in import_from_string\n    module = importlib.import_module(module_str)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 14, in <module>\n    from langchain.schema import SystemMessage, HumanMessage\nModuleNotFoundError: No module named 'langchain'\n",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# --- Gemini via LangChain (REST v1) ---\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\n# expose key for LangChain wrapper\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # must be in .env\n\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",          # free\u2011tier model\n    temperature=0.8,\n    convert_system_message_to_human=True\n)\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    messages = [\n        SystemMessage(content=SYSTEM_PROMPT),\n        HumanMessage(content=full_prompt)\n    ]\n    response_text = llm(messages).content.strip()\n    # LangChain may wrap JSON in ``` blocks \u2013 strip them\n    if response_text.startswith(\"```\"):\n        response_text = response_text.strip(\"`\").lstrip(\"json\").strip()\n    out = json.loads(response_text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ ChatGPT File Edit View Window\u2019 Help 6 8 \u00a9 DB S w2%G) F Q S \u00a9 Wed Jul2 10:59AM\n\n= List of research @ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence | Al-05-BBLEN4 \u00a9 Openal o API keys - Open/ (S) Gemini API refer * Get API key | GX\na 6 =\n<- 79 32 aistu~ ~a Intelligent Excuse Generator Plan > yy =\nC a 06% eco \u00a9 G Mntellig (\n\noO\niS) .\nGoogle Al Studio \u00abel PyCharm Qs t New! Bo\n\n2 PAV ATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATATAS\n<> P excuse-generator By oO Ww AARARARAAR\n\u00a9) a\n| \u2018a EXPLORER + x) Welcome \u00ae excuse_api.py 5,U X %.env U Dy oe File \"<frozen importlib._bootstrap>\", line 1204, in\nV EXCUSE-GENERATOR \u00ae excuse_api.py > \u00a9 generate _gcd_import\n{> \u2014Pycache_ 49 def generate(r: Req): :\n\nShow full message\n\nVV venv\n\n5 oh 58 if response_text.startswith(\"*>~\" 3\nne > include 59 response_text = response_text.strip(\"*\").Ustrip(\"json\").strip(\u2014\nP| 2\u201d 60 out = json. loads(response_text) Ulta negli alr Giesesehie\n. Pyvenv.ctg . 61 entry = { The crash is simply because the LangChain packages aren't installed in this virtual-env yet.\nenv\nie Ocomamin 50 62 \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\nWw historyson v PROBLEMS e OUTPUT DEBUG CONSOLE TERMINAL PORTS A 1 Install the missing packages (inside the venv)\nA = requirements.txt U \u2014_\u2014\u2014\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 67, in run\nreturn asyncio. run(self.serve(sockets=sockets) ) bash O Copy\n\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/runners.py\", line 190, in run\nreturn runner. run(main) . 2\nANAS ET A source .venv/bin/activate\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/runners.py\", line 118, in run\nreturn self._loop. run_until_complete(task)\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/1lib/python3.11/asyncio/base_events.py\", line 654, in run_until_co#\"\nmplete\nt future. Ut \u00b0 . . .\nTERED (AIRS TESA) (langchain pulls in langchain-core; the Google wrapper depends on it.)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 71, in serve\nawait self._serve(sockets)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 78, in _serv\u00bb\ne 2 Restart the server\nconfig. load()\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/config.py\", line 436, in load\nself. loaded_app = import_from_string(self.app)\nAAAAAARAAAARAAAAAAAAAAAAAAAA bash oO Copy\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/uvicorn/importer.py\", line 22, in imp\nort_from_string\nraise exc from None\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/uvicorn/importer.py\", line 19, in imp\nort_from_string\nmodule = importlib. import_module(module_str)\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/1lib/python3.11/importlib/__init__.py\", line 126, in import_module\u2122\nreturn _bootstrap._gcd_import(name[level:], package, level)\n\nuvicorn excuse_api:app --reload\n\nYou should now see:\n\nFile \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import oO Copy |\nFile \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load Vv\n\nFile \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n\nFile \"<frozen importlib._bootstrap>\", line 69@, in _load_unlocked i.\n\nFile \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\nFile \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed 4\n@ File \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 14, in <module> L<) excuse_apl.py X\nfrom langchain.schema import SystemMessage, HumanMessage\nModuleNotFoundError: No module named 'langchain'\n\n> OUTLINE ACINFO: Stopping reloader process [5920] : Message Bhuvan\n$03 @ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % source .venv/bin/activate\n> VILE (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % [] I, eo 0\n& mains @ @O0AS5 Q 1n61,Col14 Spaces:4 UTF-8 LF {} Python @ 3.13.264-bit O + \u00ae & Y\n\nolen ical == | :"
}