{
  "timestamp": "2025-07-02_09-47-51",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "uvicorn excuse_api:app --reload",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ Code\n\nO<\u00ab 7? Co\n\ng\u00a7\n2\n\u00a9\n\nFile Edit Selection View Go  Run_ Terminal Window\u2019 Help\n= x x  \u00a2O x  \u00a2O x\nO OD file:///Users/bhuvanarora/Downloads/Artificial_Intelligence_Capstone_Project.pdf.pdf\ne@e@ < \u00a3 excuse-generator By oO WW\n| oO EXPLORER J Welcome \u00ae excuse_api.py 4,U X % .env U Py B\n\nVv EXCUSE-GENERATOR @ excuse_api.py > ...\n\n{> \u2014Pycache_ # excuse_api.py E\nes import os, json, time, hashlib \u2014\na > include from pathlib import Path =\n| 2b from dotenv import load_dotenv\n& \u00a9 pyvenv.cfg SLES\nSlew 5 load_dotenv() # \u00ab NEW: pulls OPENAI_API_KEY from .env\n_\n)\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\nU\nU\n@ excuse_api.py 4,U\n{} history.json U\n\nU\n\nDead\n\n= requirements.txt\n\n(SSS simple \u201cDB\u201d ---------\u2014\n\nDATA = Path(\"history. json\")\n\nif not DATA.exists():\nDATA.write_text(\"[]\")\n\n(SSS OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\") )\n\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS. B-) python3.11 + v i) -- ~ XxX\nRequirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.@->openai) (1.0.9) I\nRequirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*\u2014->httpx<1,>=@.23.@->openai) (0.1\nee already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.@->openai) (0.7\neo aren already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.@->openai) (2.33\nReavirenent already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.@->openai) (@\n\nRequirement already satisfied: starlette<0.47.0,>=0.40.@ in ./.venv/lib/python3.11/site-packages (from fastapi) (@.46.2)\nRequirement already satisfied: click>=7.0 in ./.venv/lib/python3.11/site-packages (from uvicorn) (8.2.1)\n\n\u00ae (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % from dotenv import load_dotenv\nzsh: command not found: from\n(.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % uvicorn excuse_api:app \u2014-reload\nINFO: Will watch for changes in these directories: ['/Users/bhuvanarora/excuse-generator']\n\n@ INFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n\nINFO: Started reloader process [88510] using StatReload\n\nINFO: Started server process [88515]\n> OUTLINE INFO: Waiting for application startup.\n$03 INFO: Application startup complete.\n> TIMELINE\nw&y % main* \u00ae@ @oA4 Q Ln5,Col63 Spaces:4 UTF-8 LF {} Python @ 3.13.264-bit O\n\nG@ROTO8\n\nArtificial_Intelligence_Capstone_ X a]\n\n34% 0) FS\n\nx M x\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\npython\n\nimport os, json, time, hashlib\nfrom pathlib import Path\n\nfrom dotenv import load_dotenv\nload_dotenv()\n\nfrom fastapi import FastAPI\n\n3. Save the file (#S/ Ctrl S).\n\n4. In the terminal (still inside (.venv)):\n\nbash\nuvicorn excuse_api:app --reload\n\nINFO: Uvicorn running on http://127.0.0.1:8000\n\n5. Open a second terminal tab (_) and test:\n\nbash\n\ncurl -X POST http://127.0.0.1:8000/generate \\\n-H \"Content-Type: application/json\" \\\n-d '{\"scenario\":\"missed class\", \"urgency\":\"panic\"}!\n\nYou should receive your first JSON excuse. 3\n\n(If you haven't created . env yet, make the file \u2018th one line\nv\nOPENAI_API_KEY=sk-xxxxxxxx in the proj. _. root, then repeat step 4.)\n\nMessage Bhuvan\n\n+ \u00ae\n\nS800eEGE820 \u00a9O8F\u00b010 &*\n\n@ Wed Jul 2 9:47AM\n\nx\n\nmo >\u00bb\n\u00a9) Copy\n\n\u00a9) Copy\n\n\u00a9) Copy"
}