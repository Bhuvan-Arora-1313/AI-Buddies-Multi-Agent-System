{
  "timestamp": "2025-07-02_10-46-52",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "pkill -f \"uvicorn.*excuse_api\" 2>/dev/null ",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"gemini-pro\")\nprint(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "Code File Edit Selection View Go Run Terminal Window\u2019 Help 3 23%%4) FQ Bg Wed Jul 2 10:46AM\n+\n\n= List of research @ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence [| Al-05-BBLEN4 \u00a9 OpenAl coy API keys - Open/ [G) G\nMaccy\n. pkill -f \"uvicorn*excuse_api\" 2>/dev/null-\nO<\u00a2\u00ab vr coe O & \u00a9 aistudio.google.com/apikey Intelligent Excuse Generator Plan >\nBhuvan\nS f\n1 or\nGoogle Al Studio a ; ; 0\na} models/gemini-pro, which that old endpoint can't serve.\n\u00a9 eee \u00ab> P excuse-generator By oO Wl ith the new SDK (0.8.5) you should pass the plain model ID (\"gemini-\u2014pro\") when you build\na oO EXPLORER + J Welcome \u00ae excuse_api.py 4,U X env U Dy -- @model object \u2014not the full \u201cmodels/...\" path.\n@\nVv EXCUSE-GENERATOR @ excuse_api.py > ...\nP > __pycache__ 7\nih, Us: v .venv 8 |\n> bin H H i\na uick 2-line fix\n= Ch oo > include 9 from fastapi import FastAPI f\n>is 10 from pydantic import BaseModel |\nrd % pyvenv.cfg U Pyeantzc p python oO Copy\n .env U all\nES @ excuse _apipy 4,U 12 import google.generativeai as genai import google.generativeai as genai\n( Giseaien U 13 genai.configure(api_key=os.getenv(\"GEMINI_KEY\") ) genai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nA, = requirements.txtu r r i =n T model = genai.GenerativeModel(\"gemini-pro\")\n14 model = genai.GenerativeModel(\"gemini-pro\")\n15 print(\">>> model being used:\", model._name . . . .\np ( . ug \u00bb \u2019 - ) fake sure there\u2019s only one import / configure / model block in the file.)\n1@ Ff ===Saeeees simple \u201cDB\u201d ---------\u2014\n17 DATA = Path(\"history. json\")\n18 if not DATA.exists():\n19 DATA.write_text(\"[]\") # seed empty list hen restart everything cleanly\n20\n7 bash \u00a9) Copy\n22\n23 2 ====eSSeo= FastAPI app \u2014--------- ctr1-c\n24 app = FastAPI() pkill -f \"uvicorn.*excuse_api\" 2>/dev/null\n25 source .venv/bin/activate\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS. +. + A x Uvicorn excuse_api:app \u2014-reload\nFile \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked = 2J zsh\nFile \"<frozen importlib._bootstrap_external>\", line 940, in exec_module a H .\nFile wefrozen importlib.-bootstrap>\", line 341, in call_with. frames removed alee u should now see the temporary line we added:\nFile \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 15, in <module> |\nprint(\">>> model being used:\", model._name) V\nSERRE @ Copy\nAttributeError: 'GenerativeModel' object has no attribute '_name'\n# stop any uvicorn still running '\nCtrl-C\npkill -f \u201cuvicorn.*excuse_api\" 2>/dev/null # just in case excuse_api.py x\n@ source .venv/bin/activate # activate venv\nicorn excuse_api:app \u2014-reload >\n> OUTLINE ae * \u201cstopping reloader process [2760] 2ssage Bhuvan\n$03 @ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % pkill -f \u201cuvicorn.xexcuse_api\" 2>/dev/null\n> TIMELINE (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % ff ha \u00ae en 0, st)\na View stat ll % main* \u00ae@ @oA4 : : Q_ 1n14,Col32 Spaces:4 UTF-8 LF {} Python & ae 64-bit O Ww Y"
}