{
  "timestamp": "2025-07-02_10-58-45",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "(.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}'\ncurl: (28) Failed to connect to 127.0.0.1 port 8000 after 7781 ms: Couldn't connect to server\n(.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % ",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# --- Gemini via LangChain (REST v1) ---\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\n# expose key for LangChain wrapper\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # must be in .env\n\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",          # free\u2011tier model\n    temperature=0.8,\n    convert_system_message_to_human=True\n)\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    messages = [\n        SystemMessage(content=SYSTEM_PROMPT),\n        HumanMessage(content=full_prompt)\n    ]\n    response_text = llm(messages).content.strip()\n    # LangChain may wrap JSON in ``` blocks \u2013 strip them\n    if response_text.startswith(\"```\"):\n        response_text = response_text.strip(\"`\").lstrip(\"json\").strip()\n    out = json.loads(response_text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "Code File Edit Selection View Go  Run_ Terminal Window\u2019 Help 6 \u20ac&8 0D S w2%G) F Q S \u00a9 Wed Jul2 10:58AM\n\nOw \u00ae 0\n\n= List of research & Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob \u2122 Launched - Artifi Artificial_Intelligence (i al-05-BBLEN4 \u00a9 Openal coy API keys - Open\u00e9 (G) Gemini API refere +\u201d Get API key | GX\n- > C @ O @ 2 aistu\u2019@\u2014\u2014 Intelligent Excuse Generator Plan > a =\nBhuvan\n. 7781 ms: Couldn't connect to server\nGoogle Al Studio \u00abel PyCharm Q Search projects New!\n- \u2014 : (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-\neee & > PP excuse-generator 8B\u00bb oO &\n\u00b0 generator %\n| o EXPLORER + J Welcome \u00ae excuse_api.py5,U X env U aan\n\\ EXCUSE-GENERATOR \u00ae excuse_api.py > \u00a9 generate\n5 \" Thought for a couple of seconds\n5) \u2014Pycache__ 49 def generate(r: Req):\nv venv - . vv\n5 bin 58 if response_text.startswith(\"***\"): Looked at Code\nay eras Se . Looked at Code\n> include 59 response_text = response_text.strip( ).Ustrip(\"json\").strip( =\n2 . lib 60 out = json. loads(response_text) It looks like the FastAPI server wasn't actually running when you sent the curl request\u2014so the\npyvenv.cfg U | Q : . .\n& env 7 61 entry = { client couldn't connect to anything listening on 127 .@.0.1:8000.\nHS & excuse_apipy 5,u oy \"id\": hashlib.md5(out [\"excuse\"].encode()).hexdigest(),\n{} history.json U . . .\nPROBLEMS OUTPUT DEBUGCONSOLE TERMINAL PORTS Vous AX\nA geepiceeee \u00a9 \u00ae + Quick checklist to bring the server back up\nInstalling collected packages: filetype, zstandard, tenacity, PyYAML, packaging, orjson, jsonpointer, requests-tootb\u201d 1 pybonsaii . . .\nelt, jsonpatch, langsmith, langchain-core, google-ai-generativelanguage, langchain_google_genai zsh 1. Open / focus a terminal tab that\u2019s inside your project folder and venv\nAttempting uninstall: google-ai-generativelanguage b\nFound existing installation: google-ai-generativelanguage @.6.15 ij\nUninstalling google-ai-generativelanguage-0.6.15: (the prompt should start with ( . venv))\nSuccessfully uninstalled google-ai-generativelanguage-0.6.15 he\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This beha 4 4 4\nviour is the source of the following dependency conflicts. 2. Start Uvicorn and leave it running\ngoogle-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0 1\n.6.18 which is incompatible. LT\nSuccessfully installed PyYAML-6.0.2 filetype-1.2.@ google-ai-generativelanguage-0.6.18 jsonpatch-1.33 jsonpointer-3. bash oO Copy\n@.@ langchain-core-@.3.67 langchain_google_genai-2.1.6 langsmith-@.4.4 orjson-3.10.18 packaging-24.2 requests\u2014toolbe\n1t-1.0.0@ tenacity-9.1.2 zstandard-@.23.0\nuvicorn excuse_api:app --reload\nt\nYou should see something like:\n\u00a9) Copy\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/1lib/python3.11/multiprocessing/process.py\", line 108, in run\nself._target(*self._args, *kself._kwargs)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/_subprocess.py\", line 80, in 3 3 :\nsubprocess_started INFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\ntarget (sockets=sockets) : i i\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 67, in run F INFO: Application startup complete.\nreturn asyncio.run(self.serve(sockets=sockets) )\nFile ESET CEE AERTS SDD EYL TREE LT line 190, in run 3. In a second terminal tab (also venv-activated) send the test request: |\nreturn runner.run(main\nAAAAAAAAARAAAAAAA Vv\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/runners.py\", line 118, in run f=)\nreturn self._loop.run_until_complete(task) . bash opy\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_co a\n@ mplete uv pyenv/versi ib/py ynci evi py il in run_unti Q excuse_api.py x\nreturn future. result()\n> OUTLINE File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 71, in serve\u00ae\u2122 Message Bhuvan\n$03 await self._serve(sockets)\n> TIMELINE File \"/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/uvicorn/server.py\", line 78, in _serv cf, \u00ae cy (o)\n& maint @ @O0AS Q  Ln61,Col14 Spaces:4 UTF-8 LF {} Python @& 3.13.264-bit O Ww Y\n\nSS eee\n\nS80\u00b0eESE20 O8fO00 BF\n\n\u201cial \u2014_\" Fes"
}