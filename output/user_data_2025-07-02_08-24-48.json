{
  "timestamp": "2025-07-02_08-24-48",
  "active_window": "firefox",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "Smart Border Patrol Using Drones and Wireless Charging System Under Budget Limitation\n",
  "vscode_text": "<!DOCTYPE html>\n<html>\n  <body style=\"margin: 0; background: rgba(0,0,0,0.7); color: white; font-family: sans-serif;\">\n    <div style=\"-webkit-app-region: drag; padding: 10px; background: rgba(0,0,0,0.8);\">\n      <pre id=\"output\" style=\"white-space: pre-wrap; word-wrap: break-word;\">Waiting for data...</pre>\n    </div>\n    <script>\n      const { ipcRenderer } = require('electron');\n      ipcRenderer.on('update-prediction', (event, data) => {\n        document.getElementById('output').textContent = data;\n      });\n    </script>\n  </body>\n</html>",
  "ocr_text": "Firefox File Edit View History Bookmarks Tools Window _ Help\n\n(ica) =} List of research papers - Google X A UAV patrol system using pano X * A UAV patrol system using par X Smart border patrol using drone X +\n\nC a 0 8 sciencedirectassets.com\n\nem} A Vv 3 of 9 \u2014 + 200%\n\noo : ime\noo - =\n\n\u2018 oo. ol system architecture. ne tle as etter\nVv AUAV patrol system using Ci) Highlight removed x \u00a9 oO oO\npanoramic stitching and\n\nobject detection\nThickness\n\n1 Introduction\n\nVv 2 Related work\n\nto this category as well and combines YOLO\u2019s theory with detection anchors and fully convoluted networ!\n_ augments the SSD detector with deconvoluted layers.\n\n2.1 Image stitching . . . . :\n\n2.2 Motion ghost Some object detectors with an end-to-end architecture are specifically developed for video detect\n\nla ae which uses optical flow to aggregate object features, and T-CNN which consists of multiple\n\n2.3 Object detecti : :\nee \u2014\u2122 temporal and contextual information.\nVv 3 UAV patrol system\n\nShow all\n\n3.1 System\narchitecture\n\n3. UAV patrol system\n\n3.2 Image stitching\n\n3.3 Motion ghost .\n\nelimination 3.1. System architecture\nVv 3.4 Object detection\n\nparsing ~~ As is shown in , this UAV patrol system consists of a stitching and a detection module and takes a video as its input.\n\n3.4.2 Quantifying The stitching module uses selected frames from the video to generate a single image, which is then sent to the detection\n\nthe object-scene\n\nrelationship module. The stitched image is dissected and labeled with scene types by the scene parsing layer. Together with the output\n\n34.8 Model of the region proposal layer, the scene parsing result is sent to the scoring layer which produces the detection visualizations\n\n4. Experiments as the final result. SPHP is employed as the stitching module, while the detection module is a combination of PSPNet and\nY 4.1 Dataset and Faster R-CNN. In a real-world application, this system can function as a web server that accepts an uploaded video and\n\nexperiment settings\n\n4.11 Dataset returns a stitched image with detection labels afterwards.\n\n4.1.2 Experiments\nti . \u00b0\n\nae 3.2. Image stitching\n\n4.2 Image stitching\n\nevaluation\n\n28 Che 8D We adopt SPHP as the image stitching algorithm, which works at a simple principle while providing a good stitching\n\nA.A Results effect at a satisfactory speed. SPHP proposes a method that can smoothly transition from a projection transformation to\n5 Conclusion an overlapping region and to a similar transformation in a non-overlapping region, thus creating naturally looking stitching\nDeclaration of\n\nenosteanence: results. However, this works best for the stitching of static objects. For moving objects in the image sequences or video,\nReferences motion residuals will appear in the stitched results, thus resulting in a bad visual experience.\n\n3.3. Motion ghost elimination\n\nSGO0%\u00b0eGSEE2\u00b0 O82 G\u00ae*"
}