{
  "timestamp": "2025-07-02_10-40-37",
  "active_window": "ChatGPT",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "python - <<'PY'\nimport os, dotenv, google.generativeai as genai, pathlib, sys\ndotenv.load_dotenv('.env', override=True)\n\nprint(\"SDK version  :\", genai.__version__)\nprint(\"API key prefix:\", os.getenv(\"GEMINI_KEY\")[:10] if os.getenv(\"GEMINI_KEY\") else \"MISSING\")\n\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\ntry:\n    print(\"\\nModels visible to this key:\")\n    for m in genai.list_models():\n        print(\"  \u2022\", m.name)\nexcept Exception as e:\n    print(\"\\n\u26a0\ufe0f  list_models() raised:\", e.__class__.__name__, e)\n    sys.exit(1)\nPY",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "\u00ab\n\no\nS\n\n\u00a9\n\nChatGPT\n\nFile\n\nEdit\n\nView\n\nC2 GA\n\n2\n\noO\n&\n>\n\nm%\n\nES\n\nDead\n\n@\na\n\nEXPLORER\n\nV EXCUSE-GENERATOR\n> __pycache__\nv venv\n> bin\n> include\n> lib\n\u00a9 pyvenv.cfg\n\u00a9 .env\n@ excuse_api.py 4,\n{} history.json\n= requirements.txt\n\n> OUTLINE\n> TIMELINE\n\nGE & maine @0A4\n\nWindow Help\nFy co co | M\nO @& = aistudio.google.com/apikey\n< P excuse-generator By Dual\nJ Welcome \u00ae excuse_api.py 4,U X %.env U Py %& O -\n\u00ae excuse_api.py > \u00a9 generate\n0 \u2014\u2014 /PMEAKe \u2014\u2014\u2014\u2014\u2014\u2014=\u2014 .\n@app-post(\"/generate\")\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS. +yv A x\n+5 models/gemini-1.5-flash-002 i | Glzsh\nmodels/gemini-1.5-flash-8b >.) zsh\nU models/gemini-1.5-flash-8b-001\nU models/gemini-1.5-flash-8b-latest\nmodels/gemini-2.5-pro-preview-03-25\nU models/gemini-2.5-flash-preview-04-17 [\nU models/gemini-2.5-f lash-preview-@5-20\nmodels/gemini-2.5-flash\nmodels/gemini-2.5-f lash-preview-04-17-thinking\nmodels/gemin -f lash-Lite-preview-06-17\nmodels/gemin \u2014pro-preview-05-06 L\nmodels/gemini-2.5-pro-preview-6-05\nmodels/gemini-2.5-pro\nmodels/gemini-2.0-f lash-exp\nmodels/gemini-2.0-flash\nmodels/gemini-2.0-f lash-01\nmodels/gemini-2.0-f lash-exp\u2014image-generation\nmodels/gemini-2.0-flash-lite-001 I\nmodels/gemini-2.0-flash-lite\nmodels/gemini-2.0-f lash-preview-image-generation\nmodels/gemin -f lash-Lite-preview-02-05 H\nmodels/gemin -f lash-lite-preview\nmodels/gemini-2.0-pro-exp\nmodels/gemini-2.@-pro-exp-02-05\nmodels/gemini-exp-1206\nmodels/gemini-2.0-f lash-thinking-exp-01-21\nmodels/gemini-2.0-f lash-thinking-exp\nmodels/gemini-2.0-f lash-thinking-exp-1219 if\nmodels/gemini-2.5-flash-preview-tts\n\nmodels/gemini-2.5-pro-preview-tts\nmodels/learnlm-2.0-f lash-experimental :\nmodels/gemma-3-1b-it\nmodels/gemma-3-4b-it\nmodels/gemma-3-12b-it\nmodels/gemma-3-27b-it\nmodels/gemma-3n-e4b-it\nmodels/gemma-3n-e2b-it\nmodels/embedding-001 at\nmodels/text-embedding-004\nmodels/gemini-embedding-exp-03-07\nmodels/gemini-embedding-exp\n\nmodels/aga\n\nmodels/imagen-3.@-generate-002\nmodels/imagen-4.@-generate-preview-06-06\nmodels/imagen-4. @-ultra-generate-preview-06-06\n\nmodels/veo-2.0-generate-001\n\nmodels/gemini-2.5-f lash-preview-nat ive-audio-dialog\nmodels/gemini-2.5-f lash-exp-nat ive-audio-thinking-dialog\nmodels/gemini-2.0-f lash-live-001\nmodels/gemini-live-2.5-flash-preview\n\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % o\n\nLn 42,Col63 Spaces:4 UTF-8 LF {} Python @& 3.13.264-bit (|\n= bs bss w = = =\nfile.pdf ITRV (1).pdf ITRV.pdf AIEUTIR EAI EY Iko to mtj Iko to MTJ (1).pdf Iko to MTJ-s~\n\nG@ROTO8\n\nB 6 6 [)\n\n19% (6\n\n\u2014\n-\n\nQs\n\n@ Wed Jul 2 10:40AM\n\n96 Get API key | GX\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\neco MO @G\n\nThought for 22 seconds >\nGreat \u2014 your diagnostic confirms everything we need:\n\n+ SDK version: 0.8.5 (new enough)\n\n+ Key loaded: good\n\n+ models/gemini-pro is visible in the list\n\nSo access is fine.\n\nThe 404 is only because the server is still calling the model with\n\nthe short name (\"gemini-pro\") rather than the full path\n\"models/gemini-pro\" (or the old code is still in memory).\n\nDo these two tiny fixes and you'll be done:\n\n1 Make sure the code uses the full model name\n\nAt the very top of excuse_api.py keep exactly:\npython\n\nimport google.generativeai as genai\n\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\n\nmodel = genai.GenerativeModel(\"mode*s/gemini-pro\" )\nVv\n\n\u00a9 excuse_api.py x\n\nMessage Bhuvan\n\n+ @\u00ae\n\nen\n\nWw\n\nS80\u00b0G8880 eeea ae\n\n(es)\n\n\u00a9) Copy\n\n10"
}