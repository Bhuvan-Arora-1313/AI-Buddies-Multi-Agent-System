{
  "timestamp": "2025-07-02_09-40-37",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "a\n\nCode File Edit Selection View Go Run Terminal Window\u2019 Help\n\n= x (2 x Oo x Oo x [a\noO om lan -\u2122 in Por seme mo \u2014 . ba eee ee ete ~ . \u2014 . ae ae\ne@e@ < \u00a3 excuse-generator By i oO\n\u00a9 & EXPLORER ++ J Welcome \u00ae excuse_api.py 3,U X Dy B\nD \\ EXCUSE-GENERATOR \u00ae excuse_api.py > \u00a9 top\nY acy def generate(r: Req): =\n\u00a9 > bin i=\n> include )\n@ >i out = json. loads(res.choices[@] .message. content)\npyvenv.cfg U\n@ excuse_api.py 3,U\n= requirements.txt U entry = {\n\"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n\"ts\": time.time(),\n**\u00abOUt,\n}\nhistory = json. loads(DATA. read_text())\nif entry[\"id\"] not in {h[\"id\"] for h in history}: # de-dupe\nhistory.append(entry)\nDATA.write_text(json.dumps(history, indent=2) )\nreturn entry\n2 SSS /top?n=5 -\u2014--------\u2014\n@app.get(\"/top\")\ndef top(n: int = 5):\nhistory = json. loads(DATA. read_text())\nhistory.sort(key=lambda x: x[\"believability_score\"], reverse=True:\n64 return history[:n]]|\n> OUTLINE\n> TIMELINE\nwy go main* \u00ae@ @O0A3 Q_ 1n64,Col23 Spaces:4 UTF-8 LF {} Python @ 3.13.264-bit Q\nSB\n\n6 \u20ac&8 \u00a9G O S 3%8) FQ BS \u00a9 WedJul2 9:40AM\n\nx M x Artificial_Intelligence_Capstone_ X @ x\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\no \u00bb\nStill in Explorer:\n\n1. New File > .env\n\n2. Put a single line (replace with your key):\n\n\u00a9) Copy\n\nOPENAI_API_KEY=sk\u2014XXXXXXXXXXXXXXXXXXXXXXXX\n\n3. Save. (.env stays local; we won't commit it.)\n\n3 Open VS Code's integrated terminal\n\nShortcut: **Ctrl ** (back-tick) &nbsp;or from menu Terminal > New Terminal\u2019.\n\nYou should already be in the project root; the prompt might show (venv) if the virtual-env\nauto-activated.\n\nIf it doesn't, activate it manually:\n\nbash \u00a9 Copy\n\nsource .venv/bin/activate\n\n4 Install / verify dependencies\n\nMessage Bhuvan\n\n+ @\u00ae ov\n\n=]\n\nS800eEGE820 \u00a9O8F\u00b010 &*"
}