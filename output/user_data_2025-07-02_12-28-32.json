{
  "timestamp": "2025-07-02_12-28-32",
  "active_window": "ChatGPT",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "8.\n9.\n10.\nAuto-Scheduling \u2013\nMulti-Language Support \u2013\nSmart Excuse Ranking \u2013\nAI predicts when an excuse might be needed based on past patterns.\nExcuses available in different languages for global use.\nAI ranks the best possible excuse based on past effectiveness.",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# --- Gemini via LangChain (REST v1) ---\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\n# expose key for LangChain wrapper\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # must be in .env\n\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",          # free\u2011tier model\n    temperature=0.8,\n    convert_system_message_to_human=True\n)\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n    mode: str = \"normal\"   # \"normal\" | \"apology\"\n    language: str = \"en\"   # ISO code, e.g. \"en\", \"es\", \"fr\"\n\nclass EmergencyRequest(BaseModel):\n    number: str\n    message: str\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    style_clause = (\n        \"Respond in a guilt\u2011tripping, heartfelt apology tone.\"\n        if r.mode.lower() == \"apology\"\n        else \"Respond in a neutral, believable tone.\"\n    )\n    # language directive\n    lang_clause = (\n        \"\" if r.language.lower() in [\"en\", \"english\"] else\n        f\"Respond in {r.language} language.\"\n    )\n    full_prompt = (\n        f\"{SYSTEM_PROMPT}\\n\"\n        f\"Tone: {style_clause}\\n\"\n        f\"{lang_clause}\\n\"\n        f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    )\n    messages = [\n        SystemMessage(content=SYSTEM_PROMPT),\n        HumanMessage(content=full_prompt)\n    ]\n    response_text = llm(messages).content.strip()\n    # LangChain may wrap JSON in ``` blocks \u2013 strip them\n    if response_text.startswith(\"```\"):\n        response_text = response_text.strip(\"`\").lstrip(\"json\").strip()\n    out = json.loads(response_text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]\n\n# ---------- /emergency ----------\n@app.post(\"/emergency\")\ndef emergency(req: EmergencyRequest):\n    \"\"\"\n    Simulate sending an emergency SMS/call.\n    For the demo we just log the request and append an entry to history.json.\n    \"\"\"\n    entry = {\n        \"id\": f\"emergency-{int(time.time())}\",\n        \"ts\": time.time(),\n        \"excuse\": \"EMERGENCY TRIGGER\",\n        \"believability_score\": 1.0,\n        \"chat_log\": f\"Sent '{req.message}' to {req.number}\"\n    }\n    history = json.loads(DATA.read_text())\n    history.append(entry)\n    DATA.write_text(json.dumps(history, indent=2))\n    return {\"status\": \"sent\", \"to\": req.number, \"msg\": req.message}",
  "ocr_text": "@ ChatGPT File Edit View Window Help 6 \u20acOD S wx F Q S OS WedJul2 12:28PM\n\n\u00bb \u2122 B 6 coy (S) SP Get API key |G X\n7 \u2014\n7. Excuse History & Favorites \u2014 Users can save frequently used excuses for quick access. rT E G Pl\nntelligent Excuse Generator Plan >\neee cB) Z Shane\nThought for a couple of seconds\n< excuse-generator\n1 file changed Review Revert\noO EXPLORER 990 @ excuse_api.py5 X  {} history.json @ README.md env u 4 9 9\n\\ EXCUSE-GENERATOR \u00ae excuse_api.py > \u00a9 generate D excuse_api.py -1 fa)\n> _pycache_ def generate(r: Req): =\nv .venv 4 . -~ - - - 37 urgency: str\n\u00bb > [ele y ) 38 mode: str = \"normal\"\n> includ ; =\n5 i. . j full_prompt = ( 39 language: str = \"en\"\npyvenv.ctg \u00a3\"{SYSTEM_PROMPT}\\n\" 40\nenv U i f\"Tone: {style_clause}\\n\" 41 class EmergencyRequest(BaseModel):\n\u00ae excuse_api. 5 j x i\n6 historyjeon. 69\u00b0 f\"{lang_clause}\\n\" x 17 lines\n. 4 . . \" 4 - \"\n@ ReAaY Em i f\"Scenario: {r.scenario}\\nUrgency: {r.urgency 59 else \"Respond in a neutral, believable tone.\n= requirements.txt y ) 68 )\n. 61\nmessages = [\n62 lang_clause =\nSystemMessage(content=SYSTEM_PROMPT), se : . ;\na a \u2019 wn ae - 63 \"\" if r.language.lower() in [\"en\", \"english\"] else\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS 64 f\"Respond in {r language} language.\"\n-d '{\"scenario\":\"missed class\",\"urgency\":\"panic\",\"mode\":\"apology\"}' 65 )\n{\"id\" :\"b3d467d71332169893e42b24102ece48\" , \"ts\":1751437206.329449,\"excuse\":\"Woke up in absolute agony|\nsoning. Spent the entire morning completely incapacitated and glued to the bathroom. There was si 66 full t= (\ne without risking a truly embarrassing public incident.\",\"believability_score\":0.92,\"chat_log u _Prompt =\nass.\\nMe: OMG, so sorry! Woke up with the worst stomach bug. It was pure hell, literally couldn't 1 _ .\nCusiue Watrrs ors Ugh, that sucks! Hope you feel better soon. Don't worry about notes.\\nMe: Thanks. f\"{SYSTEM_PROMPT}\\nTone: {style_clause}\\n\"\neciate it!\"}2\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % curl -X POST http://127.0.@.1:8000/gener 67 f\"{SYSTEM_PROMPT}\\n\" oO Copy\n-H \"Content-Type: application/json\" \\ 6\nd '{\"scenario\":\"bumped my friends car that i borrowed\",\"urgency\":\"low\",\"mode\":\"apology\"}' 68 f\"Tone: {style_clause}\\n\"\n\n{\"i \"2d2e2aca2d3e7e9 fb66d8e4d5694613f\", \"ts\": 1751437389. 9344718,\"excuse\":\"Hey, so sorry, but someo \" \"\n\nt was parked at the grocery store. I left it for maybe 3@ minutes, came back, and saw the bump on t| 69 f {lang_clause}\\n\n\nout it, I swear I didn't feel anything while driving.\",\"believability_score\":0.88,\"chat_log\":\"Me: | \" - . . \"\nyour car...\\nFriend: Oh no, what?!\\nMe: Looks like someone backed into it or something while it wa 78 f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\nhe rear when I came out. I'm so sorry, dude.\\nFriend: Ugh, seriously?! People are the worst. Is it 71 )\n\nly noticeable. I'm gutted for you. Couldn't believe it.\"}2\n\n@ (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/gener Added multi-language support:\n-H \"Content-Type: application/json\" \\\n-d Sa TENE eee ESTE, Mena erase ,'\"mode\":\"humorous\"}'\nInternal Server Errorg . - u \" H\n@ (.venv) prtvanenchecenitvanseneceectard excuse-generator % curl -X POST http://127.0.0.1:8000/gener \u00b0 Req now has language: str = en (default English).\n-H \"Content-Type: application/json\" \\\n-d '{\"scenario\":\"deadline\",\"urgency\":\"medium\",\"mode\":\"humorous\"}'\nInternal Server Errorg\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % curl -X POST http://127.0.@.1:8000/gener n mA 3 n v\n-H \"Content-Type: application/json\" \\ language #\u00b0-en | english fs\n-d '{\"scenario\":\"missed class\",\"urgency\":\"panic\",\"mode\":\"apology\"}'\n{\"id\":\"af4f89f590036448a16a258ad9637681\", \"ts\":1751437937.811754,\"excuse\":\"Oh my god, I am so, so te\n. I truly feel awful. Something completely unexpected and deeply upsetting came up with my grandmot\nred me to drop everything and rush to her side. I had absolutely no time to even send a message. I' \u00a9 excuse_api.py x\n\n+ Prompt injects a clause like \u201cRespond in Spanish language.\u201d when\n\n> OUTLINE core\":0.88,\"chat_log\":{\"sender_a\":\"Okay, hurry. She needs you.\",\"me\":\"On my way! Just left, praying|\nre sooner.\"}}2\n> TIMELINE (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % [] Message Bhuvan\n main* 2 @0A5 Not Committed Yet Q Ln 69, Col 27\n\n=e INIT @...LOW] MPS QOCUITIEMLS \u00abpal l= E.par 234.3 MB\n8 vroese \u00b0 \u00b0 + @ & \u00a2 @\n\n\u2014 S@80O\u00b0aSSe\u00a9 \u00a98002 &*\n\n.\nB= \u2014 1 = | EB \u2014_. 7 _\u2014 | Pass | Ee"
}