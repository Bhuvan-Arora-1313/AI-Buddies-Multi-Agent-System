{
  "timestamp": "2025-07-02_12-45-04",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "git push",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# --- Gemini via LangChain (REST v1) ---\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\n# expose key for LangChain wrapper\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # must be in .env\n\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",          # free\u2011tier model\n    temperature=0.8,\n    convert_system_message_to_human=True\n)\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n    mode: str = \"normal\"   # \"normal\" | \"apology\"\n    language: str = \"en\"   # ISO code, e.g. \"en\", \"es\", \"fr\"\n\nclass EmergencyRequest(BaseModel):\n    number: str\n    message: str\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    style_clause = (\n        \"Respond in a guilt\u2011tripping, heartfelt apology tone.\"\n        if r.mode.lower() == \"apology\"\n        else \"Respond in a neutral, believable tone.\"\n    )\n    # language directive\n    lang_clause = (\n        \"\" if r.language.lower() in [\"en\", \"english\"] else\n        f\"Respond in {r.language} language.\"\n    )\n    full_prompt = (\n        f\"{SYSTEM_PROMPT}\\n\"\n        f\"Tone: {style_clause}\\n\"\n        f\"{lang_clause}\\n\"\n        f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    )\n    messages = [\n        SystemMessage(content=SYSTEM_PROMPT),\n        HumanMessage(content=full_prompt)\n    ]\n    response_text = llm(messages).content.strip()\n    # LangChain may wrap JSON in ``` blocks \u2013 strip them\n    if response_text.startswith(\"```\"):\n        response_text = response_text.strip(\"`\").lstrip(\"json\").strip()\n    out = json.loads(response_text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]\n\n# ---------- /emergency ----------\n@app.post(\"/emergency\")\ndef emergency(req: EmergencyRequest):\n    \"\"\"\n    Simulate sending an emergency SMS/call.\n    For the demo we just log the request and append an entry to history.json.\n    \"\"\"\n    entry = {\n        \"id\": f\"emergency-{int(time.time())}\",\n        \"ts\": time.time(),\n        \"excuse\": \"EMERGENCY TRIGGER\",\n        \"believability_score\": 1.0,\n        \"chat_log\": f\"Sent '{req.message}' to {req.number}\"\n    }\n    history = json.loads(DATA.read_text())\n    history.append(entry)\n    DATA.write_text(json.dumps(history, indent=2))\n    return {\"status\": \"sent\", \"to\": req.number, \"msg\": req.message}",
  "ocr_text": "Code File Edit Selection View Go  Run_ Terminal Window\u2019 Help 3 100%) fF Q Wed Jul 2 12:45PM\n+\n\n\u00a9 9\u20ac Get API key |G X\n\n[|\nx\n6\n\nw usr os\n\n7. Excuse History & Favorites \u2014 Users can save frequently used excuses for quick access.\n\nIntelligent Excuse Generator Plan >\n\nBhuvan\n: \u2014 - Ly Wy yy wy\nee@e@ & PP excuse-generator By eo Ww ok now lets update this on git\noO EXPLORER 990 @ excuse_api.py 5 X  {} history.json M @ README.md env u Dy\n\\ EXCUSE-GENERATOR \u00ae excuse_api.py > \u00a9 generate\n> _pycache_ def generate(r: Req): : |\nVV venv ~ - ~ - rl\n> bin ) \u00e9\n10K > include messages = [ an 4 . . .\n> lib 9g e ands to commit your latest code (with Language support) and push it to GitHub.\nPREM SystemMessage(content=SYSTEM_PROMPT) ,\nenv u HumanM ntent=full_prompt F . . . . . .\n\u00ae excuse_api.py 5 umanMessage (conte ult_prompt) project folder and the virtual-env is optional (not required for Git operations).\n{} history.json M ] ;\n@ README.md response_text = 1lm(messages).content.strip() \u00a9 Copy\n= requirements.txt # LangChain may wrap JSON in \u201c~*~ blocks \u2014 strip them\nif response_text.startswith(\"***\"):\nq 9 q q q E.md\nresponse_text = response_text.strip(\"*\").1lstrip(\"json\").strip()\nPROBLEMS OUTPUT DEBUG CONSOLE TERMINAL PORTS Vous A XK 7 .\ne SS a lti-language support (language field) and keep apology mode\"\nINFO: Application startup complete. >.) zsh\n/Users/bhuvanarora/excuse-generator/excuse_api.py:76: LangChainDeprecationWarning: The method \u2018BaseChatModel.__call__\u2019 was deprecated i lay\n\nn langchain-core @.1.7 and will be removed in 1.0. Use :meth:*~invoke* instead.\n\nresponse_text = 11lm(messages).content.strip()\n/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_\nsystem_message_to_human will be deprecated!\n\nwarnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n\nINFO: 127.0.@.1:65522 - \"POST /generate HTTP/1.1\" 200 OK\n\n/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/langchain_google_genai/chat_models.py:483: UserWarning: Convert_\n\nsystem_message_to_human will be deprecated! ' a _\nwarnings.warn(\"Convert_system_message_to_human will be deprecated!\") \u2018rora 1313/excuse generator\n\nINFO: 127.0.@.1:65532 - \"POST /generate HTTP/1.1\" 200 OK\n\nACINFO: Shutting down\n\nINFO: Waiting for application shutdown.\n\nINFO: Application shutdown complete.\n\nINFO: Finished server process [12570] 1 4 .\n\nINFO: Stopping reloader process [11332] is now on GitHub.\n\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % git add excuse_api.py README.md\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % git commit -m \u201cfeat: add multi-language support (language field) and keep ap\n\nology mode\"\n[main 8@@a8a1] feat: add multi-language support (language field) and keep apology mode He\n1 file changed, 18 insertions(+), 2 deletions(-) | Th\n\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % git push\nEnumerating objects: 5, done.\nCounting objects: 100% (5/5), done. :\nDelta compression using up to 8 threads\nCompressing objects: 100% (3/3), done.\nWriting objects: 100% (3/3), 657 bytes | 657.00 KiB/s, done.\nTotal 3 (delta 2), reused @ (delta @), pack-reused @\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects\n\n> OUTLINE To https://github. com/Bhuvan-Arora-1313/excuse-generator.git\n98d2b2a..800a8a1 main -> main\n> TIMELINE (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % fj I\nLx  mainx O @0A5 \u00a9 Bhuvan Arora (now) @Q  Ln69,Col27 Spaces:4 UTF-8 LF {} Python @& 3.13.264-bit O\n\n\u2014\u2014 S80%\u00b0eSS20 \u00a98008\n\nB= \u2014 1 = | EB \u2014\u2014, a."
}