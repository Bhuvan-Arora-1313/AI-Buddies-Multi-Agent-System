{
  "timestamp": "2025-07-02_11-23-50",
  "active_window": "ChatGPT",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "pip freeze > requirements.txt",
  "vscode_text": "[\n  {\n    \"id\": \"d4640a6dc6136022101f8e116987667f\",\n    \"ts\": 1751434240.388604,\n    \"excuse\": \"My deepest apologies for missing class today. My pet had a sudden, severe medical emergency this morning \\u2013 a terrifying seizure. I had to rush him to the emergency vet immediately and am still here waiting for news. It was a complete panic; I couldn't possibly have made it in.\",\n    \"believability_score\": 0.92,\n    \"chat_log\": \"From Friend: Hey, you okay? Class started, didn't see you.\\nFrom Me: No, major panic. [Pet's Name] had a seizure, rushed him to emergency vet. Still here. Couldn't make it. \\ud83d\\ude2d\\nFrom Friend: Oh no! So sorry, hope he's okay! \\ud83d\\ude4f\"\n  },\n  {\n    \"id\": \"emergency-1751435255\",\n    \"ts\": 1751435255.78213,\n    \"excuse\": \"EMERGENCY TRIGGER\",\n    \"believability_score\": 1.0,\n    \"chat_log\": \"Sent 'Call me now!' to +1123456789\"\n  },\n  {\n    \"id\": \"9a03094745b90498848dac0ed1f8e20e\",\n    \"ts\": 1751435416.3541481,\n    \"excuse\": \"My younger sibling had a sudden, severe allergic reaction and I had to rush them to urgent care. It was incredibly sudden and chaotic, pure panic. I'm still at the clinic with them, waiting for updates. Couldn't even think about class.\",\n    \"believability_score\": 0.96,\n    \"chat_log\": {\n      \"Mom\": \"Hurry! They're struggling to breathe.\",\n      \"You\": \"Pulling up now. This is insane.\"\n    }\n  },\n  {\n    \"id\": \"emergency-1751435436\",\n    \"ts\": 1751435436.605806,\n    \"excuse\": \"EMERGENCY TRIGGER\",\n    \"believability_score\": 1.0,\n    \"chat_log\": \"Sent 'Call me now!' to +1123456789\"\n  }\n]",
  "ocr_text": "@ ChatGPT File Edit View Window\u2019 Help 6 \u20ac8 \u00a9 DB S ome) F Q S \u00a9 Wed Jul2 11:23AM\n\n= List of research @ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob \u2122 Launched - Artif Artificial_Intelligence | Al-05-BBLEN4 \u00a9 Openal o API keys - Open/ (S) Gemini API refer * Get API key | GX\n_ . ae ern a ( . \\e =\nO<\u00a2vr Co O @ = aistu\u00a2 eee OG intelligent Excuse Generator Plan > \u2014 =\nSy) www wu wv\n\u00b0 Google Al Studio (Fe] PyCharm Qs t how will it know my git ID and where to push Bo\n|\n<5 \u00a3 excuse-generator By\n\u00a9 a\n| oO EXPLORER 90 @ excuse_api.py5 X  {} history.json @ README.md & .env U\n\\ EXCUSE-GENERATOR \u00ae excuse_api.py > @ emergency\n{> \u2014pycache_ 87 def emergency(req: EmergencyRequest) :\nv venv 5\n5 bin 100 history.append(entry)\n\u2018we > include 101 DATA.write_text(json.dumps(history, indent=2) )\n> 2\u201d 102 return {\"status\": \"sent\", \"to\": req.number, \"msg\":\n\n\u00a9 pyvenv.cfg\n .env\n\nES @ excuse_api.py ty\n{} history.json\n\nPROBLEMS e OUTPUT DEBUG CONSOLE TERMINAL PORTS\nJX @ README.md a\n\n= requirements.txt INFO: Finished server process [6655]\nINFO: Stopping reloader process [6653]\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % pip freeze > requirements.txt\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % nano README.md\n@ (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % uvicorn excuse_api:app --reload\nINFO: Will watch for changes in these directories: ['/Users/bhuvanarora/excuse-generator']\nINFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO: Started reloader process [7578] using StatReload\nINFO: Started server process [7580]\nINFO: Waiting for application startup.\nINFO: Application startup complete.\nINFO: 127.@.0.1:65352 \u2014 \"POST /emergency HTTP/1.1\" 200 OK\nACINFO: Shutting down\nINFO: Waiting for application shutdown.\nINFO: Application shutdown complete.\nINFO: Finished server process [7580]\nINFO: Stopping reloader process [7578]\n\u00ae (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % pkill -f \u201cuvicorn.*excuse_api\"\n\u00ae (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % pkill -f \u201cuvicorn.*excuse_api\"\n@ (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % uvicorn excuse_api:app --reload\nINFO: Will watch for changes in these directories: ['/Users/bhuvanarora/excuse-generator']\nINFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO: Started reloader process [8187] using StatReload\nINFO: Started server process [8189]\nINFO: Waiting for application startup.\nINFO: Application startup complete.\n\n/Users/bhuvanarora/excuse-generator/excuse_api.py:6@: LangChainDeprecationWarning: The method \u201cBase!\n\nall_ was deprecated in langchain-core @.1.7 and will be removed in 1.0. Use :meth:*~invoke* instei\nresponse_text = 11m(messages).content.strip()\n\n/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/langchain_google_genai/chat_i\n\n: UserWarning: Convert_system_message_to_human will be deprecated! |\nwarnings.warn(\"Convert_system_message_to_human will be deprecated!\")\nINFO: 127.0.@.1:65354 - \"POST /generate HTTP/1.1\" 200 OK\nINFO: 127.0.0.1:65357 \u2014 \"POST /emergency HTTP/1.1\" 200 OK\nACINFO: Shutting down\nINFO: Waiting for application shutdown.\nINFO: Application shutdown complete. 4\n@ INFO: Finished server process [8189] o CXOUSE AIUD 2\nINFO: Stopping reloader process [8187]\n\u00ae (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % (\u00a7I[200~pip freeze > requirements. txt~\n> OUTLINE zsh: bad pattern: *[[200~pip Message Bhuvan\n$03 @ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % pip freeze > requirements.txt\n> TIMELINE (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % = ofl \u00ae co\nmaint @\u00ae @O0AS5 Ln 102,Col68 Spaces:4 UTF-8 LF w\n\nvee\n\u2014 i a a = \u2014\n\n. ."
}