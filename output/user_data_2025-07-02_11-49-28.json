{
  "timestamp": "2025-07-02_11-49-28",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "git add README.md\ngit commit -m \"docs: complete README\"\ngit push",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# --- Gemini via LangChain (REST v1) ---\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\n# expose key for LangChain wrapper\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # must be in .env\n\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",          # free\u2011tier model\n    temperature=0.8,\n    convert_system_message_to_human=True\n)\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n    mode: str = \"normal\"   # \"normal\" | \"apology\"\n\nclass EmergencyRequest(BaseModel):\n    number: str\n    message: str\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    style_clause = (\n        \"Respond in a guilt\u2011tripping, heartfelt apology tone.\"\n        if r.mode.lower() == \"apology\"\n        else \"Respond in a neutral, believable tone.\"\n    )\n    full_prompt = (\n        f\"{SYSTEM_PROMPT}\\nTone: {style_clause}\\n\"\n        f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    )\n    messages = [\n        SystemMessage(content=SYSTEM_PROMPT),\n        HumanMessage(content=full_prompt)\n    ]\n    response_text = llm(messages).content.strip()\n    # LangChain may wrap JSON in ``` blocks \u2013 strip them\n    if response_text.startswith(\"```\"):\n        response_text = response_text.strip(\"`\").lstrip(\"json\").strip()\n    out = json.loads(response_text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]\n\n# ---------- /emergency ----------\n@app.post(\"/emergency\")\ndef emergency(req: EmergencyRequest):\n    \"\"\"\n    Simulate sending an emergency SMS/call.\n    For the demo we just log the request and append an entry to history.json.\n    \"\"\"\n    entry = {\n        \"id\": f\"emergency-{int(time.time())}\",\n        \"ts\": time.time(),\n        \"excuse\": \"EMERGENCY TRIGGER\",\n        \"believability_score\": 1.0,\n        \"chat_log\": f\"Sent '{req.message}' to {req.number}\"\n    }\n    history = json.loads(DATA.read_text())\n    history.append(entry)\n    DATA.write_text(json.dumps(history, indent=2))\n    return {\"status\": \"sent\", \"to\": req.number, \"msg\": req.message}",
  "ocr_text": "@ Code File Edit Selection View Go Run Terminal Window Help 6 8 \u00a90D S srg F Q SBS \u00a9 WedJul2 11:49AM\n= List of research @ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence | Al-05-BBLEN4 \u00a9 Openal coy API keys - Open/ [G) Gemini API refers * Get API key | G X\n- > C @ O & \u00a9 aistudio.google.com/apikey Pad os+ox @ =\n\no\nS\n\n\u00a9\n\nGoogle Al Studio\n\nIntelligent Excuse Generator Plan >\n\nBhuvan\n\n2\n\nEXPLORER\n\n\\Y EXCUSE-GENERATOR\n\nP > __pycache__\nv .venv\n> bin\n\u2018wie > include\n> lib\n\ni>\n8\n\n .env\n\n\u00a9 pyvenv.cfg\n\n@ excuse_api.py\n\n{} history.json\n\nA\n\n@ README.md\n\n= requirements.txt\n\n> OUTLINE\n\n@\naD > TIMELINE\nf maint O\n\nView status\n\n@0A5\n\n\u20ac 5\n\n@ excuse_api.py5 X  {} history.json @ README.md\n\n\u00ae excuse_api.py > @ emergency\n\nPP excuse-generator\n\n .env\n\nreturn \"status\": \"sent\", \"to\": req. number, \"msg\": req.message}\n\nU\n\n87 def emergency(req: EmergencyRequest) :\n100 history.append(entry)\n101 DATA.write_text(json.dumps(history, indent=2) )\n102\nPROBLEMS e OUTPUT DEBUG CONSOLE TERMINAL PORTS\nINFO: Finished server process [8189]\nINFO: Stopping reloader process [8187]\n\n\u00ae (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % (JI[200~pip\n\nzsh: bad pattern: *[[200~pip\n\n(.venv) bhuvanarora@Bhuvans\u2014MacBook-Pro\n(.venv) bhuvanarora@Bhuvans\u2014MacBook-Pro\n(.venv) bhuvanarora@Bhuvans\u2014MacBook-Pro\n(.venv) bhuvanarora@Bhuvans\u2014MacBook-Pro\n(.venv) bhuvanarora@Bhuvans\u2014MacBook-Pro\norigin\norigin\n@ (.venv)\n\nexcuse-generator % pip\nexcuse-generator % git\nexcuse-generator % git\nexcuse-generator % git\nexcuse-generator % git\nhttps://github. com/Bhuvan-Arora-1313/excuse-generator.git (fetch)\n\nhttps://github. com/Bhuvan-Arora-1313/excuse-generator.git (push)\n\nbhuvanarora@Bhuvans-MacBook-Pro excuse-generator % git add excuse_api.py requirements.txt README.md history.json\n\nfreeze\nconfig\nconfig\nremote\nremote\n\nfreeze > requirements.txt~\n\n> requirements.txt\n--global user.name \u201cBhuvan Arora\"\n--global user.email \u201cbhuvanaro123@gmail.com\"\n\nadd origin https://github. com/Bhuvan-Arora-1313/excuse-generator.git\n\n-v\n\ngit commit -m \"feat: complete Excuse Generator API (generate, top, emergency)\"\n[main (root-commit) abc2b5d] feat: complete Excuse Generator API (generate, top, emergency)\n\n4 files changed, 204 insertions(+)\n\ncreate mode 100644 README.md\n\ncreate mode 100644 excuse_api.py\n\ncreate mode 100644 history.json\n\ncreate mode 100644 requirements.txt\n\n@ (.venv) bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator\n\nEnumerating objects: 6, done.\nCounting objects: 100% (6/6), done.\nDelta compression using up to 8 threads\nCompressing objects: 100% (6/6), done.\n\nWriting objects: 100% (6/6), 3.28 KiB | 3.28 MiB/s, done.\n\nTotal 6 (delta @), reused @ (delta @), pack-reused 0\n\nTo https://github. com/Bhuvan-Arora-1313/excuse-generator.\n\n* [new branch] main -> main\nbranch 'main' set up to track \u2018origin/main'.\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator\ngit commit -m \u201cdocs: complete README\"\ngit push\n[main 98d2b2a] docs: complete README\n1 file changed, 37 insertions(+), 10 deletions(-)\nEnumerating objects: 5, done.\nCounting objects: 100% (5/5), done.\nDelta compression using up to 8 threads\nCompressing objects: 100% (3/3), done.\n\nWriting objects: 100% (3/3), 1.05 KiB | 1.05 MiB/s, done.\n\nTotal 3 (delta @), reused @ (delta @), pack-reused 0\n\nTo https://github. com/Bhuvan-Arora-1313/excuse-generator.\n\nabc2b5d..98d2b2a main -> main\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator\n\nRemember to use API keys securely. Don't share or embed them in public code. |\n\n. . .\n\n% git push -u origin main\n\ngit\n\n% git add README.md\n\ngit\n\n*O\n\n> Bhuvan Arora (20 minutes ago) Q\n\nar ww)\n\nse20\n\nLn 102, Col43  Spaces:4 UTF-8 LF\n\n( Python @ 3.13.2 64-bit\n\n. . .\n\nial\n\nmode to /generate\"\n\nnecklist\u2014under 10 lines of code and no new dependencies.\n\nario}\\nUrgency: {r.urgency}\"\nPT}\\nScenario: {r.scenario}\\nUrgency:\n\noping, heartfei v apology tone.\"\n\npleae edit in vs\n\nReview  \u00a7& Apply\n\nfa)\n\n{r.urgency}\"\n\nco}"
}