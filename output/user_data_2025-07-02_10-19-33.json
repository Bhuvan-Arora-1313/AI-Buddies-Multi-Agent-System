{
  "timestamp": "2025-07-02_10-19-33",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "import google.generativeai as genai\n+genai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\n+model = genai.GenerativeModel(\"gemini-pro\")",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ Code File Edit Selection View Go Run Terminal Window\u2019 Help 6 \u00a38 \u00a9GD O S wz F Q S \u00a9 Wed Jul2 10:19AM\n\n= List of research @ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence [| Al-05-BBLEN4 \u00a9 OpenAl coy API keys - Open/ (S) Gemini API refer +\u201d Get API key | GX\no<erca O & \u00ae aistudio.google.com/apikey Intelligent Excuse Generator Plan > y=\nBhuvan\n0e@e0@ <> PP excuse-generator By Cob WwW\nS SSS 3 Add your Gemini key .\nEXPLORER oe J Welcome \u00ae excuse_api.py 5,U @  .env U Dy &% vee\n[a]\nra) | a\n\\ EXCUSE-GENERATOR \u00ae excuse_api.py >... 1. Get a free key at https://aistudio.google.com > API keys > Create.\n(\u00a9) {> \u2014Pycache_ 5 load_dotenv() # \u2014 NEW: pulls OPENAI_API_KEY from .env\nVv venv q 4 2. Open\u2014or create\u2014your local . env and add a new line:\n\u00bb 5 oh from fastapi import FastAPI ee y\n> include 7 from pydantic import BaseModel \u00ae Copy\n> a 8 import google.generativeai as genai\n\u00a9 pyvenv.cfg U IIIA DALAL AAA LALLA ALL ALAA u u\nony u 9 +genai.configure(api_key=os.getenv(\"GEMINI_KEY\") ) GEMINI_KEY=AI-XXXXXXXXXXXXXXXXXXXXXXXX\nFS @ excuse_apipy 5,U 1@ +model = genai.GenerativeModel(\"gemini-pro\") |\nW Lisieiay Sem v 11 (keep OPENAI_API_KEY-.. too; it won't be used but no harm in keeping it)\nA = requirements.txt U . 7 \u00bb\nW200 GP s==Sseeees simple \u201cDB\u201d ---------\u2014\n13 DATA = Path(\"history. json\")\n14 if not DATA.exists(): , ,\n: van ; 4 Edit excuse_api.py\n15 DATA.write_text(\"[]\") # seed empty list\nPROBLEMS @) OUTPUT DEBUGCONSOLE TERMINAL PORTS tye A xX\n. Replace the OpenAl block with Gemini.\nRequirement already satisfied: typing-inspection>=0.4.@ in ./.venv/lib/python3.11/site-packages (from pydantic->goog 2-] zsh\nle-generativeai) (@.4.1) u all i: i Hi :\nBEE Cor CoE ETIAK-O-AGmE-aONeMeRi (0B Co o\u00ae Bzsh Here's the minimal diff (copy exactly what's between the lines):\nDownloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\nSS 1.3/1.3 MB 3.9 MB/s eta 0:00:00 .\nUsing cached google_api_core-2.25.1-py3-none-any.whl (160 kB) diff oO Copy\nUsing cached google_auth-2.4@.3-py2.py3-none-any.whl (216 kB)\nUsing cached cachetools-5.5.2\u2014py3-none-any.whl (1@ kB) b\nUsing cached googleapis_common_protos-1.70.@-py3-none-any.whl (294 kB) (cle)\nUsing cached grpcio-1.73.1-cp311-cp311-macosx_11_@_universal2.whl (10.6 MB) .\nDownloading grpcio_status-1.71.2-py3-none-any.whl (14 kB) -from openai import OpenAI\nUsing cached proto_plus-1.26.1-py3-none-any.whl (5@ kB) a g - 9 _ \" \"\nDownloading protobuf-5.29.5-cp38-abi3-macosx_10_9 _universal2.whl (418 kB) client = OpenAI(api_key=os.getenv( \"OPENAI_API_KEY ))\nUsing cached requests-2.32.4\u2014py3-none-any.whl (64 kB) b +import google.generativeai as genal\nUsing cached charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl (198 kB) 4 5 o = \" u\nTSS) Cechce) Gene NEE noREmenv chin (OS COR +genai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\nUsing cached urllib3-2.5.0-py3-none-any.whl (129 kB) +model = genai.GenerativeModel(\"gemini-pro\")\nUsing cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\nUsing cached pyasn1_modules-@.4.2-py3-none-any.whl (181 kB)\nDownloading google_api_python_client-2.174.@-py3-none-any.whl (13.7 MB)\n\u2014\u2014\u2014\u2014\u2014\u2014_ 13.7/13.7 MB 10.2 MB/s eta 0:00:00 Eo and further down, swap the LLM call:\nUsing cached google_auth_httplib2-0.2.@\u2014-py2.py3-none-any.whl (9.3 kB) re\nUsing cached httplib2-0.22.@\u2014py3-none-any.whl (96 kB)\nUsing cached pyparsing-3.2.3-py3-none-any.whl (111 kB) i:\nUsing cached uritemplate-4.2.@-py3-none-any.whl (11 kB) diff ay Copy\nInstalling collected packages: urllib3, uritemplate, pyparsing, pyasni, protobuf, grpcio, charset_normalizer, cachet\nools, rsa, requests, pyasni-modules, proto-plus, httplib2, googleapis\u2014-common-protos, grpcio-status, google-auth, goo . . |\n@ gle-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai ' - res = client.chat.completions.create(\nSuccessfully installed cachetools-5.5.2 charset_normalizer-3.4.2 google-ai-generativelanguage-0.6.15 google-api-core del=\" t-4 sea\n-2.25.1 google-api-python-client-2.174.@ google-auth-2.4@.3 google-auth-httplib2-0.2.@ google-generativeai-0@.8.5 goo a model=\"gpt\u201440-minl\u201d,\n> OUTLINE gleapis\u2014common-protos-1.70.@ grpcio-1.73.1 grpcio-status-1.71.2 httplib2-0.22.@ proto-plus-1.26.1 protobuf-5.29.5 py - messages=[ v\n$03 asn1-@.6.1 pyasni-modules-0.4.2 pyparsing-3.2.3 requests-2.32.4 rsa-4.9.1 uritemplate-4.2.@ urllib3-2.5.@ ru Ian \" ; \" everc ppnvpTi\n> TIMELINE (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % []\nWE & mains @ @0A5 Q Ln10,Col45 Spaces:4 UTF-8 LF {} Python @ 3.13.264-bit (@\n: = \u2014 : = Message Bhuvan\na)\n= + @& \u00a2 @\noy file.pdf ITRV (1).pdf ITRV.pdf JETIR2101184 Iko to mtj Iko to MTJ (1).pdf =\u2018 Iko to MTJ-5.-=: wee rere Ser oes wer eerere eres re ee\n\nS800eEGE820 \u00a9O8F\u00b010 &*"
}