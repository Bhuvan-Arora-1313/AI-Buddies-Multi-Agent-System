{
  "timestamp": "2025-07-02_10-55-56",
  "active_window": "ChatGPT",
  "focused_text": "import json\nimport time\nimport os\nfrom typing import Dict, Any, List\nimport subprocess\nimport signal\n\n# Import Google Gemini\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Google Gemini API key setup\nimport os\n\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # Set this externally\n\n# Initialize Google Gemini LLM\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",\n    temperature=0.3,\n    convert_system_message_to_human=True\n)\n\n\ndef read_latest_user_data() -> Dict[str, Any]:\n    \"\"\"Read the latest user data from live_output.json\"\"\"\n    try:\n        with open(\"output/live_output.json\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return {}\n    except json.JSONDecodeError:\n        return {}\n\n\ndef read_user_data_file(filename: str) -> Dict[str, Any]:\n    \"\"\"Read a specific user data file\"\"\"\n    try:\n        with open(f\"output/{filename}\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return {}\n    except json.JSONDecodeError:\n        return {}\n\n\ndef get_all_user_data_files() -> List[str]:\n    \"\"\"Get list of all user data files in output directory\"\"\"\n    try:\n        files = [f for f in os.listdir(\"output\") if f.startswith(\"user_data_\") and f.endswith(\".json\")]\n        return sorted(files)\n    except FileNotFoundError:\n        return []\n\n\ndef analyze_user_activity_from_json(user_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Analyze user data from JSON to determine what the user is doing\n    Returns JSON format with activity classification\n    \"\"\"\n    if not user_data:\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": \"No user data available\",\n            \"timestamp\": time.time()\n        }\n\n    # Extract relevant information from user data\n    active_window = user_data.get(\"active_window\", \"\")\n    focused_text = user_data.get(\"focused_text\", \"\")\n    clipboard_content = user_data.get(\"clipboard\", \"\")\n    # vscode_text = user_data.get(\"vscode_text\", \"\")\n    ocr_text = user_data.get(\"ocr_text\", \"\")\n    timestamp = user_data.get(\"timestamp\", \"\")\n\n    # Combine all text sources for analysis\n    #     combined_text = f\"\"\"\n    # Active Window: {active_window}\n    # Focused Text: {focused_text}\n    # Clipboard: {clipboard_content}\n    # VS Code Text: {vscode_text}\n    # Screen OCR: {ocr_text}\n    #     \"\"\".strip()\n    combined_text = f\"\"\"\nActive Window: {active_window}\nFocused Text: {focused_text}\nClipboard: {clipboard_content}\nScreen OCR: {ocr_text}\n    \"\"\".strip()\n\n    if not combined_text or combined_text.strip() == \"\":\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": \"No meaningful text data available\",\n            \"timestamp\": time.time()\n        }\n\n    system_prompt = \"\"\"You are an AI assistant that analyzes user activity data to determine what the user is currently doing. \n\n    You have access to multiple data sources:\n    - Active Window: The currently active application\n    - Focused Text: Text from the focused element\n    - Clipboard: Content in the clipboard\n    - VS Code Text: Text from VS Code editor (if available)\n    - Screen OCR: Text extracted from screen capture\n\n    Analyze this data and classify the user's activity into one of these categories:\n    - coding: Writing, editing, or reviewing code (Python, JavaScript, etc.)\n    - researching: Reading articles, papers, documentation, or searching for information\n    - browsing: General web browsing, social media, or casual internet use\n    - emailing: Composing, reading, or managing emails\n    - messaging: Using chat applications, messaging apps, or communication tools\n    - gaming: Playing video games or game-related activities\n    - watching: Watching videos, streams, or multimedia content\n    - writing: Writing documents, notes, or creative content\n    - designing: Working on design, graphics, or creative projects\n    - working: General work activities not covered by other categories\n    - unknown: Unable to determine the activity\n\n    Consider the following patterns:\n    - Coding: Look for code syntax, function definitions, imports, IDE elements\n    - Messaging: Look for chat interfaces, message bubbles, contact names\n    - Researching: Look for articles, documentation, search results\n    - Browsing: Look for web browser elements, URLs, navigation\n\n    Return your response in valid JSON format with these fields:\n    - activity: The classified activity (string)\n    - confidence: Confidence level 0.0-1.0 (float)\n    - description: Brief description of what you observed (string)\n    - details: Additional context or specific tools/applications detected (string)\n    - data_sources: Which data sources were most useful for classification (string)\n    - timestamp: Current timestamp (float)\n\n    Example response:\n    {\n        \"activity\": \"coding\",\n        \"confidence\": 0.85,\n        \"description\": \"User appears to be writing Python code in Cursor IDE\",\n        \"details\": \"Detected Python imports, function definitions, and Cursor IDE interface\",\n        \"data_sources\": \"VS Code text and active window\",\n        \"timestamp\": 1234567890.123\n    }\n\n    Only return valid JSON, no additional text.\"\"\"\n\n    human_prompt = f\"Here's the user activity data to analyze:\\n\\n{combined_text}\\n\\nPlease analyze this data and determine what the user is doing.\"\n\n    try:\n        messages = [\n            SystemMessage(content=system_prompt),\n            HumanMessage(content=human_prompt)\n        ]\n\n        response = llm(messages)\n        response_text = response.content.strip()\n\n        # Try to parse the JSON response\n        try:\n            # Handle markdown-wrapped JSON responses\n            if response_text.startswith(\"```json\") and response_text.endswith(\"```\"):\n                # Extract JSON from markdown code blocks\n                json_start = response_text.find(\"```json\") + 7\n                json_end = response_text.rfind(\"```\")\n                if json_start < json_end:\n                    response_text = response_text[json_start:json_end].strip()\n            elif response_text.startswith(\"```\") and response_text.endswith(\"```\"):\n                # Extract JSON from generic code blocks\n                json_start = response_text.find(\"```\") + 3\n                json_end = response_text.rfind(\"```\")\n                if json_start < json_end:\n                    response_text = response_text[json_start:json_end].strip()\n\n            result = json.loads(response_text)\n            # Ensure timestamp is current\n            result[\"timestamp\"] = time.time()\n            return result\n        except json.JSONDecodeError:\n            # Fallback if JSON parsing fails\n            return {\n                \"activity\": \"unknown\",\n                \"confidence\": 0.0,\n                \"description\": \"Failed to parse LLM response\",\n                \"details\": response_text,\n                \"data_sources\": \"LLM response parsing failed\",\n                \"timestamp\": time.time()\n            }\n\n    except Exception as e:\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": f\"Error analyzing user data: {str(e)}\",\n            \"details\": \"\",\n            \"data_sources\": \"Error occurred during analysis\",\n            \"timestamp\": time.time()\n        }\n\n\ndef analyze_historical_data(num_files: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"Analyze the most recent user data files\"\"\"\n    files = get_all_user_data_files()\n    if not files:\n        return []\n\n    # Get the most recent files\n    recent_files = files[-num_files:] if len(files) > num_files else files\n    results = []\n\n    for filename in recent_files:\n        user_data = read_user_data_file(filename)\n        if user_data:\n            analysis = analyze_user_activity_from_json(user_data)\n            analysis[\"source_file\"] = filename\n            results.append(analysis)\n\n    return results\n\n\ndef main():\n    \"\"\"Main function to continuously monitor and analyze user activity\"\"\"\n    print(\"\ud83d\udd0d User Activity Monitor Started\")\n    print(\"Using Google Gemini LLM for activity analysis\")\n    print(\"Analyzing data from gatheruserdata.py JSON files\")\n    print(\"Press Ctrl+C to stop\\n\")\n\n    # Start gatheruserdata.py as a subprocess\n    gather_proc = subprocess.Popen([\n        \"python\", \"gatheruserdata.py\"\n    ])\n    print(\"\ud83d\ude80 Started gatheruserdata.py in the background (PID: {}), collecting user data...\".format(gather_proc.pid))\n\n    try:\n        last_timestamp = None\n        while True:\n            print(\"\ud83d\udcca Reading latest user data...\")\n            user_data = read_latest_user_data()\n\n            # Only analyze if new data is available\n            if user_data and user_data.get(\"timestamp\") != last_timestamp:\n                last_timestamp = user_data.get(\"timestamp\")\n                print(\"\ud83e\udd16 Analyzing user activity from JSON data...\")\n                result = analyze_user_activity_from_json(user_data)\n                # Pretty print the JSON result\n                print(\"\ud83d\udcca Activity Analysis:\")\n                print(json.dumps(result, indent=2))\n                try:\n                    with open(\"output/prediction_output.json\", \"w\", encoding=\"utf-8\") as f:\n                        json.dump(result, f, indent=2)\n                except Exception as e:\n                    print(f\"\u274c Failed to save prediction output: {e}\")\n                print(\"=\" * 60)\n            else:\n                print(\"\u23f3 Waiting for new user data...\")\n\n            # Wait before next check\n            time.sleep(5)\n\n    except KeyboardInterrupt:\n        print(\"\\n\ud83d\udc4b Activity monitor stopped by user\")\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n    finally:\n        print(\"\ud83d\uded1 Terminating gatheruserdata.py subprocess...\")\n        gather_proc.terminate()\n        try:\n            gather_proc.wait(timeout=5)\n        except subprocess.TimeoutExpired:\n            gather_proc.kill()\n        print(\"\u2705 gatheruserdata.py stopped.\")\n\n\ndef analyze_single_file(filename: str):\n    \"\"\"Analyze a specific user data file\"\"\"\n    print(f\"\ud83d\udd0d Analyzing file: {filename}\")\n    user_data = read_user_data_file(filename)\n\n    if user_data:\n        result = analyze_user_activity_from_json(user_data)\n        print(\"\ud83d\udcca Activity Analysis:\")\n        print(json.dumps(result, indent=2))\n    else:\n        print(f\"\u274c Could not read file: {filename}\")\n\n\ndef analyze_recent_files(num_files: int = 5):\n    \"\"\"Analyze the most recent user data files\"\"\"\n    print(f\"\ud83d\udd0d Analyzing {num_files} most recent files...\")\n    results = analyze_historical_data(num_files)\n\n    for result in results:\n        print(f\"\\n\ud83d\udcc1 File: {result.get('source_file', 'Unknown')}\")\n        print(f\"\ud83c\udfaf Activity: {result.get('activity', 'Unknown')}\")\n        print(f\"\ud83d\udcc8 Confidence: {result.get('confidence', 0.0):.2f}\")\n        print(f\"\ud83d\udcdd Description: {result.get('description', 'No description')}\")\n        print(\"-\" * 40)\n\n\nif __name__ == \"__main__\":\n    import sys\n\n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"--file\" and len(sys.argv) > 2:\n            analyze_single_file(sys.argv[2])\n        elif sys.argv[1] == \"--recent\" and len(sys.argv) > 2:\n            analyze_recent_files(int(sys.argv[2]))\n        elif sys.argv[1] == \"--recent\":\n            analyze_recent_files()\n        else:\n            print(\"Usage:\")\n            print(\"  python activity_analyzer.py                    # Monitor live data\")\n            print(\"  python activity_analyzer.py --file <filename>  # Analyze specific file\")\n            print(\"  python activity_analyzer.py --recent [num]     # Analyze recent files\")\n    else:\n        main()  have alook at this this is my totally differnt project here also i had used gemini api",
  "clipboard": "import json\nimport time\nimport os\nfrom typing import Dict, Any, List\nimport subprocess\nimport signal\n\n# Import Google Gemini\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Google Gemini API key setup\nimport os\n\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # Set this externally\n\n# Initialize Google Gemini LLM\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",\n    temperature=0.3,\n    convert_system_message_to_human=True\n)\n\n\ndef read_latest_user_data() -> Dict[str, Any]:\n    \"\"\"Read the latest user data from live_output.json\"\"\"\n    try:\n        with open(\"output/live_output.json\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return {}\n    except json.JSONDecodeError:\n        return {}\n\n\ndef read_user_data_file(filename: str) -> Dict[str, Any]:\n    \"\"\"Read a specific user data file\"\"\"\n    try:\n        with open(f\"output/{filename}\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return {}\n    except json.JSONDecodeError:\n        return {}\n\n\ndef get_all_user_data_files() -> List[str]:\n    \"\"\"Get list of all user data files in output directory\"\"\"\n    try:\n        files = [f for f in os.listdir(\"output\") if f.startswith(\"user_data_\") and f.endswith(\".json\")]\n        return sorted(files)\n    except FileNotFoundError:\n        return []\n\n\ndef analyze_user_activity_from_json(user_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Analyze user data from JSON to determine what the user is doing\n    Returns JSON format with activity classification\n    \"\"\"\n    if not user_data:\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": \"No user data available\",\n            \"timestamp\": time.time()\n        }\n\n    # Extract relevant information from user data\n    active_window = user_data.get(\"active_window\", \"\")\n    focused_text = user_data.get(\"focused_text\", \"\")\n    clipboard_content = user_data.get(\"clipboard\", \"\")\n    # vscode_text = user_data.get(\"vscode_text\", \"\")\n    ocr_text = user_data.get(\"ocr_text\", \"\")\n    timestamp = user_data.get(\"timestamp\", \"\")\n\n    # Combine all text sources for analysis\n    #     combined_text = f\"\"\"\n    # Active Window: {active_window}\n    # Focused Text: {focused_text}\n    # Clipboard: {clipboard_content}\n    # VS Code Text: {vscode_text}\n    # Screen OCR: {ocr_text}\n    #     \"\"\".strip()\n    combined_text = f\"\"\"\nActive Window: {active_window}\nFocused Text: {focused_text}\nClipboard: {clipboard_content}\nScreen OCR: {ocr_text}\n    \"\"\".strip()\n\n    if not combined_text or combined_text.strip() == \"\":\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": \"No meaningful text data available\",\n            \"timestamp\": time.time()\n        }\n\n    system_prompt = \"\"\"You are an AI assistant that analyzes user activity data to determine what the user is currently doing. \n\n    You have access to multiple data sources:\n    - Active Window: The currently active application\n    - Focused Text: Text from the focused element\n    - Clipboard: Content in the clipboard\n    - VS Code Text: Text from VS Code editor (if available)\n    - Screen OCR: Text extracted from screen capture\n\n    Analyze this data and classify the user's activity into one of these categories:\n    - coding: Writing, editing, or reviewing code (Python, JavaScript, etc.)\n    - researching: Reading articles, papers, documentation, or searching for information\n    - browsing: General web browsing, social media, or casual internet use\n    - emailing: Composing, reading, or managing emails\n    - messaging: Using chat applications, messaging apps, or communication tools\n    - gaming: Playing video games or game-related activities\n    - watching: Watching videos, streams, or multimedia content\n    - writing: Writing documents, notes, or creative content\n    - designing: Working on design, graphics, or creative projects\n    - working: General work activities not covered by other categories\n    - unknown: Unable to determine the activity\n\n    Consider the following patterns:\n    - Coding: Look for code syntax, function definitions, imports, IDE elements\n    - Messaging: Look for chat interfaces, message bubbles, contact names\n    - Researching: Look for articles, documentation, search results\n    - Browsing: Look for web browser elements, URLs, navigation\n\n    Return your response in valid JSON format with these fields:\n    - activity: The classified activity (string)\n    - confidence: Confidence level 0.0-1.0 (float)\n    - description: Brief description of what you observed (string)\n    - details: Additional context or specific tools/applications detected (string)\n    - data_sources: Which data sources were most useful for classification (string)\n    - timestamp: Current timestamp (float)\n\n    Example response:\n    {\n        \"activity\": \"coding\",\n        \"confidence\": 0.85,\n        \"description\": \"User appears to be writing Python code in Cursor IDE\",\n        \"details\": \"Detected Python imports, function definitions, and Cursor IDE interface\",\n        \"data_sources\": \"VS Code text and active window\",\n        \"timestamp\": 1234567890.123\n    }\n\n    Only return valid JSON, no additional text.\"\"\"\n\n    human_prompt = f\"Here's the user activity data to analyze:\\n\\n{combined_text}\\n\\nPlease analyze this data and determine what the user is doing.\"\n\n    try:\n        messages = [\n            SystemMessage(content=system_prompt),\n            HumanMessage(content=human_prompt)\n        ]\n\n        response = llm(messages)\n        response_text = response.content.strip()\n\n        # Try to parse the JSON response\n        try:\n            # Handle markdown-wrapped JSON responses\n            if response_text.startswith(\"```json\") and response_text.endswith(\"```\"):\n                # Extract JSON from markdown code blocks\n                json_start = response_text.find(\"```json\") + 7\n                json_end = response_text.rfind(\"```\")\n                if json_start < json_end:\n                    response_text = response_text[json_start:json_end].strip()\n            elif response_text.startswith(\"```\") and response_text.endswith(\"```\"):\n                # Extract JSON from generic code blocks\n                json_start = response_text.find(\"```\") + 3\n                json_end = response_text.rfind(\"```\")\n                if json_start < json_end:\n                    response_text = response_text[json_start:json_end].strip()\n\n            result = json.loads(response_text)\n            # Ensure timestamp is current\n            result[\"timestamp\"] = time.time()\n            return result\n        except json.JSONDecodeError:\n            # Fallback if JSON parsing fails\n            return {\n                \"activity\": \"unknown\",\n                \"confidence\": 0.0,\n                \"description\": \"Failed to parse LLM response\",\n                \"details\": response_text,\n                \"data_sources\": \"LLM response parsing failed\",\n                \"timestamp\": time.time()\n            }\n\n    except Exception as e:\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": f\"Error analyzing user data: {str(e)}\",\n            \"details\": \"\",\n            \"data_sources\": \"Error occurred during analysis\",\n            \"timestamp\": time.time()\n        }\n\n\ndef analyze_historical_data(num_files: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"Analyze the most recent user data files\"\"\"\n    files = get_all_user_data_files()\n    if not files:\n        return []\n\n    # Get the most recent files\n    recent_files = files[-num_files:] if len(files) > num_files else files\n    results = []\n\n    for filename in recent_files:\n        user_data = read_user_data_file(filename)\n        if user_data:\n            analysis = analyze_user_activity_from_json(user_data)\n            analysis[\"source_file\"] = filename\n            results.append(analysis)\n\n    return results\n\n\ndef main():\n    \"\"\"Main function to continuously monitor and analyze user activity\"\"\"\n    print(\"\ud83d\udd0d User Activity Monitor Started\")\n    print(\"Using Google Gemini LLM for activity analysis\")\n    print(\"Analyzing data from gatheruserdata.py JSON files\")\n    print(\"Press Ctrl+C to stop\\n\")\n\n    # Start gatheruserdata.py as a subprocess\n    gather_proc = subprocess.Popen([\n        \"python\", \"gatheruserdata.py\"\n    ])\n    print(\"\ud83d\ude80 Started gatheruserdata.py in the background (PID: {}), collecting user data...\".format(gather_proc.pid))\n\n    try:\n        last_timestamp = None\n        while True:\n            print(\"\ud83d\udcca Reading latest user data...\")\n            user_data = read_latest_user_data()\n\n            # Only analyze if new data is available\n            if user_data and user_data.get(\"timestamp\") != last_timestamp:\n                last_timestamp = user_data.get(\"timestamp\")\n                print(\"\ud83e\udd16 Analyzing user activity from JSON data...\")\n                result = analyze_user_activity_from_json(user_data)\n                # Pretty print the JSON result\n                print(\"\ud83d\udcca Activity Analysis:\")\n                print(json.dumps(result, indent=2))\n                try:\n                    with open(\"output/prediction_output.json\", \"w\", encoding=\"utf-8\") as f:\n                        json.dump(result, f, indent=2)\n                except Exception as e:\n                    print(f\"\u274c Failed to save prediction output: {e}\")\n                print(\"=\" * 60)\n            else:\n                print(\"\u23f3 Waiting for new user data...\")\n\n            # Wait before next check\n            time.sleep(5)\n\n    except KeyboardInterrupt:\n        print(\"\\n\ud83d\udc4b Activity monitor stopped by user\")\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n    finally:\n        print(\"\ud83d\uded1 Terminating gatheruserdata.py subprocess...\")\n        gather_proc.terminate()\n        try:\n            gather_proc.wait(timeout=5)\n        except subprocess.TimeoutExpired:\n            gather_proc.kill()\n        print(\"\u2705 gatheruserdata.py stopped.\")\n\n\ndef analyze_single_file(filename: str):\n    \"\"\"Analyze a specific user data file\"\"\"\n    print(f\"\ud83d\udd0d Analyzing file: {filename}\")\n    user_data = read_user_data_file(filename)\n\n    if user_data:\n        result = analyze_user_activity_from_json(user_data)\n        print(\"\ud83d\udcca Activity Analysis:\")\n        print(json.dumps(result, indent=2))\n    else:\n        print(f\"\u274c Could not read file: {filename}\")\n\n\ndef analyze_recent_files(num_files: int = 5):\n    \"\"\"Analyze the most recent user data files\"\"\"\n    print(f\"\ud83d\udd0d Analyzing {num_files} most recent files...\")\n    results = analyze_historical_data(num_files)\n\n    for result in results:\n        print(f\"\\n\ud83d\udcc1 File: {result.get('source_file', 'Unknown')}\")\n        print(f\"\ud83c\udfaf Activity: {result.get('activity', 'Unknown')}\")\n        print(f\"\ud83d\udcc8 Confidence: {result.get('confidence', 0.0):.2f}\")\n        print(f\"\ud83d\udcdd Description: {result.get('description', 'No description')}\")\n        print(\"-\" * 40)\n\n\nif __name__ == \"__main__\":\n    import sys\n\n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"--file\" and len(sys.argv) > 2:\n            analyze_single_file(sys.argv[2])\n        elif sys.argv[1] == \"--recent\" and len(sys.argv) > 2:\n            analyze_recent_files(int(sys.argv[2]))\n        elif sys.argv[1] == \"--recent\":\n            analyze_recent_files()\n        else:\n            print(\"Usage:\")\n            print(\"  python activity_analyzer.py                    # Monitor live data\")\n            print(\"  python activity_analyzer.py --file <filename>  # Analyze specific file\")\n            print(\"  python activity_analyzer.py --recent [num]     # Analyze recent files\")\n    else:\n        main() ",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content([full_prompt]).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "a\n\nOw \u00ae 0\n\nChatGPT File Edit View Window\u2019 Help 6 8 \u00a9D S 32%G) FF Q S \u00a9 Wed Jul2 10:55AM\n= z co co ca M @ iS) 6 \u00a9 9 Get API key | GX\n- > Ca O 8 = aistu\u2019\u2014\u2014\u2014+\u2014\u2014\u2014+- eee OG Intelligent Excuse Generator Plan > i\u2019 \u2014\nBhuvan\nuse:model =\nGoogle Al Studio PyCharm Q New | genai.GenerativeModel (\"gemini- BD\npro\")out =\n\u00a9 :\n| json.loads(model.generate_content(\n(o\u2014) ay ie omens ~~ | 20 Welcome Fikaris 8 EmTelcd) full_prompt).text)\n\\ EXCUSE-GENERATOR @ excuse_api.py +\nCustomize\n7. te > \u2014Pyeache_ def GB stealth-popup B Switch to an open-source model via 1.pip install openrouter (or pip No qu\na | Y ST Plugins . : . .\n\u00ae > fan 9 Hugging Face (zero Google setup) install requests).2. Sign up at confi\u00a2\n=> Ch > include Learn Pc PyCharmMiscProject huggingface.co > Settings > Access tokens HF tol\nlib\nae a 43 > New token (free).3. Replace the LLM call\npyvenv.cfg U\n_ env U PP PythonProject with a simple POST to the HF Inference\nCJ @ excuse_api.py 4, U endpoint for mistralai/Mistral-7B-\n{} history, uU at\nA = eeisen PROBLEMS @ Instruct\u2014v@. 2 (free community tier).4.\n= requirements.txt U\niy ala) (REDD Parse its JSON reply the same way.\nresult = co\nFile \"/Users/\nout = json.\nFile \"/Users/\n-py\", line 331,\nRAEN & If you choose Path A (enable v1)\nFile \"/Users/\nices/ t . .\na 1. Enable the v1 API as described above (takes < 2 min).\nFile \"/Users/ :\nline 131, in __ 2. Put the new key in . env. 0\nreturn wrap) Vv\nFile \"/Users/ 3. Inexcuse api.py use the simple model ID and string, not the list:\n, line 294, in\nreturn retr\noa \u00a9 excuse_api.py x\nFile \"/Users/\n, line 156, in elt sys.afQVL1] == \u201c--recent\u201d ana ten(sys.argy) > 2:\nnextEsLeep TEETER\nFile \"/Users/ . . eli 1] == \"--recent\":\nno aaa, tinal Take a quick onboarding tour ee, files()\nraise final \u2014 \u2014\nFile \"/Users/ else:\n, line 147, in ; \" a\nresult = ta Start Tour print(\"Usage: ) ae . . \"\n; print(\" python activity_analyzer.py # Monitor live data\")\nFe ed B print(\" python activity_analyzer.py --file <filename> # Analyze specific file\")\n\" \u201creturn func print(\" python activity _analyzer.py --recent [num] # Analyze recent files\")\n; a, - , , , else:\nFile \"/Users/bh / - tor/.venv/1ib/python3.11/site-packages/google/api_core/grpc_helpers.py\", . see . . . ee\n@ e 78, in eercelrcnappedicallas ek cumeaneeeananamammanaas asecaeaneaaeeaneaaeaaaaniamanaieaaeaaaamimaaaneamaanataaeal main() have alook at this this is my totally differnt project here also i had used gemini api i\nraise exceptions. from_grpc_error(exc) from exc\n> OUTLINE google.api_core.exceptions.NotFound: 404 models/gemini-pro is not found for API version vibeta, or is not supported k\n$03 for generateContent. Call ListModels to see the list of available models and their supported methods.\n> TIMELINE +@\u00ae 0 \u00b0\nView stat Wal % main* \u00ae@ @oA4 Q_ 1n43,Col36 Spaces:4 UTF-8 LF _() Python B 3.13.2 64- Ww Y\n\nS204eee2S \u00a98200 af\n\n. . . . . ."
}