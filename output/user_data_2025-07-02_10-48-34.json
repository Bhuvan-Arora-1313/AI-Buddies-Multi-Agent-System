{
  "timestamp": "2025-07-02_10-48-34",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": " File \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/runners.py\", line 190, in run\n    return runner.run(main)\n           ^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 71, in serve\n    await self._serve(sockets)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 78, in _serve\n    config.load()\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/config.py\", line 436, in load\n    self.loaded_app = import_from_string(self.app)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/importer.py\", line 19, in import_from_string\n    module = importlib.import_module(module_str)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 15, in <module>\n    print(\">>> model being used:\", model._name)\n                                  ^^^^^^^^^^^\nAttributeError: 'GenerativeModel' object has no attribute '_name'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"gemini-pro\")\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "Ow \u00ae 0\n\nChatGPT File Edit View Window\u2019 Help\n\n= List of research\n\n\u20ac7> C@ O B=\n\n2 aistudio.google.com/apikey\n\nGoogle Al Studio\n\n\u20ac 5 P\u00a3 excuse-generator Bot\noO EXPLORER J Welcome \u00ae excuse_api.py 4,U X % .env U Dy &%\n\u00a9 AP\nVv EXCUSE-GENERATOR @ excuse_api.py > ...\nP > __pycache__ 7\nih, Us: v .venv\n> bin 8\n= Ch oo > include 9 from fastapi import FastAPI\n| 2b 18 from pydantic import BaseModel\n& \u00a9 pyvenv.cfg U REED\n\u00a9 .env U all\nHS @ excuse_apipy 4, 12 import google.generativeai as genai\n{} history.json U 0 Oy The\nestoy) 13 genai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\nA = requirements.txt U . . hn . hn\n14 model = genai.GenerativeModel(\"gemini-pro\")\n15 #print(\">>> model being used:\", model._name)\n1@ Ff ===Saeeees simple \u201cDB\u201d ---------\u2014\n17 DATA = Path(\"history. json\")\n18 if not DATA.exists():\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS +yv\nreturn future. result() \u2018| >] pyth\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 71, in serve 2-] zsh\nawait self._serve(sockets)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 78, in _serv\ne\nconfig. load()\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/config.py\", line 436, in load\nself. loaded_app = import_from_string(self.app)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/importer.py\", line 19, in imp\u00ae\nort_from_string\nmodule = importlib. import_module(module_str)\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/importlib/__init__.py\", line 126, in import_module\nreturn _bootstrap._gcd_import(name[level:], package, level)\nFile \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\nFile \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\nFile \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\nFile \"<frozen importlib._bootstrap>\", line 69@, in _load_unlocked\nFile \"<frozen importlib._bootstrap_external>\", line 940, in exec_module af\nFile \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\nFile \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 15, in <module>\nprint(\">>> model being used:\", model._name)\n@ AttributeError: 'GenerativeModel' object has no attribute '_name'\nWARNING: StatReload detected changes in \u2018excuse_api.py'. Reloading...\nINFO: Started server process [3714]\n> OUTLINE INFO: Waiting for application startup.\n$03 INFO: Application startup complete.\n> TIMELINE\n\n* in* @ 0 4\nView stat Sau \u201d \"=\" 2\u00bb OOM\n\n# Artificial Intellige\n\nCO NLP_1.ipynb - Co CO NLP_1.ipynb - Cc BB Launcue Glot\n\n0)\n\na |\no\n\nM Launched - Artif\n\nArtificial_Intelligence\n\nQ n15,Col2 Spaces:4 UTF-8 LF {} Python & 3.13.2 64-\n\n6 \u20ac@ODB S we FQ BS\n\na] Al-05-BBLEN4 \u00a9 OpendAl coy API keys - Open. (G) Gemini API refer\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\nFile \"/Users/bhuvanarora/excuse-generator/\nexcuse_api.py\", line 15, in <module>\nprint(\">>> model being used:\", model._name)\n\nAAAARARADRAAN\n\n@ Wed Jul 2 10:48AM\n\n96 Get API key | G X\n\nAttributeError: 'GenerativeModel' object has no attribute\n\n\"_name'\n\nThought for a couple of seconds\n\nFound it\u2014the server is crashing before it even starts because the debug line tries to access a\n\nprivate attribute that doesn't exist in the current SDK:\n\npython\n\nprint(\">>> model being used:\", model._name)\n\nFix (5 seconds)\n\n1. Delete or comment out that line.\n\npython\n\n2. Restart Uvicorn cleanly:\nbash\n\nCtr1-C\n\nuvicorn excuse_api:app -\u2014-reload ay\n\u00a9 excuse_api.py x\nMessage Bhuvan\n\n+ @ &\n\n\u00a9) Copy\n\n\u00a9) Copy\n\n\u00a9) Copy\n\n=]"
}