{
  "timestamp": "2025-07-02_08-29-33",
  "active_window": "firefox",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "Smart Border Patrol Using Drones and Wireless Charging System Under Budget Limitation\n",
  "vscode_text": "<!DOCTYPE html>\n<html>\n  <body style=\"margin: 0; background: rgba(0,0,0,0.7); color: white; font-family: sans-serif;\">\n    <div style=\"-webkit-app-region: drag; padding: 10px; background: rgba(0,0,0,0.8);\">\n      <pre id=\"output\" style=\"white-space: pre-wrap; word-wrap: break-word;\">Waiting for data...</pre>\n    </div>\n    <script>\n      const { ipcRenderer } = require('electron');\n      ipcRenderer.on('update-prediction', (event, data) => {\n        document.getElementById('output').textContent = data;\n      });\n    </script>\n  </body>\n</html>",
  "ocr_text": "@ Firefox Edit View History Bookmarks Tools Window Help \u00a9 8 \u00a9oB0Os 4e\n\nee (ica = List of research papers - Google X A UAV patrol system using pano X * A UAV patrol system using par X Smart border patrol using drone X +\n\nC @ 0 8 sciencedirectassets.com\n\nen) A Vv \u2014 + 200%\n\n= to this category as well and combines YOLO\u2019s theory with detection anchors and fully convoluted networMgrienzet\nSera PCoES [16] augments the SSD detector with deconvoluted layers.\n\nobject detection Some object detectors with an end-to-end architecture are specifically developed for video detect\n\n{Introduction [25] which uses optical flow to aggregate object features, and T-CNN [19,20] which consists of multiple\n\nv 2 Related work . 5\ntemporal and contextual information.\n\noo : ime\noo -\n\nThickness\ne\n\n2.1 Image stitching\n\n2.2 Motion ghost Show all\n\nelimination 3. UAV patrol system\n\n2.3 Object detection\nVv 3 UAV patrol system\n3.1 System 3.1. System architecture\n\narchitecture\n\n3.2 Image stitching . . . . . . . . = * 3\n3.3 Motion ghost As is shown in Fig. 1, this UAV patrol system consists of a stitching and a detection module and takes a video as its input.\n\nelimination The stitching module uses selected frames from the video to generate a single image, which is then sent to the detection\n\n. \u201c ee module. The stitched image is dissected and labeled with scene types by the scene parsing layer. Together with the output\n\nparsing of the region proposal layer, the scene parsing result is sent to the scoring layer which produces the detection visualizations\n3.4.2 Quantifying as the final result. SPHP is employed as the stitching module, while the detection module is a combination of PSPNet and\n\nthe object-scene\nrelationship Faster R-CNN. In a real-world application, this system can function as a web server that accepts an uploaded video and\nstructure returns a stitched image with detection labels afterwards.\n\n4 Experiments\n\nv 4.1 Dataset and\n\nexperiment settings\n\n4.1.1 Dataset\nAle Sycalicas We adopt SPHP as the image stitching algorithm, which works at a simple principle while providing a good stitching\n\nti\n4.2 image stitching effect at a satisfactory speed. SPHP proposes a method that can smoothly transition from a projection transformation to\nevaluation an overlapping region and to a similar transformation in a non-overlapping region, thus creating naturally looking stitching\npao ool results. However, this works best for the stitching of static objects. For moving objects in the image sequences or video,\n\n4.4 Results motion residuals will appear in the stitched results, thus resulting in a bad visual experience.\n\n5 Conclusion\n\n3.2. Image stitching\n\nDeclaration of\n\nCompeting Interest 3.3. Motion ghost elimination\n\nReferences\n\nThe region growing method based on a difference image is an effective method for the removal of ghosts of moving\nobjects in stitched images. The difference image is obtained as the absolute value of pixel differences of two images after\n\nS8Q00eG820 O82 2"
}