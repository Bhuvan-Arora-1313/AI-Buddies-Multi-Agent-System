{
  "timestamp": "2025-07-02_10-41-02",
  "active_window": "ChatGPT",
  "focused_text": "let me tell u that i had already updated it to model",
  "clipboard": "python - <<'PY'\nimport os, dotenv, google.generativeai as genai, pathlib, sys\ndotenv.load_dotenv('.env', override=True)\n\nprint(\"SDK version  :\", genai.__version__)\nprint(\"API key prefix:\", os.getenv(\"GEMINI_KEY\")[:10] if os.getenv(\"GEMINI_KEY\") else \"MISSING\")\n\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\ntry:\n    print(\"\\nModels visible to this key:\")\n    for m in genai.list_models():\n        print(\"  \u2022\", m.name)\nexcept Exception as e:\n    print(\"\\n\u26a0\ufe0f  list_models() raised:\", e.__class__.__name__, e)\n    sys.exit(1)\nPY",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "6\n\no\nS\n\n\u00a9\n\nChatGPT File Edit View\n\n= List of research\n\nC2 GA\n\n| oO EXPLORER\n\n\\Y EXCUSE-GENERATOR\n\nP > __pycache__\n\nv venv\n> bin\noe > include\n> lib\nrod \u00a9 pyvenv.cfg\n\u00a9 .env\nHS @ excuse_api.py\n{} history.json\nA = requirements.txt\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nGE & maine @0A4\n\n4\n\nWindow Help\n\nU\nU\nU\nU\nU\n\n* Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Cc\n\nO @& = aistudio.google.com/apikey\n\ne=> PP excuse-generator\n\nx Welcome @ excuse_api.py 4,U X % .env U\n\n\u00ae excuse_api.py > \u00a9 generate\nS/o Ye \u2014===eSsSe= /generate \u2014-------\u2014-\u2014\n38 @app.post(\"/generate\")\n\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS.\n\nmodels/gemini- -1.5-flash-002\n\n5-flash-8b\n\n5-flash-8b-001\n5-flash-8b-Latest\n5-pro-preview-@3-25\n\n5-f lash-preview-04-17\n\n5-f lash-preview-05-20\n\n5-flash\n\n5-f lash-preview-04-17-thinking\n5-flash-lite-preview-@6-17\n5-pro-preview-@5-06\n5-pro-preview-@6-05\n\n5-pro\n\n@-flash-exp\n\n@-flash\n\nQ-flash-001\n\n@-f lash-exp-image-generation\nQ-flash-lite-001\n\nQ-flash-lite\n\nQ@-f lash-preview-image-generation\nQ@-flash-lite-preview-@2-05\nQ@-flash-lite-preview\n@-pro-exp\n\n@-pro-exp-02-05\n\nexp-1206\n\n@-f Lash-thinking-exp-1-21\n\n@-f Lash-thinking-exp\n\nQ@-f Lash-thinking-exp-1219\n5-flash-preview-tts\nmodels/gemini-2.5-pro-preview-tts\nmodels/learnlm-2.0-f lash-experimental\nmodels/gemma-3-1b-it\n\nmodels/gemma-3-4b-it\n\nmodels/gemma-3-12b-it\n\nmodels/gemma-3-27b-it\n\nmodels/gemma-3n-e4b-it\n\nmodels/gemma-3n-e2b-it\n\nmodels/embedding-001\n\nmodels/text-embedding-004\nmodels/gemini-embedding-exp-03-07\nmodels/gemini-embedding-exp\n\nmodels/aga\n\nmodels/imagen-3.@-generate-002\nmodels/imagen-4.@-generate-preview-06-06\nmodels/imagen-4. @-ultra-generate-preview-06-06\nmodels/veo-2.0-generate-001\n\nini-2.5-f lash-preview-nat ive-audio-dialog\n5-f Llash-exp-nat ive-audio-thinking-dialog\nQ-flash-live-001\nmodels/gemini-live-2.5-flash-preview\n\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % o\n\nLn 42, Col 63\n\nfile.pdf ITRV (1).pdf ITRV.pdf\n\nBB LAUNCHED Globe = M Launched - Artif\n\nSpaces: 4 UTF-8\n\nAIEUTIR EAI EY\n\n9%0) =\n\nG@ROTO8\n\nArtificial_Intelligence i] Al-05-BBLEN4 \u00a9 OpendAl o API keys - Open e Gemini API refer\n\nQs\n\n96 Get API key | GX\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\neco MO @G\n\nINVUGL \u2014 YCNGL-.-OCNECLALIVEMUUECL) MNUUCLS/ YoNLIIL~pLlu 7\n\nBOAT\nDy %\n\n(No second import or configure later in the file.)\n\na Save (38S / Ctrl S).\n\n+v ~ x\nI >.) zsh\nalee 2 Kill any old process and start fresh\n4 bash\n' Ctr1-C\npkill -f \"uvicorn.*excuse_api\" 2>/dev/null\n' uvicorn excuse_api:app --reload\n3 Test again\nbash\n1 .\ncurl -X POST http://127.0.0.1:8000/generate \\\n-H \"Content-Type: application/json\" \\\n-d '{\"scenario\":\"missed class\", \"urgency\":\"panic\"}'!\nPL\n\nYou should now receive a JSON block like:\n\njson\n\n\u00a9 excuse_api.py x\n\u00ae 3.13.264-bit\n\nlet me tell u that i had already updated it to model/\now\n\nIko to MTJ (1).pdf\n\nIko to MTJ-s~\n\nS80\u00b0G8880 e270 ae\n\n.\n\n\u00a9) Copy\n\n\u00a9) Copy\n\n\u00a9) Copy\n\n\u00a9\n>)\n\n@ Wed Jul 2 10:41AM"
}