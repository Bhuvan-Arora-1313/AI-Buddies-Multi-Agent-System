{
  "timestamp": "2025-07-02_10-47-42",
  "active_window": "ChatGPT",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "uvicorn excuse_api:app --reload",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"gemini-pro\")\nprint(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "Ow \u00ae 0\n\nChatGPT File Edit View\n\n= List of research\n\n\u20ac > C\n\nGoogle Al Studio\n\nEXPLORER\n[O\u2014) ay Oo\n\n\\Y EXCUSE-GENERATOR\n\nP > __pycache__\nih, Us: v .venv\n\npa > bin\n\u2014| Ch > include\n\n> lib\n>\n& \u00a9 pyvenv.cfg\n\nU\n\u00a9 .env U\nES @ excuse_api.py 4,U\nU\nU\n\n{} history.json\nA = requirements.txt\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n* in* @ 0 4\nView stat All men es ees\n\nWindow\n\n# Artificial Intellige\n\nJ Welcome\n\nHelp\n\nCO NLP_1.ipynb - Co CO NLP_1.ipynb - Cc BB Launcue Glot \u2122 Launched - Artif\n\nO @& = aistudio.google.com/apikey\n\neC => PP excuse-generator\n\n@ excuse_api.py 4,U X % .env U\n\n@ excuse_api.py > ...\n\n7\n8\n9 from fastapi import FastAPI\n\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS.\n\n# stop any uvicorn still running\n\nCtrl-C\n\npkill -f \u201cuvicorn.*excuse_api\" 2>/dev/null # just in case\nsource .venv/bin/activate # activate venv\n\nuvicorn excuse_api:app \u2014-reload\n\nACINFO: Stopping reloader process [2760]\n\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % pkill -f \u201cuvicorn.xexcuse_api\" 2>/dev/null\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % source .venv/bin/activate\n\n(.venv) bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % uvicorn excuse_api:app --reload\n\nINFO: Will watch for changes in these directories: ['/Users/bhuvanarora/excuse-generator']\n\nINFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n\nINFO: Started reloader process [3663] using StatReload\n\nProcess SpawnProcess-1:\n\nTraceback (most recent call last):\n\nap\nself.run()\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/multiprocessing/process.py\", line 108, in run\nself._target(*self._args, *kself._kwargs)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/_subprocess.py\", line 80, in\nsubprocess_started\ntarget (sockets=sockets)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 67, in run\nreturn asyncio.run(self.serve(sockets=sockets) )\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/runners.py\", line 190, in run\nreturn runner. run(main)\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/runners.py\", line 118, in run\nreturn self._loop. run_until_complete(task)\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_co\nmplete\nreturn future. result()\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 71, in serve\nawait self._serve(sockets)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/server.py\", line 78, in _serv\ne\nconfig. load()\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/config.py\", line 436, in load\nself. loaded_app = import_from_string(self.app)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/importer.py\", line 19, in imp\nort_from_string\nmodule = importlib. import_module(module_str)\n\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n\nQ  n14,Col32 Spaces:4 UTF-8 LF {} Python\n\nArtificial_Intelligence\n\n0\n\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstr\nt\n\n8 3.13.2 64\n\n\u00a9 fF OO 8\n\no API keys - Open\n\n240%) FQ ES\n\n(B al-05-BBLEN4 \u00a9 Openal \u00a9 Gemini API refer 96 Get API key | G X\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\neco MO @G\n\nYour FastAPI service will now run on Gemini's free tier without the 404.\nLet me know if any new traceback shows up\u2014otherwise you're all set!\n\n\u00e90 Ovad gy\n\nDy R\n\n-} pyth\u00a2\n>-| zsh\n\nThought for a couple of seconds\n\nThe traceback you see during Uvicorn startup means Python failed while importing your\nexcuse_api module \u2014 so the server never finished booting.\n\nWhat we still need\n\nScroll to the very bottom of that traceback (the last 8-10 lines) and copy the exact error\nmessage.\nTypical endings look like:\n\n+ ModuleNotFoundError: No module named 'google'\n+ json.decoder.JSONDecodeError: ...\n\n-ValueError: ...\n\nThat final line tells us precisely what to fix. V\n\n\u00a9 excuse_api.py x\nMessage Bhuvan\n+ \u00ae &\n\n@ Wed Jul 2 10:47AM"
}