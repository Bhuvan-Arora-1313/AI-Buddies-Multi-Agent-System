{
  "timestamp": "2025-07-02_10-24-15",
  "active_window": "ChatGPT",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"missed class\", \"urgency\":\"panic\"}'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"gemini-pro\")\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\n{prompt}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "Ow \u00ae 0\n\nChatGPT File Edit View\n\n= List of research\n\nC2 GA\n\nEXPLORER\n\n| \\Y EXCUSE-GENERATOR\n\nP > __pycache__\n\nv venv\n& > bin\n> include\n> lib\nae\n\n\u00a9 pyvenv.cfg U\n\u00a9 .env U\nES @ excuse_api.py 4,U\n\nU\nU\n\n{} history.json\nA = requirements.txt\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nGE & maine @0A4\n\nJ Welcome\n\nWindow Help\n\n* Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Cc ca LAUNCHED Glok \u2122 Launched - Artif\n\nO @& = aistudio.google.com/apikey\n\n< PP excuse-generator By\n\nArtificial_Intelligence\n\nG@ROTO8\n\n2%t)> FAQ BS\n\nBOO\n\n@ excuse_api.py 4,U X\n\nenv U Dy\n\n\u00ae excuse_api.py > \u00a9 generate\n\n33\n\n34 # ---------- /generate -\u2014------\u2014\u2014 x=\n\n35 @app.post(\"/generate\")\n36 def generate(r: Req):\n\n37 prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n38 full_prompt = f\"{SYSTEM_PROMPT}\\n{prompt}\"\n39 out = json. loads(model.generate_content(full_prompt) .text)\nan a cr\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS +yv AN\nFile \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 39, in generate r zlpyinong-1\nout = json. loads(model.generate_content(full_prompt) .text) >.) zsh\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/generativeai/generative_models\n-py\", line 331, in generate_content\nresponse = self._client.generate_content(\nFile \"/Users/bhuvanarora/excuse-generator/. venv/1ib/python3. 11/site-packages/google/ai/generativelanguage_' vibeta/s .\nervices/generative_service/client.py\", line 835, in generate_content\nresponse = rpc(\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method. py\",\nline 131, in __call__\nreturn wrapped_func(xargs, **kwargs)\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\"\n, line 294, in retry_wrapped_func\nreturn retry_target(\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1ib/python3.11/site-packages/google/api_core/retry/retry_unary.py\" |\n, line 156, in retry_target 4\n\nnext_sleep = I\n\n_retry_error_helper( t\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1ib/python3.11/site-packages/google/api_core/retry/retry_base. py\",\nline 214, in _retry_error_helper\nraise final_exc from source_exc\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\"\n, line 147, in retry_target 1\nresult = target()\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/timeout.py\", line 130\n, in func_with_timeout\nreturn func(*args, +kkwargs)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py\", lin\ne 78, in error_remapped_callable\nraise exceptions. from_grpc_error(exc) from exc\ngoogle.api_core.exceptions.NotFound: 404 models/gemini-pro is not found for API version vibeta, or is not supported\nir generateContent. Call ListModels to see the list of available models and their supported methods\n\nLn 39, Col 63 Spaces 4 UTF-8 LF\n\nfile.pdf\n\n{} Python & 3.13.2 64-bit\n\nITRV (1).pdf ITRV.pdf AIEUTIR EAI EY\n\nIko to mtj\n\nS80%\u00b0GEGS8S2S \u00a98270 8f\n\nIko to MTJ (1).pdf\n\nif\n\nIko to MTJ-s-~\n\nGB al-05-BBLEN4 \u00a9 Openal @ apikeys - Open \u00a9 Gemini API refer 96 Get API key | GX\nIntelligent Excuse Generator Plan >\neee @ GZ shan (6\n\n\u00a9) Copy\n\ngoogle.api_core.exceptions.NotFound: 404 ...\ngemini-pro is not found for API version vibeta, or is not supported in ge\n\nThe Google Generative Al SDK you're calling is still hitting the old \u201cv1beta\" endpoint, where the\nmodel list looked like\n\nmodels/gemini-pro (note the full path).\n\nThat happens when:\n\n1. An older SDK (< 0.3) is installed, or\n\n2. You pass just \"gemini-pro\" while the old client expects \"models/gemini-pro\".\n\n\u2019\\ Fix in two quick steps\n\n1 Upgrade the SDK so it speaks the new v1 API\n\nbash\n\npip uninstall -y google-generativeai\npip install --no-cache-dir --upgrade google-generativeai\n\n\u00a9) Copy\n\npip show google-generativeai should now say 0.3.x (or newer).\n\n2 Use the canonical model name\n\n\u20ac Work with Code Tab x\n\nMessage Bhuvan\n\n+ @\u00ae ov\n\n@ Wed Jul 2 10:24AM"
}