{
  "timestamp": "2025-07-02_08-34-20",
  "active_window": "firefox",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "Smart Border Patrol Using Drones and Wireless Charging System Under Budget Limitation\n",
  "vscode_text": "<!DOCTYPE html>\n<html>\n  <body style=\"margin: 0; background: rgba(0,0,0,0.7); color: white; font-family: sans-serif;\">\n    <div style=\"-webkit-app-region: drag; padding: 10px; background: rgba(0,0,0,0.8);\">\n      <pre id=\"output\" style=\"white-space: pre-wrap; word-wrap: break-word;\">Waiting for data...</pre>\n    </div>\n    <script>\n      const { ipcRenderer } = require('electron');\n      ipcRenderer.on('update-prediction', (event, data) => {\n        document.getElementById('output').textContent = data;\n      });\n    </script>\n  </body>\n</html>",
  "ocr_text": "a.\n\nowe 6 OD\n\nFirefox File Edit View History\n\nBookmarks\n\n(ica) =} List of research papers - Google X\n\nC a\n\nnN w- 4 of9\n\n\u00b0\n\u00b0\nlill\n\nIme\n\nv A UAV patrol system using\npanoramic stitching and\nobject detection\n\n1 Introduction\nVv 2 Related work\n2.1 Image stitching\n\n2.2 Motion ghost\nelimination\n\n2.3 Object detection\nVv 3 UAV patrol system\n\n3.1 System\narchitecture\n\n3.2 Image stitching\n\n3.3 Motion ghost\nelimination\n\nVv 3.4 Object detection\n3.4.1 Scene\nparsing\n\n3.4.2 Quantifying\nthe object-scene\nrelationship\n\n3.4.3 Model\nstructure\n\nv 4 Experiments\n\nv 4.1 Dataset and\nexperiment settings\n\n4.1.1 Dataset\n\n4.1.2 Experiments\nsettings\n\n4.2 Image stitching\nevaluation\n\n4.3 Object detection\nevaluation\n\n4.4 Results\n5 Conclusion\n\nDeclaration of\nCompeting Interest\n\nReferences\n\n98\n\nTools Window Help\n\nA UAV patrol system using pano X\n\nsciencedirectassets.com\n\nare merged into the following ten representative super-categories: indoor, building, sky, floor, plant, road, sidewalk, person,\nvehicle and water.\n\nWhen performing scene parsing on an image, a matrix denoting the scene category for each pixel is generated and is\nused in the detection model. An example of a parsed image with regions of different scene categories filled in different\n\ncolors is shown in\n\n3.4.2. Quantifying the object-scene relationship\n\nTo extract background knowledge about object occurrences and scene categories, we adopt a statistical approach. We use\n56 videos in the training dataset of the VisDrone video object detection task and select a random frame of each of them as\nthe sample. After conducting scene parsing on all images in the sample, the object occurrences of a certain class in each\nkind of scene are counted. For this purpose, we use the scene parsing result of the pixel at the center of the bounding box\n\n* A UAV patrol system using par X\n\nSmart border patrol using drone X\n\n+ 200%\n\nFig. 3. An example of scene parsing.\n\nalongside the original image.\n\n+\n\nSG0ceESBE2S OOF E\u00ae\n\na\n\n\u00a92008 eo F\n\nTE\n\nte\n\nHighlight colour\n\n@eee0e\n\nThickness\n\nShow all\n\n@ Wed Jul 2 8:34AM\n\n(\u20ac\n\nT\n\nC)\ne\n\n4\n\nVv\n\nwo =\n\n6&& \u00bb"
}