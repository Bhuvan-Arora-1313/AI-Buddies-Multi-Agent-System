{
  "timestamp": "2025-07-02_10-28-32",
  "active_window": "ChatGPT",
  "focused_text": "internal saeerever er",
  "clipboard": "curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"gemini-pro\")\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\n{prompt}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "6\n\no\nS\n\n\u00a9\n\n= List of research\n\nC2 GA\n\nChatGPT File Edit View Window Help 6 \u20ac8 \u00a9OGD O 8 2h F Se @ Wed Jul 2 10:28AM\n# Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Cc ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence | Al-05-BBLEN4 \u00a9 Openal o API keys - Open (G) Gemini API refer: * Get API key | G X\na io \u2014\no\u00a3 aistudio.google.com/apike\u2019 Intelligent Excuse Generator Plan > 7 =\nO Be goog /apikey eco MD G_Miellig a\ne=> P excuse-generator By =|)\u201c aaa wrt wm wn erm girs \u2014 Pe~ os\nx Welcome @ excuse_api.py 4,U X % .env U Dy % a .\n\n| oO EXPLORER\n\n\\Y EXCUSE-GENERATOR\n\nP > __pycache__\n\nv venv\npa > bin\n> include\n> lib\nae\n\n\u00a9 pyvenv.cfg\n\u00a9 .env\n\nES @ excuse_api.py 4,\n\nU\nU\nU\n{} history.json U\nU\n\nA = requirements.txt\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nGE & maine @0A4\n\n(Make sure you import only once and configure only once.)\n@ excuse_api.py > ...\n\n1 # excuse_api.py\n\n2 import os, json, time, hashlib = Now test\n3 from pathlib import Path :\n4 from dotenv import load_dotenv, find_dotenv bash \u00a9) Copy\n5 load_dotenv(find_dotenv(), override=True)\n6 Ctr1-c\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS + vrs AX\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 96\" >.) python3.11\n\n7, in run bc uvicorn excuse_api:app --reload\n\nresult = context.run(func, xargs) 2.J zsh\nFile \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 42, in generate 4 .\nout = json. loads (model. generate_content(full_prompt) .text) In a second terminal tab:\n\nAAAAAAAAAAAAAARAAAAAAAAAAAARAAAAAAA [\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/generativeai/generative_models\n\n-py\", line 331, in generate_content bash O) Copy\nresponse = self._client.generate_content(\n\nFile \"/Users/bhuvanarora/excuse-generator/. venv/1ib/python3. 11/site-packages/google/ai/generativelanguage_' vibeta/s .\n\nervices/generative_service/client.py\", line 835, in generate_content curl -X POST http://127.0.0.1:8000/generate \\\nresponse = rpc( -H \"Content-Type: application/json\" \\\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method. py\", -d '{\"scenario\":\"missed class\" ! \"urgency\" : \"panic\"} '\nline 131, in __call__\nreturn wrapped_func(xargs, *xkwargs) i\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\" You should see JSON with excuse, believability_score, and chat_log.\n\n, line 294, in retry_wrapped_func\nreturn retry_target(\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\" = If that works:\n, line 156, in retry_target\nnext_sleep = _retry_error_helper( |\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1ib/python3.11/site-packages/google/api_core/retry/retry_base. py\", bash v oO Copy\nline 214, in _retry_error_helper '\n\nraise final_exc from source_exc\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\"\n, line 147, in retry_target .\nresult = target () ( Work with Code Tab x\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/timeout.py\", line 130\u00a7 a= om -\n, in func_with_timeout ene (3)\nreturn func(*args, +kkwargs)\n\nt\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py\", lin\ne 78, in error_remapped_callable\nraise exceptions. from_grpc_error(exc) from exc\ngoogle.api_core.exceptions.NotFound: 404 models/gemini-pro is not found for API version vibeta, or is not supported\nfor generateContent. Call ListModels to see the list of available models and their supported methods\n\nLn7,Col1 Spaces:4 UTF-8 LF {} Python @&3 3.13.264-bit (3\n\ninternal saeerever err\n: \u00b0\n\nfile.pdf ITRV (1).pdf ITRV.pdf AIEUTIR EAI EY Iko to mtj Iko to MTJ (1).pdf = Iko to MTJ-s.\n\n\u00a9\n\nS80\u00b0G8880 e270 ae\n\n."
}