{
  "timestamp": "2025-07-02_10-12-29",
  "active_window": "ChatGPT",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"missed class\", \"urgency\":\"panic\"}'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "Ow \u00ae 0\n\nChatGPT File Edit View Window\u2019 Help 6 \u20ac8 &OGD O S 2) FQ\n\n=\nSC > G a\n\n| oO EXPLORER\n\n\\Y EXCUSE-GENERATOR\n\nP > __pycache__\n\nv venv\n& > bin\n> include\n> lib\nae\n\n\u00a9 pyvenv.cfg U\n\u00a9 .env U\nES @ excuse_api.py 4,U\n\nU\nU\n\n{} history.json\nA = requirements.txt\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nWE & maine @0A4\n\nOo\nLe}\n\n@ Wed Jul 2 10:12AM\n\nx [& x Oo x Oo x x M x x a) x @ aApPlikeys - Openal Ai X\n\nO 8 = platform.openai.com/settings/organization/api-keys eee OG Intelligent Excuse Generator Plan >\n\nBhuvan\n\u20ac P\u00a3 excuse-generator By te oe\nJ Welcome \u00ae excuse_api.py 4,U X %.env U Pym O- Step What you type / click\n@ excuse_api.py > ...\n# excuse_api.py = 1. Get a key 1. Sign in at https://aistudio.google.com.2.\nimport os, json, time, hashlib og Top-right -> API keys > Create API key >\nfrom pathlib import Path : copy.\nfrom dotenv import load_dotenv\nload_dotenv() # \u2014 NEW: pulls OPENAI_API_KEY from .env 2. Add it to .env bash<br>GEMINI_KEY=AI-\nfrom fastapi import FastAPI XXXXXXXXXXXXXXXX<br>\nfrom pydantic import BaseModel\nfrom openai impo rt OpenAl 3. Install Google's SDK bash<br>source .venv/bin/activate\n\n# ---------+- OpenAL client ---------- # if not already<br>pip install\n\n1@ client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\") ) HOQEMA pele ae Anse are beaclaie\n\n4 . Replace the OpenAl block in python<br>import\n\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS tye A Xx . . .\n_ excuse_api.py google.generativeai as\nsync * | BJ python3.11 Q Q Q 9\nreturn await get_async_backend().run_sync_in_worker_thread( Slate genai<br>genai.configure(api_key=o\nAAA AAAAARAAAAAAAAAAAAAAAAAAAAAAAAARARAAAAAAARARAAAAA .1\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 24 Ss. getenv( \"GEMINI_KEY\" ) ) <br>model =\n70, in run_sync_in_worker_thread 9 9 o 9.9\nreturnvawait future genai.GenerativeModel (\"gemini-\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 96 pro\") # free-tier\n7, in run\nresult = context.run(func, \u00a5args) ' model<br><br>def call_1llm(prompt:\nFile \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 38, in generate str) :<br> Return the raw\nres = client.chat.completions.create( ee nnn\nAA AAA A AAA AAA AAAAAAAAAARAAAAAAAA, text from Gemini. <br> return\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 287, i\nn wrapper model.generate_content (prompt) .tex\nreturn func(*args, +kkwargs) b\nAA AAAAAAAAAARAARAAAAAL t<br>\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/com\npletions.py\", line 1087, in create\nt Gis t . . 4\npurse os 5 . Adjust the generation call Replace your previous\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/openai/_base_client.py\", line 1249, i \u00b0 Q\nn post g vy PETEUC vy client.chat.completions.create(..)\nreturn cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls) ) 1 4\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAR AAAAAAARAARAARAAAARRARAA ' stanza with:\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1037, i\nn request v\nraise self._make_status_error_from_response(err.response) from None _\nopenai.RateLimitError: Error code: 429 - {'error': {'message': \u2018You exceeded your current quota, please check your p python<br>prompt =\nlan and billing details. For more information on this error, read the docs: https://platform. openai.com/docs/guides/\nerror-codes/api-errors.', \u2018type': \u2018insufficient_quota', \u2018param': None, \u2018code': \u2018insufficient_quota'}}\n\n\u20ac Work with Code Tab x\nQ  n10,Col53 Spaces:4 UTF-8 LF {} Python & 3.13.264-bit ()\nMessage Bhuvan\n\n+ @\u00ae ov\n\nS800eEGE80 \u00a98210 &*\n\n(es)\n\nResult\nOne AI\u2014XXXXXx\nclipboard.\n\nKey stays local &\n\nAdds the goog]:\n\npypi.org\n\nA tiny helper tha\u2019\nas a string.\n\ndata now holds\n\n2@"
}