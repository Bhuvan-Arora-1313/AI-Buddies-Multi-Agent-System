{
  "timestamp": "2025-07-02_10-57-16",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "source .venv/bin/activate\npip install --upgrade langchain_google_genai langchain-core",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content([full_prompt]).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ Code File Edit Selection View Go Run Terminal Window\u2019 Help 6 \u20ac8 \u00a9 @D S 3%%) F Q S \u00a9 Wed Jul2 10:57AM\n= List of research @ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence [| Al-05-BBLEN4 \u00a9 OpenAl coy API keys - Open/ [G) G\nApoorv Goyal Sanskriti The School\n. No i have not met her.....\n\u20ac > C a O 8 = aistue\u2014\u2014+\u2014\u2014\u2014+\u2014 Intelligent Excuse Generator Plan > J\n\no\nS\n\n\u00a9\n\nGoogle Al Studio\neee\n\n2\n\nEXPLORER\n\nP > __pycache__\nv venv\n> bin\nne > include\n> lib\nrd \u00a9 pyvenv.cfg\n .env\nBS @ excuse_api.py\n{} history.json\nA = requirements.txt\n\n> OUTLINE\n\n> TIMELINE\n\nmaint @ @Wo0A4\n\nView status\n\n\\Y EXCUSE-GENERATOR\n\n4\n\nU\nU\nU\n\nBhuvan\n\nTINY INVIG VUINUSIVIIUVGI VINTgLa vo vib Ul Hot vo oUNIY Yayluaus.\n\nNew |\n\nria | PyCharm Q\n<> p excuse-generator 8 a 08 Oo la\nx Welcome @ excuse_api.py 4,U X % .env U Dy %\n\n\u00ae excuse_api.py > \u00a9 generate\n\n40 def generate(r: Req):\n\nGive that a try; if the cur] still errors, send back just the last five traceback lines and we'll\nsquash whatever's left.\n\nOvad gy\n\nupdaTE yourself in vs\n\n41 prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n42 full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency:\n43 out = json. loads (model. generate_content ( {[full_prompt] ). text)\n44 entry = {\n45 \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS +v ON\n\n>) zsh\n\nRequirement already satisfied: httpx<1,>=0.23.@ in ./.venv/lib/python3.11/site-packages (from langsmith>=0.3.45->lan\u2122 | _\ngchain-core) (@.28.1) >| zsh\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.3.45->langchain-core)\n\nUsing cached orjson-3.10.18-cp311-cp311-macosx_15_@_arm64.whl.metadata (41 kB)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.3.45->langchain-core)\n\nUsing cached requests_toolbelt-1.@.0-py2.py3-none-any.whl.metadata (14 kB)\nCollecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.3.45->langchain-core) a\n\nUsing cached zstandard-@.23.@-cp311-cp311-macosx_11_@_arm64.whl.metadata (3.@ kB)\nRequirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.\n45->langchain-core) (4.9.0) :\nRequirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmi\u00ae\nth>=0.3.45->langchain-core) (1.0.9)\nRequirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.+*->httpx<1,>=0.23\n-@->langsmith>=0.3.45->langchain-core) (0.16.0)\nRequirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->1\nangsmith>=0.3.45->langchain-core) (1.3.1)\nDownloading Langchain_google_genai-2.1.6-py3-none-any.whl (47 kB) 1\nDownloading lLangchain_core-@.3.67-py3-none-any.whl (44@ kB)\nUsing cached filetype-1.2.@-py2.py3-none-any.whl (19 kB)\nUsing cached google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\nUsing cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nUsing cached packaging-24.2-py3-none-any.whl (65 kB)\nUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\nUsing cached jsonpointer-3.0.@-py2.py3-none-any.whl (7.6 kB)\nUsing cached langsmith-@.4.4\u2014py3-none-any.whl (367 kB)\nUsing cached orjson-3.10.18-cp311-cp311-macosx_15_\u00ae_arm64.whl (133 kB)\nUsing cached requests_toolbelt-1.@.0-py2.py3-none-any.whl (54 kB)\nUsing cached zstandard-@.23.@-cp311-cp311-macosx_11_@_arm64.whl (633 kB)\nUsing cached PyYAML-6.@.2-cp311-cp311-macosx_11_@_arm64.whl (172 kB)\nInstalling collected packages: filetype, zstandard, tenacity, PyYAML, packaging, orjson, jsonpointer, requests-toolb,\nelt, jsonpatch, langsmith, langchain-core, google-ai-generativelanguage, langchain_google_genai\n\nAttempting uninstall: google-ai-generativelanguage\n\nFound existing installation: google-ai-generativelanguage @.6.15\nUninstalling google-ai-generativelanguage-0.6.15:\nSuccessfully uninstalled google-ai-generativelanguage-0.6.15\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This beha\nviour is the source of the following dependency conflicts. :\ngoogle-generativeai @.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0\n-6.18 which is incompatible.\nSuccessfully installed PyYAML-6.0.2 filetype-1.2.@ google-ai-generativelanguage-0.6.18 jsonpatch-1.33 jsonpointer-3.\n@.@ langchain-core-@.3.67 langchain_google_genai-2.1.6 langsmith-@.4.4 orjson-3.10.18 packaging-24.2 requests\u2014toolbe\n1t-1.0.0 tenacity-9.1.2 zstandard-@.23.0\n(.venv) bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % o\n\nQ  .n43,Col22 Spaces:4 UTF-8 LF {} Python & 3.13.2 64-bi\n\na |\n\nThought for 6 seconds >\n\nWriting code Details\nx\n\u20ac Auto-apply code T )\nVv\n\u00a9 excuse_api.py x\nMessage Bhuvan\nCD\nfal RF \u00ae Ww iw )\n\"| \u2018cea =a amcnanened pEses F\n\n| :\n(3) e \u00a9) | ~\n. . ."
}