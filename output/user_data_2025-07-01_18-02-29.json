{
  "timestamp": "2025-07-01_18-02-29",
  "active_window": "firefox",
  "focused_text": "\u200b\u200b",
  "clipboard": "Enhanced Multi-Agent Coordination Algorithm for Drone Swarm Patrolling in Durian Orchards",
  "vscode_text": "<!DOCTYPE html>\n<html>\n  <body style=\"margin: 0; background: rgba(0,0,0,0.7); color: white; font-family: sans-serif;\">\n    <div style=\"-webkit-app-region: drag; padding: 10px; background: rgba(0,0,0,0.8);\">\n      <pre id=\"output\" style=\"white-space: pre-wrap; word-wrap: break-word;\">Waiting for data...</pre>\n    </div>\n    <script>\n      const { ipcRenderer } = require('electron');\n      ipcRenderer.on('update-prediction', (event, data) => {\n        document.getElementById('output').textContent = data;\n      });\n    </script>\n  </body>\n</html>",
  "ocr_text": "nay\n\n<\n\nList of research papers - Google X\n\nCa O68\n\nY ChatGPT\n\nChatGPT v\n\nSaved memory full \u00a9\n\nfly together\u2014it depends on the mission.\n\nDo you want me to explain how drones stay\n\nconnected when they are dispersed?\n\nQO6 9m\n\nov &\n\nppo algo\n\nThe PPO algorithm stands for Proximal\nPolicy Optimization.\nIt is a popular Reinforcement Learning (RL)\n\nalgorithm.\n\nLet me explain in simple words:\n\n@ What is PPO?\n\ne PPO is a method vy to train agents\n\n(like drones, robots, or game\n\nAsk anything\n\n+ 2 Tools Q\n\nChatGPT can make mistakes. Check important info. See Cookie\nPreferences.\n\nN_ Enhanced multi agent coordinat X\n\ngoogle.com\n\n<\n\nFile Edit\n\n* s41598-025-88145-7-2.pdf x \u00a9) JayKap-Git/Buddy x +\nw\nList of research papers + 5 Saving... D\nView Insert Format Tools Extensions Help\nQo @ BA F 100% ~ | Normaltext ~ Arial ~\\-(\"]+\\/B TU A Poo PQ\\Ss- e+e E-SEYX\non Min SP i i in ee i i i i ee i i Sn ns\nfor take-off/landing times, drone endurance, and uses mixed-integer programming for path\nplanning.\n+ Novelty\n\nDocument tabs\n\nNovelty\n\nTraffic Patrolling Rout...\n\nSummary\nHighlight\n\nNovelty\n\nEnhanced Multi-Agen...\n\nSummary\nHighlight\n\nNovelty\n\nA UAV Patrol System ...\n\nSummary\nHighlight\n\nNovelty\n\nSmart Border Patrol U...\n\nSummary\nHighlight\n\nNovelty\n\nUAV-Enabled Intellige...\n\nSummary\nHighlight\n\nNovelty\n\nUnlike earlier works on vehicle-drone coordination (which often focus on logistics), this paper\nextends the problem to urban traffic patrolling with road-based constraints. The DL-ARP\nformulation, inclusion of heterogeneous task types, and real-world deployment-backed\ncase study set it apart as a foundational work for future urban surveillance patrol systems.\n\n1.8. Enhanced Multi-Agent Coordination Algorithm for Drone Swarm\n\nPatrolling in Durian Orchards\nMarch 2025\nJournal : Scientific Reports |\nPublisher : Nature Publishing Group\nGoogle scholar Link\nSummary\n\nThis study introduces a novel EN-MASCA (Enhanced Multi-Agent Swarm Control Algorithm)\nfor optimizing drone swarm patrolling in complex agricultural environments\u2014specifically durian\norchards. The approach incorporates a virtual navigator model that dynamically guides drones\nin real-time, responding to environmental challenges such as obstacles, terrain irregularities,\nand wind.\n\nThe system uniquely combines Deep Q-Network (DQN) and Proximal Policy Optimization\n(PPO) reinforcement learning algorithms to refine flight path, speed, and obstacle avoidance.\nExtensive simulations using ROS-Gazebo and Rflysim3D environments validate its\neffectiveness compared to existing control algorithms (MASCA, NNCA, NSGA-II).\n\nHighlight\n\na\n\nv"
}