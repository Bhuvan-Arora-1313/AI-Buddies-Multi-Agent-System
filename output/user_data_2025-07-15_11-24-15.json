{
  "timestamp": "2025-07-15_11-24-15",
  "active_window": "Terminal",
  "focused_text": "Last login: Sat Jul 12 06:00:38 on console\nbhuvanarora@Bhuvans-MacBook-Pro ~ % ls\nApplications (Parallels)\t\tPictures\nBuddy\t\t\t\t\tProjects\nCursor project\t\t\t\tPublic\nDesktop\t\t\t\t\tPyCharmMiscProject\nDocuments\t\t\t\tPyCharmMiscProject.iml\nDownloads\t\t\t\tPycharmProjects\nexcuse-generator\t\t\tsetted_chavanprash\nexcuse-generator-website\t\tstealth-popup\nGuru Gobind singh ji prakash parv .jpg\tStealthOverlay\nLibrary\t\t\t\t\ttext-extractor\nMovies\t\t\t\t\tVirtual Machines.localized\nMusic\t\t\t\t\tvscode-text-extractor\nParallels\nbhuvanarora@Bhuvans-MacBook-Pro ~ % cd buddy\nbhuvanarora@Bhuvans-MacBook-Pro buddy %",
  "clipboard": "git init",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# --- Gemini via LangChain (REST v1) ---\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\n# expose key for LangChain wrapper\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # must be in .env\n\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",          # free\u2011tier model\n    temperature=0.8,\n    convert_system_message_to_human=True\n)\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n    mode: str = \"normal\"   # \"normal\" | \"apology\"\n    language: str = \"en\"   # ISO code, e.g. \"en\", \"es\", \"fr\"\n    voice: bool = False   # If true, return an MP3 of the excuse\n\nclass EmergencyRequest(BaseModel):\n    number: str\n    message: str\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    style_clause = (\n        \"Respond in a guilt\u2011tripping, heartfelt apology tone.\"\n        if r.mode.lower() == \"apology\"\n        else \"Respond in a neutral, believable tone.\"\n    )\n    # language directive\n    lang_clause = (\n        \"\" if r.language.lower() in [\"en\", \"english\"] else\n        f\"Respond in {r.language} language.\"\n    )\n    full_prompt = (\n        f\"{SYSTEM_PROMPT}\\n\"\n        f\"Tone: {style_clause}\\n\"\n        f\"{lang_clause}\\n\"\n        f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    )\n    messages = [\n        SystemMessage(content=SYSTEM_PROMPT),\n        HumanMessage(content=full_prompt)\n    ]\n    response_text = llm(messages).content.strip()\n    # LangChain may wrap JSON in ``` blocks \u2013 strip them\n    if response_text.startswith(\"```\"):\n        response_text = response_text.strip(\"`\").lstrip(\"json\").strip()\n    out = json.loads(response_text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n    # --- optional voice synthesis ---\n    if r.voice:\n        from gtts import gTTS\n        audio_dir = Path(\"audio\")\n        audio_dir.mkdir(exist_ok=True)\n        audio_file = audio_dir / f\"{entry['id']}.mp3\"\n        gTTS(out[\"excuse\"], lang=r.language[:2]).save(audio_file.as_posix())\n        entry[\"audio\"] = str(audio_file)\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]\n\n# ---------- /emergency ----------\n@app.post(\"/emergency\")\ndef emergency(req: EmergencyRequest):\n    \"\"\"\n    Simulate sending an emergency SMS/call.\n    For the demo we just log the request and append an entry to history.json.\n    \"\"\"\n    entry = {\n        \"id\": f\"emergency-{int(time.time())}\",\n        \"ts\": time.time(),\n        \"excuse\": \"EMERGENCY TRIGGER\",\n        \"believability_score\": 1.0,\n        \"chat_log\": f\"Sent '{req.message}' to {req.number}\"\n    }\n    history = json.loads(DATA.read_text())\n    history.append(entry)\n    DATA.write_text(json.dumps(history, indent=2))\n    return {\"status\": \"sent\", \"to\": req.number, \"msg\": req.message}",
  "ocr_text": "@ Terminal Shell Edit View Window Help a 6 O DOS \u00a9 exam F Q S @ Tue Jul 15 11:24AM\nea ~ e_ nan =~ :\nWEY - al iii iii iii Cu 43\nMaccy\nBuddy Bubble Project 2 - Al buddies cloduddefence Al : git init\nChats \u00a9 \u00a9 2 Isha, Jayant Kapoor Bits 2, Rupesh, ~Shreyak, You ey & Q py @ buddy_magic,, A\nroq. <r\n(sam) prod-Py XP Q Ask Meta Al or Search A2As\u00a5anv \u00a9\nssistant.py Today\n@ swe_buddy.py a\n33 7 @ &@Clouda@ Yesterday ae .\n& tr gemini api credits khatam hogaye 7:\n\"@ swe_buddy_groq.py Draft: lets have a meeting at 11 am all Ps ea F CAO PIS\nfa) vy Moutput 0 i made 2 new google accounts in that hardly i ran a few\noo , A \u2018O) queries after which all credits were exausted ... aisa kaise\nie; live_outputjson \u00a9 Project 2 - Al buddies clodudd... 11:23 AM ho sakta hai for new ID 7:46AM YW\nsee (} prediction_output.json % You: till then i updaet on git\nWs =~ koi free LLM nai aata kya 7:47AM W\nSieee im Buddy \u2014 -zsh \u2014 80x24\n& Last login: Sat Jul 12 06:00:38 on console =H} 11:18 AM online wala 7:47AM\n=) [bhuvanarora@Bhuvans\u2014MacBook-Pro ~ % 1s ] -\na Applications (Parallels) Pictures a X A) meeting kab karnin hai?? 9:37am W\n\u00a39) | Buddy Projects\nCursor project Public : Mam? o:\n) Desktop PyCharmMiscProject 10:57 AM CEN\ng Documents PyCharmMiscProject.iml nak-...\nDownloads PycharmProjects Isha Gupta BITS 2023\n{} excuse-generator setted_chavanprash\nexcuse-generator-\u2014website stealth-popup Bhunu\n{} Guru Gobind singh ji prakash parv .jpg StealthOverlay 10:53 AM .\nLibrary text-extractor 11am?\no Movies Virtual Machines. localized\nt Music vscode-text-extractor ie 11:45 Kar lo plz A 10:02 AM\nParallels 10:46 AM\n{} [bhuvanarora@Bhuvans\u2014MacBook-Pro ~ % cd buddy =e\n{ bhuvanarora@Bhuvans\u2014MacBook-Pro buddy % ff link f... Ok 10:23AM Y\n>\u00bb Btex\na 10:39 AM\n=.en ~Shreyak +91 96571 56993\n@ git i) can we have it rn? have another meet at 12:30 11:22AM\n@ act.\nq ' Re . : Amazon Yesterday yafine 11:23am -\u2014\n@\u00ae activity_analyzer_groq.py \u2014 als! @ 2%...\n\u00ae buddy_magic.py iwill send link 11:23AM W\nae Ht a\nce . Jayant Allen Bits Yesterday 11 30 we can meet 11:23AM W\nRun \u00a9 floating_bubble_ui_groq \u00a9 activity W Thanks bye\n@ till then i updaet on git Edited 11:23AM VW\nG\noF Gpt+ Yesterday 0\ng \u201cdata_sources\": \"Active Window, Fo a W You: like for each new job opportunity + Y\n\"timestamp\": 1752558689 .797154\n7 Deleted: output/user_data_2025-07-15_11-21-26.json\nes) = Deleted: output/user_data_2025-07-15_11-21-10.json\n\u00a9 irs Deleted: output/user_data_2025-07-15_10-20-03.json\niT Deleted: output/user_data_2025-07-15_10-18-27.json\n99 Deleted: output/user_data_2025-07-15_10-19-16.json\n= Deleted: outnut/user data 2025-07-15 10-19-39.ison\nOBuddy > #@ activity_analyzer_groqg.py 151:41 LF UTF-8 4spaces Python 3.13 (Buddy) cf\n\nS8GBOx8SESC BEOSVOBOH*+O\n\n(=)\n\n."
}