{
  "timestamp": "2025-07-02_10-08-40",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "uvicorn excuse_api:app --reload",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ Code File Edit Selection View Go Run Terminal Window Help 6 \u20ac&8 \u00a9GD O S we FF Q SB \u00a9 WedJul2 10:08AM\n= List of research pape X * Artificial Intelligence X CO NLP_1.ipynb - Colab X CO NLP_1.ipynb - Colab X ca LAUNCHED Global X M Launched - Artificial X Artificial_Intelligence_Ce X (Bi al-05-BBLEN4 x \u00a9 Opendl x So API keys - OpenAl A! X\nO <7 Ce O @G = platform.openai.com/settings/organization/api-keys Intelligent Excuse Generator Plan > y=\nBhuvan\n6 C eee \u20acE = P excuse-generator By oO Wl Move the dotenv load block above where you build the client (or simply rebuild the client after \"\naq | EXPLORER J Welcome \u00ae excuse_api.py 4,U X % .env U Py oe loading):\n= Vv EXCUSE-GENERATOR @ excuse_api.py > ...\n\u00a9) > \u2014Pycache_ 1 # excuse_api.py python \u00a9) Copy\nes 2 import os, json, time, hashlib = : ; ; .\npay . . = import os, json, time, hashlib\n> include 3 from pathlib import Path from pathlib import Path\nS| 2! 4 from dotenv import load_dotenv\new | meme 5 load_dotenv() # \u00ab NEW: pulls OPENAI_API_KEY from .env\neo : u . . 5\nSB env ; J - | P _ - from dotenv import load_dotenv, find_dotenv\n2 CEI OU 6 from fastapi import FastAPI load_dotenv(find_dotenv(), override=True)\nUD Wana \u00b0 7 from pydantic import BaseModel\nA = requirements.txt U SERA\n8 from openai impo rt Sar from fastapi import FastAPI\nQ9 # ---------- OpenAI client ---------- from pydantic import BaseModel\n1@ client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\") ) from openai import OpenAl\nall client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\") )\nW200 GP s==Sseeees simple \u201cDB\u201d ---------\u2014\n13. DATA = Path(\"history.json\") (The critical bit is that load_dotenv() must execute before client = OpenAl...).)\n14 if not DATA.exists():\n15 DATA.write_text(\"[]\") # seed empty list 2 Save & restart cleanly\n16\n17 bash O) Copy\n18\nI @e =====eeoS= FastAPI app \u2014---------\nCtr1-C\n28 app = FastAPI()\n71\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS tye aA x unset OPENAI_API_KEY\nprint(\"Loaded key starts with:\", os.getenv(\"OPENAI_API_KEY\") [:10] ) Ed >.) python3.11\nPY >-| zsh\nLoaded k tart ith: sk- j-fb 7 je\n(venv) HaumnnioreCthene eamacte Fra excuse-generator % uvicorn excuse_apl:app \u2014-reload\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % unset OPENAI_API_KEY 1\n(.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % uvicorn excuse_api:app --reload\nINFO: Will watch for changes in these directories: ['/Users/bhuvanarora/excuse-generator']\n@ INFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit) \u201c 3 Test once more |\nINFO: Started reloader process [92860] using StatReload -\nINFO: Started server process [92862]\n> OUTLINE INFO: Waiting for application startup. bash v oO Copy\n$03 INFO: Application startup complete. on\n> TIMELINE 1\nLi | % main* \u00ae@ @0A4 Q n10,Col53 Spaces:4 UTF-8 LF {} Python @& 3.13.264-bit O\nMessage Bhuvan\n+ @& \u00a2 @\nS\n\n920068820 8920 AF"
}