{
  "timestamp": "2025-06-27_11-11-22",
  "active_window": "Safari",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "from dotenv import load_dotenv\n   load_dotenv()",
  "vscode_text": "import json\nimport time\nimport os\nfrom typing import Dict, Any, List\nimport subprocess\nimport signal\n\n# Import Google Gemini\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\nfrom dotenv import load_dotenv\nload_dotenv()\n\n# Google Gemini API key setup\nimport os\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # Set this externally\n\n# Initialize Google Gemini LLM\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",\n    temperature=0.3,\n    convert_system_message_to_human=True\n)\n\ndef read_latest_user_data() -> Dict[str, Any]:\n    \"\"\"Read the latest user data from live_output.json\"\"\"\n    try:\n        with open(\"output/live_output.json\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return {}\n    except json.JSONDecodeError:\n        return {}\n\ndef read_user_data_file(filename: str) -> Dict[str, Any]:\n    \"\"\"Read a specific user data file\"\"\"\n    try:\n        with open(f\"output/{filename}\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return {}\n    except json.JSONDecodeError:\n        return {}\n\ndef get_all_user_data_files() -> List[str]:\n    \"\"\"Get list of all user data files in output directory\"\"\"\n    try:\n        files = [f for f in os.listdir(\"output\") if f.startswith(\"user_data_\") and f.endswith(\".json\")]\n        return sorted(files)\n    except FileNotFoundError:\n        return []\n\ndef analyze_user_activity_from_json(user_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Analyze user data from JSON to determine what the user is doing\n    Returns JSON format with activity classification\n    \"\"\"\n    if not user_data:\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": \"No user data available\",\n            \"timestamp\": time.time()\n        }\n\n    # Extract relevant information from user data\n    active_window = user_data.get(\"active_window\", \"\")\n    focused_text = user_data.get(\"focused_text\", \"\")\n    clipboard_content = user_data.get(\"clipboard\", \"\")\n    vscode_text = user_data.get(\"vscode_text\", \"\")\n    ocr_text = user_data.get(\"ocr_text\", \"\")\n    timestamp = user_data.get(\"timestamp\", \"\")\n\n    # Combine all text sources for analysis\n    combined_text = f\"\"\"\nActive Window: {active_window}\nFocused Text: {focused_text}\nClipboard: {clipboard_content}\nVS Code Text: {vscode_text}\nScreen OCR: {ocr_text}\n    \"\"\".strip()\n\n    if not combined_text or combined_text.strip() == \"\":\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": \"No meaningful text data available\",\n            \"timestamp\": time.time()\n        }\n\n    system_prompt = \"\"\"You are an AI assistant that analyzes user activity data to determine what the user is currently doing. \n    \n    You have access to multiple data sources:\n    - Active Window: The currently active application\n    - Focused Text: Text from the focused element\n    - Clipboard: Content in the clipboard\n    - VS Code Text: Text from VS Code editor (if available)\n    - Screen OCR: Text extracted from screen capture\n    \n    Analyze this data and classify the user's activity into one of these categories:\n    - coding: Writing, editing, or reviewing code (Python, JavaScript, etc.)\n    - researching: Reading articles, papers, documentation, or searching for information\n    - browsing: General web browsing, social media, or casual internet use\n    - emailing: Composing, reading, or managing emails\n    - messaging: Using chat applications, messaging apps, or communication tools\n    - gaming: Playing video games or game-related activities\n    - watching: Watching videos, streams, or multimedia content\n    - writing: Writing documents, notes, or creative content\n    - designing: Working on design, graphics, or creative projects\n    - working: General work activities not covered by other categories\n    - unknown: Unable to determine the activity\n    \n    Consider the following patterns:\n    - Coding: Look for code syntax, function definitions, imports, IDE elements\n    - Messaging: Look for chat interfaces, message bubbles, contact names\n    - Researching: Look for articles, documentation, search results\n    - Browsing: Look for web browser elements, URLs, navigation\n    \n    Return your response in valid JSON format with these fields:\n    - activity: The classified activity (string)\n    - confidence: Confidence level 0.0-1.0 (float)\n    - description: Brief description of what you observed (string)\n    - details: Additional context or specific tools/applications detected (string)\n    - data_sources: Which data sources were most useful for classification (string)\n    - timestamp: Current timestamp (float)\n    \n    Example response:\n    {\n        \"activity\": \"coding\",\n        \"confidence\": 0.85,\n        \"description\": \"User appears to be writing Python code in Cursor IDE\",\n        \"details\": \"Detected Python imports, function definitions, and Cursor IDE interface\",\n        \"data_sources\": \"VS Code text and active window\",\n        \"timestamp\": 1234567890.123\n    }\n    \n    Only return valid JSON, no additional text.\"\"\"\n\n    human_prompt = f\"Here's the user activity data to analyze:\\n\\n{combined_text}\\n\\nPlease analyze this data and determine what the user is doing.\"\n\n    try:\n        messages = [\n            SystemMessage(content=system_prompt),\n            HumanMessage(content=human_prompt)\n        ]\n        \n        response = llm(messages)\n        response_text = response.content.strip()\n        \n        # Try to parse the JSON response\n        try:\n            result = json.loads(response_text)\n            # Ensure timestamp is current\n            result[\"timestamp\"] = time.time()\n            return result\n        except json.JSONDecodeError:\n            # Fallback if JSON parsing fails\n            return {\n                \"activity\": \"unknown\",\n                \"confidence\": 0.0,\n                \"description\": \"Failed to parse LLM response\",\n                \"details\": response_text,\n                \"data_sources\": \"LLM response parsing failed\",\n                \"timestamp\": time.time()\n            }\n            \n    except Exception as e:\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": f\"Error analyzing user data: {str(e)}\",\n            \"details\": \"\",\n            \"data_sources\": \"Error occurred during analysis\",\n            \"timestamp\": time.time()\n        }\n\ndef analyze_historical_data(num_files: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"Analyze the most recent user data files\"\"\"\n    files = get_all_user_data_files()\n    if not files:\n        return []\n    \n    # Get the most recent files\n    recent_files = files[-num_files:] if len(files) > num_files else files\n    results = []\n    \n    for filename in recent_files:\n        user_data = read_user_data_file(filename)\n        if user_data:\n            analysis = analyze_user_activity_from_json(user_data)\n            analysis[\"source_file\"] = filename\n            results.append(analysis)\n    \n    return results\n\ndef main():\n    \"\"\"Main function to continuously monitor and analyze user activity\"\"\"\n    print(\"\ud83d\udd0d User Activity Monitor Started\")\n    print(\"Using Google Gemini LLM for activity analysis\")\n    print(\"Analyzing data from gatheruserdata.py JSON files\")\n    print(\"Press Ctrl+C to stop\\n\")\n\n    # Start gatheruserdata.py as a subprocess\n    gather_proc = subprocess.Popen([\n        \"python\", \"gatheruserdata.py\"\n    ])\n    print(\"\ud83d\ude80 Started gatheruserdata.py in the background (PID: {}), collecting user data...\".format(gather_proc.pid))\n\n    try:\n        last_timestamp = None\n        while True:\n            print(\"\ud83d\udcca Reading latest user data...\")\n            user_data = read_latest_user_data()\n\n            # Only analyze if new data is available\n            if user_data and user_data.get(\"timestamp\") != last_timestamp:\n                last_timestamp = user_data.get(\"timestamp\")\n                print(\"\ud83e\udd16 Analyzing user activity from JSON data...\")\n                result = analyze_user_activity_from_json(user_data)\n                # Pretty print the JSON result\n                print(\"\ud83d\udcca Activity Analysis:\")\n                print(json.dumps(result, indent=2))\n                print(\"=\" * 60)\n            else:\n                print(\"\u23f3 Waiting for new user data...\")\n\n            # Wait before next check\n            time.sleep(5)\n\n    except KeyboardInterrupt:\n        print(\"\\n\ud83d\udc4b Activity monitor stopped by user\")\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n    finally:\n        print(\"\ud83d\uded1 Terminating gatheruserdata.py subprocess...\")\n        gather_proc.terminate()\n        try:\n            gather_proc.wait(timeout=5)\n        except subprocess.TimeoutExpired:\n            gather_proc.kill()\n        print(\"\u2705 gatheruserdata.py stopped.\")\n\ndef analyze_single_file(filename: str):\n    \"\"\"Analyze a specific user data file\"\"\"\n    print(f\"\ud83d\udd0d Analyzing file: {filename}\")\n    user_data = read_user_data_file(filename)\n    \n    if user_data:\n        result = analyze_user_activity_from_json(user_data)\n        print(\"\ud83d\udcca Activity Analysis:\")\n        print(json.dumps(result, indent=2))\n    else:\n        print(f\"\u274c Could not read file: {filename}\")\n\ndef analyze_recent_files(num_files: int = 5):\n    \"\"\"Analyze the most recent user data files\"\"\"\n    print(f\"\ud83d\udd0d Analyzing {num_files} most recent files...\")\n    results = analyze_historical_data(num_files)\n    \n    for result in results:\n        print(f\"\\n\ud83d\udcc1 File: {result.get('source_file', 'Unknown')}\")\n        print(f\"\ud83c\udfaf Activity: {result.get('activity', 'Unknown')}\")\n        print(f\"\ud83d\udcc8 Confidence: {result.get('confidence', 0.0):.2f}\")\n        print(f\"\ud83d\udcdd Description: {result.get('description', 'No description')}\")\n        print(\"-\" * 40)\n\nif __name__ == \"__main__\":\n    import sys\n    \n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"--file\" and len(sys.argv) > 2:\n            analyze_single_file(sys.argv[2])\n        elif sys.argv[1] == \"--recent\" and len(sys.argv) > 2:\n            analyze_recent_files(int(sys.argv[2]))\n        elif sys.argv[1] == \"--recent\":\n            analyze_recent_files()\n        else:\n            print(\"Usage:\")\n            print(\"  python activity_analyzer.py                    # Monitor live data\")\n            print(\"  python activity_analyzer.py --file <filename>  # Analyze specific file\")\n            print(\"  python activity_analyzer.py --recent [num]     # Analyze recent files\")\n    else:\n        main()",
  "ocr_text": "fo- < amazon.in @ + \u00a9\n\nInbox (2,230) - \u00a320231099@pilani.b... A Enabling Abilities India [Placement Unit] | AlphaGrep | Regi... i text-extractor - Google Drive CJ} can i run a local meta Ilm and get its... 4) Get API key | Google Al Studio Amazon.in Shopping Cart\n\n. Deliver to Arun . Hello, Arun Returns\nSt 2, \u00a9 New Delhi 110024 =SEN~ Account &Lists~ & Orders EY cart\n\n=All Fresh Today'sDeals MXPlayer Sell BuyAgain GiftCards KindleeBooks Browsing History Amazon Business \u00bb AmazonPay Arun's Amazon.in ae prime day 12-14 July >\n\nSho ppi ng Cart Subtotal (3 items): 712,088.00\nDeselect all items | This order contains a gift\nSony PS5 Astro Bot- Standard Edition %3,899%\nby Sony Up to 5% back with Amazon Pay EMI Availabl Vv\nCD-ROM ICICI card Terms vananre\nIn stock\nv prime Same-Day\nFREE delivery Today by 10 PM\n| This will be a gift Learn more\nRecommendations for all\nwu 1 + Delete Saveforlater Seemorelikethis Share products:\n= Sony PlayStation5...\nSony\n. . . . . hess\nSony Dualsense Usb Type A Charging Station For Playstation (Playstation5),Multicolor 71,999 i Kk KAA 465\n: PlayStation 5\nby Sony Up to 5% back with Amazon Pay | oi -1 y 5A 490\u00b0\nAccessory ICICI card Terms \u00b0 y\n\nM.R.P: 254,999.08\n\n. Get it by Tuesday, July 8\nrime -D.\nvP Same ay FREE Delivery by Amazon\nFREE delivery Today by 10 PM\n\nCJ This will be a gift Learn more Add to cart\n\nwu 1 + Delete Saveforlater Seemorelikethis Share\n\nIn stock\n\nBandai Namco Tekken...\nBandai Namco\n\ntoto tots 128\n-31% *3,299\n\nSony DualSense Wireless Controller Grey Camo (PlayStation 5) Limited time deal Ey MRP: 24,799.00\n\nby Sony 76,190 vprime FREE Delivery\nUnknown Binding M.R.P.: 26;399-00 Sunday, June 29\n\nIn stock Up to 5% back with Amazon Pay Add to cart\n\nv prime Same-Day ICICI card Terms\n\nFREE delivery Today 4 pm - 7pm\n| This will be a gift Learn more\n\nBeardo 100% Boar...\n\nSoke totes 268\nColour: Grey cammo\n: -37% 735315\naw 1 + Delete Saveforlater See more like this | Share M.R.P: 2560-00\n\nvprime FREE One-Day Get\nit Tomorrow, June 28\n\nSubtotal (3 items): 12,088.00 a=."
}