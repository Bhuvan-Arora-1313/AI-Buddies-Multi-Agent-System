{
  "timestamp": "2025-07-02_10-41-52",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "print(\">>> model being used:\", model._name) ",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "6\n\no\nS\n\n\u00a9\n\nCode File Edit Selection\n\n= List of research\n\n\u20ac > CG @\nee0@\n\n| oO EXPLORER\n\nV EXCUSE-GENERATOR\n> __pycache__\nv venv\n> bin\n> include\n> lib\n\u00a9 pyvenv.cfg\n\u00a9 .env\n\nU\nU\n@ excuse_api.py 4,U\n{} history.json U\n\nU\n\n= requirements.txt\n\n=> BY & oO\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nGE & maine @0A4\n\nView Go Run Terminal Window\u2019 Help\n\n* Artificial Intellige CO NLP_1.ipynb - Cc CO NLP_1.ipynb - Cc ca LAUNCHED Glok M Launched - Artif Artificial_Intelligence\n\nO @& = aistudio.google.com/apikey\n\n\u20ac PP excuse-generator By oe |\n\nx Welcome @ excuse_api.py 4,U X % .env U Dy %\n\n\u00ae excuse_api.py > \u00a9 generate\n\n3 from pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\nOnNr oau fs\n\n9 from fastapi import FastAPI\n\n10 from pydantic import BaseModel\n\n11\n\n12 import google.generativeai as genai\n\n13 genai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\n14 model = genai.GenerativeModel(\"models/gemini-pro\")\n15 # ---------- simple \u201cDB\u201d -\u2014---------\n\n16 DATA = Path(\"history. json\")\n\n17 if not DATA.exists():\n\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS. +yv we AX\n\n187, in __call__\nraise exc b\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line\n165, in __call__\nawait self.app(scope, receive, _send) -\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\",\nline 62, in __call__\n\nawait wrap_app_handling_exceptions(self.app, conn)(scope, receive, send) 1\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", lin\n\ne 53, in wrapped_app t\nraise exc\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", lin\ne 42, in wrapped_app 7\nawait app(scope, receive, sender)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 714, in _\ncall.\nawait self.middleware_stack(scope, receive, send)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/starlette/routing.py\", line 734, in aul\npp\n\n: : t\nawait route.handle(scope, receive, send)\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in h\nandle\nawait self.app(scope, receive, send)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in ap\n\nfile.pdf ITRV (1).pdf ITRV.pdf JETIR2101184 Iko to mtj Iko to MTJ (1).pdf\n\nS80\u00b0E68E820 \u00a9982\u00b010\n\nQ- .n42,Col63 Spaces:4 UTF-8 LF {} Python & 3.13.264-bit (\n\nIko to MTJ-+\n\n6 \u20ac8 OGD O S wt F Q S \u00a9 Wed Jul2 10:41AM\n\n2 Mom\n1 bottle nikal ker upper le ja\n\n\u00bb)\n\n() al-05-BBLeEN4 \u00a9 Openal @ apikeys - Open (S)\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\nThought for 13 seconds > .\nWe know three facts\n\n1. SDK 0.8.5 is installed \u2014 good.\n2. Your key can see models/gemini-pro \u2014 the diagnostic listed it.\n\n3. generate_content () is still hitting the old vibeta endpoint and throws\n404 .. gemini-pro is not found for API version vibeta.\n\nThat means the specific model instance inside the running process is\n\nstill being created with the short name (\"gemini-pro\") \u2014 or an old module\nis still in memory \u2014 even though the source file now shows\n\"models/gemini-pro\".\n\n1 \u2014 Double-check at runtime\n\nAdd one temporary print right after you create the model:\n\npython \u00a9) Copy\n\nmodel = genai.GenerativeModel(\"models/gemini-pro\" )\nprint(\">>> model being used:\", model._name)\n\nExpected output when you restart uvicorn:\n\n\u00a9) Copy\n\n>>> model being used: models/gemin \\ ro\n\n\u00a9 excuse_api.py x\nMessage Bhuvan\n\n+ @ &\n\n=]\n\naf"
}