{
  "timestamp": "2025-07-02_10-52-21",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content([full_prompt]).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ Code File Edit Selection View Go Run\u2019 Terminal Window Help 6 \u20ac8 \u00a9 DBD S 32%%) F Q S \u00a9 Wed Jul2 10:52AM\n= List of research f @ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence @ Al-05-BBLEN4 \u00a9 Openal coy API keys - Open/ (G) Gemini API refere +\u201d Get API key | GX\nO<\u00a2\u00ab vr coe O @& = aistudio.google.com/apikey Intelligent Excuse Generator Plan > =\nBhuvan\n\u00a9 15\nGoogle Al Studio - atti || LJ Reser\nQ\n0e@08 \u20ac\u00ab& > \u00a3 excuse-generator By Roa 24 lines\n\u00a9 1 prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\nEXPLORER Welcome \u00ae excuse_api.py 4,U @ & .env U by ote 9 c\n(om a ( ne pepy a 2 full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency:\nVv EXCUSE-GENERATOR \u00ae excuse_api.py > \u00a9 top {r. urgency} \"\n> __pycache__ . . .\nfs. P ae 40 def generate(r: Req): out = json.loads(model.generate_content(full_prompt) .text)\n2 _ iT iA 8 i . u .\n\u00ae > bin 41 prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency} : out = json.loads(model.generate_content([full_prompt]).text)\n=e > include 42 full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: \u201c~~ 4 entry = {\n\u00a3 . svenveta ; 43 out = json. loads(model.generate_content([full_prompt] ).text) 5 \"id\": hashlib.md5(outL\"excuse\"].encode()).hexdigest(),\n. 44 entry = { : :\nFR env y con . 7 7 . 'e updated excuse_api.py so it now:\n\u00ae excuse_api.py 4, U 45 id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(), =\n{} history.json u PROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS 4... ~ x Builds the model with the full resource name models/gemini-pro\nA = requirements.txt U \u2014\n: o : : : : : >.) python3.11\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/google/generativeai/generative_models\u201d fF\nyay, ikina SER in concueie com cme 1 | Bzsh Calls generate_content([full_prompt]) (the list form the API expects)\nresponse = self._client.generate_content(\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/ai/generat ive language_vibeta/s .\nervices/generative_service/client.py\", line 835, in generate_content astart Uvicorn:\nresponse = rpc( I\na PTE ERLE ESTES SHIEH) SUERTE OSES EISEN AEE NG RTE TY I bash oO Copy\nreturn wrapped_func(xargs, kkwargs) I\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1ib/python3.11/site-packages/google/api_core/retry/retry_unary.py\" l Ctrl-C\nrine arn rerrptaott I source .venv/bin/activate\nORES uvicorn excuse_api:app -\u2014-reload\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\"\n, line 156, in retry_target\nnext_sleep = _retry_error_helper( I\nRAAAAARAAAAARAAAAAAA : en test:\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\",\nline 214, in _retry_error_helper\nraise final_exc from source_exc A\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\" bash v Copied\n, line 147, in retry_target\nresult = target()\nrile \u201csusernnan . \u00abib/oython\u2019.11/site-pack se/ani timeout.py\"\", Line 130 curl -X POST http://127.0.0.1:8000/generate \\\n; i 2 EON Rebs etal or/.venv/1lib/python3.11/site-packages/google/api_core/timeout.py\", line -H \"Content-Type: application/json\" \\\nreturn func(*args, *kkwargs) -d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}'\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py\", lin\ne 78, in error_remapped_callable . v\nraise exceptions. from_grpc_error(exc) from exc \u00bbu should now receive a JSON excuse.\ngoogle.api_core.exceptions.NotFound: 404 models/gemini-pro is not found for API version vibeta, or is not supported\nfor generateContent. Call ListModels to see the list of available models and their supported methods.\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\ excuse_api.py x\n@ -H \"Content-Type: application/json\" \\ ae\n-d eee reign sses class\", \"urgency\":\"panic\"}'\nInternal Server Errorg\nrs) > OUTLINE cote Ste (Tl Te-weeleecmcurl \u2014-X POST http://127.0.0.1:8000/generate \\| | geoctcl= Bhuvan\nI\n> TIMELINE issed class\", \"urgenc \u00ae Hs Q \u00ae\n. main* @ @o0A4 Ln 62,Col23 Spaces:4 UTF-8 LF {} Python 3.13.2 64-bit O .\nView stat Ol B a = g Z I u i ae =\ni. Sa \u2018cna =a"
}