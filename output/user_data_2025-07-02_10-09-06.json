{
  "timestamp": "2025-07-02_10-09-06",
  "active_window": "ChatGPT",
  "focused_text": "let mem tell u that the order u",
  "clipboard": "curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"missed class\", \"urgency\":\"panic\"}'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "\u00e9\n\nChatGPT File Edit View Window\u2019 Help\n\nS@ROTO8\n\n2%8) FQ ee\n\n@ Wed Jul 2 10:09AM\n\no\nS\n\n\u00a9\n\n= List of research pape X * Artificial Intelligence X CO NLP_1.ipynb - Colab X CO NLP_1.ipynb - Colab X\n\nBB LauNcHED Global X\n\nM@ Launched - Artificial * Artificial_Intelligence_Ce X B Al-05-BBLEN4 x \u00a9 Opendl x So API keys - OpenAl A! X\n\nS&S > G \u00ae O 8 = platform.openai.com/settings/organization/api-keys eee OG Intelligent Excuse Generator Plan >\nBhuvan\nO \u20ac5> P excuse-generator \u00aeB- eo (The critical bit is that load_dotenv() must execute before client = OpenAl(...).)\n| o EXPLORER J Welcome \u00ae excuse_api.py 4,U X %.env U PY\nVv EXCUSE-GENERATOR @ excuse_api.py > ... 2 Save & restart cleanly\nSET \u00a9 > \u2014pycache_ 1 # excuse_api.py =\nes 2 import os, json, time, hashlib bash O) Copy\nes > include 3 from pathlib import Path\nORS te 4 from dotenv import load_dotenv\n& % pyvenv.cfg U CRRRRAGD Ctrl-C\noO ew t 5 load_dotenv() # < NEW: pulls OPENAT_API_KEY from .env\nA ES @ excuse _apipy 4,U 6 from fastapi import FastAPI\na store Een U 7 from pydantic impo rt BaseModel unset OPENAI_API_KEY\nA = requirements.txt U ILL\n8 from openai import OpenAI\n9 # \u2014---------- OpenAI client ---------- uvicorn excuse_api:app \u2014-reload\n10 client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\") )\n11 3 Test once more\nW200 GP s==Sseeees simple \u201cDB\u201d ---------\u2014 bash ac\n13 DATA = Path(\"history. json\") a ery\n14 if not DATA.exists(): curl -X POST http://127.0.0.1:800@/generate \\\n15 DATA.write_text(\"[]\") # seed empty list -H \"Content-Type: application/json\" \\\n16 -d '{\"scenario\":\"missed class\", \"urgency\":\"panic\"}'\n17\n18 You should finally get a JSON payload like:\nPF\nI @e =====eeoS= FastAPI app ---------- json \u00a9 Copy\n28 app = FastAPI()\n71 {\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS + v ~ xX \"iq\" : \"9ce7... \" 1\n\u00a9 bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\ * BJ python3.11 \"ts\": 1751556451.1,\n-H \"Content-Type: application/json\" \\ | Bzsh \"excuse\": \"Professor, my metro line was shut due to a gas leak drill...\"\n\n-d '{\"scenario\":\"missed class\", \"\u201curgency\":\"panic\"}'\nInternal Server Errorg\n@ bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\\n-H \"Content-Type: application/json\" \\\n-d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}'\n()) Internal Server Errorg\n@ bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % curl -X POST http://127.0.0.1:8000/generate \\\n> OUTLINE\n$03 Internal Server Errorg\n\n-H \"Content-Type: application/json\" \\\n-d '{\"scenario\":\"missed class\", \"\u201curgency\":\"panic\"}'\n> TIMELINE bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % []\nUE & maine @ @o0A4 Q\n\nLn10,Col53 Spaces:4 UTF-8 LF\n\n{} Python\n\n. \"believability_score\": 0.81,\n\"chat_log\": \"Mum: Any update? ...\"\n\nv\n\n\u20ac Work with Code Tab x\n& 3.13.264-bit 1)\nlet mem tell u that the order u|\n\n+ @\u00ae ov\n\n920068629 80920 Af\n\n(es)\n\nco}\n>)"
}