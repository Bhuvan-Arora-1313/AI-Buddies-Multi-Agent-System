{
  "timestamp": "2025-07-02_10-08-15",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ Code File Edit Selection View Go Run Terminal Window Help 6 \u20ac&8 \u00a9GD O S we FF Q SB \u00a9 WedJul2 10:08AM\n= List of research pape X * Artificial Intelligence X CO NLP_1.ipynb - Colab X CO NLP_1.ipynb - Colab X ca LAUNCHED Global X M Launched - Artificial X Artificial_Intelligence_Ce X (Bi al-05-BBLEN4 x \u00a9 Opendl x So API keys - OpenAl A! X\nO <7 Ce O @G = platform.openai.com/settings/organization/api-keys Intelligent Excuse Generator Plan > y=\nBhuvan\nee@ \u20ac > \u00a3 excuse-generator v 08 . . .\nS \u00a2 \u2018 & sOG os.getenv(\"OPENATI_API_KEY\") is still None and the SDK falls back to the dummy string pias\ngy | EXPLORER oe J Welcome \u00ae excuse_api.py 4,U X % .env U Dy % your_api_key.\nVv EXCUSE-GENERATOR @ excuse_api.py > ...\n\u00a9 {> \u2014Pycache_ 1 # excuse_api.py | _. .\nVv venv . . . . 1 Re-order three lines in excuse_api.py\n> ot 2 import os, json, time, hashlib |\nes > include 3 from pathlib import Path 4\n> lib 4 from dotenv import load_dotenv Move the dotenv load block above where you build the client (or simply rebuild the client after\npyvenv.cfg U eee g .\n\u00a9 aan u 5 load_dotenv() # \u2014 NEW: pulls OPENAI_API_KEY from .env loading):\nES @ excuse_apipy 4,U 6 from fastapi import FastAPI * ac\ni j eer aaeerarnn on fe)\nW) (ISSA 0 7 from pydantic import BaseModel pyt au\nA = requirements.txt U ILL\n8 from openat import Sar import os, json, time, hashlib\nQ9 # ---------- OpenAI client ---------- from pathlib import Path\n10 client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))]|\n11 from dotenv import load_dotenv, find_dotenv\n12 # ---------- simple \u201cDB\u201d ---------- load_dotenv(find_dotenv(), override=True)\n13 DATA = Path(\"history. json\")\n14 if not DATA.exists(): from fastapi import FastAPI\n15 DATA.write_text(\"[]\") # seed empty list from pydantic import BaseModel\n16 from openai import OpenAI\n17 client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\") )\n18\n19 # -\u2014-------- FastAPI app \u2014--------- (The critical bit is that load_dotenv() must execute before client = OpenAl(...).)\n28 app = FastAPI()\n21 2 Save & restart cleanly\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS. + vous AX\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/dotenv/main.py\", line 311, in find_do\u00ae | 2-] zsh bash oO Copy\nt\noe a frame.f_back is not None Bean\nAssertionError bE\n@ (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % python - <<'PY' Ctrl-C\nimport os, dotenv, pathlib, sys\n(@)) assert pathlib.Path(\".env\").exists(), \".env file NOT found in cwd\" |\ndotenv. load_dotenv(dotenv_path=\".env\", override=True) .\nprint(\"Loaded key starts with:\", os.getenv(\"OPENAI_API_KEY\") [:10])\n> OUTLINE PY unset OPENAI_API_KEY Vv\n$03 Loaded key starts with: sk-proj-fb\n> TIMELINE (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % [] FS\nGE & mains @0A4 Q Ln10,Col53 Spaces:4 UTF-8 LF {} Python @ 3.13.264-bit QQ\nMessage Bhuvan\n+ @& \u00a2 @\nS\n\n920068820 8920 AF"
}