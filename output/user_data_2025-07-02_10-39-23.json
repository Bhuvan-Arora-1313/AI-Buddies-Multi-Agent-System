{
  "timestamp": "2025-07-02_10-39-23",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "python - <<'PY'\nimport os, dotenv, google.generativeai as genai, pathlib, sys\ndotenv.load_dotenv('.env', override=True)\n\nprint(\"SDK version  :\", genai.__version__)\nprint(\"API key prefix:\", os.getenv(\"GEMINI_KEY\")[:10] if os.getenv(\"GEMINI_KEY\") else \"MISSING\")\n\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\ntry:\n    print(\"\\nModels visible to this key:\")\n    for m in genai.list_models():\n        print(\"  \u2022\", m.name)\nexcept Exception as e:\n    print(\"\\n\u26a0\ufe0f  list_models() raised:\", e.__class__.__name__, e)\n    sys.exit(1)\nPY",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "\u00e9\n\no\nS\n\n\u00a9\n\nChatGPT File Edit View Window\u2019 Help\n\u00a9 List of research =) Artificial intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Cc BB Launcue Glot\n<> C84 O & & aistudio.google.com/apikey\ne=> PP excuse-generator\n| oO EXPLORER x Welcome @ excuse_api.py 4,U X % .env U\n\\ EXCUSE-GENERATOR \u00ae excuse_api.py > \u00a9 generate\nP| > \u2014pyeache_ 37. # ---------- /generate ----------\nVV venv \" \"\n\u00ae oo 38 @app.post(\"/generate\")\n> include PROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS.\n> lib\n\n2\nre\nA\n\n@\naD\n\nWE & maine @0A4\n\nmodels/gemini- -1.5-flash-002\n\n5-flash-8b\n\n5-flash-8b-001\n5-flash-8b-Latest\n5-pro-preview-@3-25\n5-flash-preview-04-17\n\n5-f lash-preview-05-20\n\n5-flash\n\n5-f lash-preview-04-17-thinking\n5-flash-lite-preview-@6-17\n5-pro-preview-@5-06\n5-pro-preview-@6-05\n\n5-pro\n\n@-flash-exp\n\n@-flash\n\nQ-flash-001\n\n@-f lash-exp-image-generation\nQ-flash-lite-001\n\nQ-flash-lite\n\nQ@-f lash-preview-image-generation\n@-flash-lite-preview-@2-05\nQ@-flash-lite-preview\n@-pro-exp\n\n@-pro-exp-02-05\n\nexp-1206\n\n@-f Lash-thinking-exp-1-21\n\n@-f Lash-thinking-exp\n\nQ@-f Lash-thinking-exp-1219\n5-flash-preview-tts\nmodels/gemini-2.5-pro-preview-tts\nmodels/learnlm-2.0-f lash-experimental\nmodels/gemma-3-1b-it\n\nmodels/gemma-3-4b-it\n\nmodels/gemma-3-12b-it\n\nmodels/gemma-3-27b-it\n\nmodels/gemma-3n-e4b-it\n\nmodels/gemma-3n-e2b-it\n\nmodels/embedding-001\n\nmodels/text-embedding-004\nmodels/gemini-embedding-exp-03-07\nmodels/gemini-embedding-exp\n\nmodels/aga\n\nmodels/imagen-3.@-generate-002\nmodels/imagen-4.@-generate-preview-06-06\nmodels/imagen-4. @-ultra-generate-preview-06-06\nmodels/veo-2.0-generate-001\n\nini-2.5-f lash-preview-nat ive-audio-dialog\n5-f Llash-exp-nat ive-audio-thinking-dialog\nQ-flash-live-001\nmodels/gemini-live-2.5-flash-preview\n\n-venv) bhuvanarora@Bhuvans\u2014MacBook-Pro excuse-generator % o\n\n\u00a9 pyvenv.cfg\n\u00a9 .env\n\nU\nU\n@ excuse_api.py 4,U\n{} history.json U\n\nU\n\n= requirements.txt\n\n> OUTLINE\n> TIMELINE (\n\nfile.pdf ITRV (1).pdf ITRV.pdf AIEUTIR EAI EY\n\nM Launched - Artif\n\nLn 42, Col 63 Spaces 4 UTF-8\n\nIko to mtj\n\nArtificial_Intelligence\n\nBOUd\n\nDy B\n\n{} Python\n\n&8 3.13.264-bit C4\n\nG@ROTO8\n\n(B) al-05-BBLEN4 \u00a9 Openal @ apikeys - Open\n\n20% \u00a9)\n\ne Gemini API refer\n\nZF Q\n\n96 Get API key | GX\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\neco MO @G\n\nso the call is still going to the old v1beta endpoint and the backend can't\nfind the model. Let's run one short diagnostic to see exactly what the SDK\n\nand your key can see, then fix accordingly.\n\n1 Run this 15-second diagnostic\n\nIn the same VS-Code terminal with the venv activated:\nbash\n\npython \u2014- <<'Py'\n\nimport os, dotenv, google.generativeai as genai, pathlib,\n\ndotenv.load_dotenv('.env', override=True)\n\nprint(\"SDK version :\", genai.__version__)\n\n\u00a9) Copy\n\nsys\n\nprint(\"API key prefix:\", os.getenv(\"GEMINI_KEY\")[:10] if os.getenv(\"GEMIN\n\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\ntry:\nprint(\"\\nModels visible to this key:\")\nfor m in genai.list_models():\nprint(\" e\", m.name)\nexcept Exception as e:\nprint(\"\\n4&\u00a5 list_models() raised:\", e.__\nsys.exit(1)\nPY v\n\n\u00a9 excuse_api.py x\n\n= =\u2019 Message Bhuvan\ncn\nwv\n\nIko to MTJ (1).pdf\n\nIko to MTJ-s~\n\nS80\u00b0G8880 eee 70 ae\n\nclass__\n\n-__name__, e)\n\n\u00a9\n>)\n\n@ Wed Jul 2 10:39AM"
}