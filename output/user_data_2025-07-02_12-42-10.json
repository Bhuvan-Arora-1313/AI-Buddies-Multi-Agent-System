{
  "timestamp": "2025-07-02_12-42-10",
  "active_window": "ChatGPT",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "git add excuse_api.py README.md",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# --- Gemini via LangChain (REST v1) ---\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\n# expose key for LangChain wrapper\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # must be in .env\n\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",          # free\u2011tier model\n    temperature=0.8,\n    convert_system_message_to_human=True\n)\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n    mode: str = \"normal\"   # \"normal\" | \"apology\"\n    language: str = \"en\"   # ISO code, e.g. \"en\", \"es\", \"fr\"\n\nclass EmergencyRequest(BaseModel):\n    number: str\n    message: str\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    style_clause = (\n        \"Respond in a guilt\u2011tripping, heartfelt apology tone.\"\n        if r.mode.lower() == \"apology\"\n        else \"Respond in a neutral, believable tone.\"\n    )\n    # language directive\n    lang_clause = (\n        \"\" if r.language.lower() in [\"en\", \"english\"] else\n        f\"Respond in {r.language} language.\"\n    )\n    full_prompt = (\n        f\"{SYSTEM_PROMPT}\\n\"\n        f\"Tone: {style_clause}\\n\"\n        f\"{lang_clause}\\n\"\n        f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    )\n    messages = [\n        SystemMessage(content=SYSTEM_PROMPT),\n        HumanMessage(content=full_prompt)\n    ]\n    response_text = llm(messages).content.strip()\n    # LangChain may wrap JSON in ``` blocks \u2013 strip them\n    if response_text.startswith(\"```\"):\n        response_text = response_text.strip(\"`\").lstrip(\"json\").strip()\n    out = json.loads(response_text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]\n\n# ---------- /emergency ----------\n@app.post(\"/emergency\")\ndef emergency(req: EmergencyRequest):\n    \"\"\"\n    Simulate sending an emergency SMS/call.\n    For the demo we just log the request and append an entry to history.json.\n    \"\"\"\n    entry = {\n        \"id\": f\"emergency-{int(time.time())}\",\n        \"ts\": time.time(),\n        \"excuse\": \"EMERGENCY TRIGGER\",\n        \"believability_score\": 1.0,\n        \"chat_log\": f\"Sent '{req.message}' to {req.number}\"\n    }\n    history = json.loads(DATA.read_text())\n    history.append(entry)\n    DATA.write_text(json.dumps(history, indent=2))\n    return {\"status\": \"sent\", \"to\": req.number, \"msg\": req.message}",
  "ocr_text": "@  ChatcpT\n\nFile Edit View\n\nWindow\n\nHelp\n\n7. Excuse History & Favorites \u2014 Users can save frequently used excuses for quick access.\n\noO\n\nEXPLORER\n\nV EXCUSE-GENERATOR\n> __pycache__\nVv .venv\n> bin\n> include\n> lib\npyvenv.cfg\n.env U\n@ excuse_api.py 5,M\n{} history.json M\n@ README.md\n= requirements.txt\n\n> OUTLINE\n> TIMELINE\n\n$ main*+ &\n\n@o0A5\n\n< excuse-generator\n\n@ excuse_api.py 5,M X  {} history.json M @ README.md env U\n\n\u00ae excuse_api.py > \u00a9 generate\n\ndef generate(r: Req):\n\n)\n\nmessages = [\nSystemMessage(content=SYSTEM_PROMPT) ,\nHumanMessage(content=full_prompt)\n\n]\n\nresponse_text = llm(messages).content.strip()\n\n# LangChain may wrap JSON in \u201c~*~ blocks \u2014 strip\n\nif response_text.startswith(\"***\"):\nresponse_text = response_text.strip(\"*\").1lstr\n\nPROBLEMS e OUTPUT DEBUG CONSOLE TERMINAL PORTS\nINFO: Application startup complete.\n/Users/bhuvanarora/excuse-generator/excuse_api.py:68: LangChainDeprecationWarning: The method \u201cBase\nn langchain-core @.1.7 and will be removed in 1.0. Use :meth:*~invoke* instead.\n\nresponse_text = 11lm(messages).content.strip()\n/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.11/site-packages/langchain_google_genai/chat_|\nsystem_message_to_human will be deprecated!\n\nwarnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n\n127.0.0.1:65476 - \"POST /generate HTTP/1.1\" 200 OK\n\nWARNING: StatReload detected changes in \u2018excuse_api.py'. Reloading...\nINFO: Shutting down\n\nINFO Waiting for application shutdown.\n\nINFO Application shutdown complete.\n\nINFO Finished server process [11886]\n\nINFO Started server process [12570]\n\nINFO Waiting for application startup\n\nINFO Application startup complete.\n\n/Users/bhuvanarora/excuse-generator/excuse_api.py:76: LangChainDeprecationWarning: The method \u201cBase\nn langchain-core @.1.7 and will be removed in 1.0. Use :meth:*~invoke* instead.\n\nresponse_text = 11lm(messages).content.strip()\n/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.\nsystem_message_to_human will be deprecated!\n\nwarnings.warn(\"Convert_system_message_to_human will\nINFO: 127.0.@.1:65522 - \"POST /generate HTTP/1.1\"\n/Users/bhuvanarora/excuse-generator/.venv/1lib/python3.\nsystem_message_to_human will be deprecated!\n\nwarnings.warn(\"Convert_system_message_to_human will\n\n11/site-packages/langchain_google_genai/chat_\nbe deprecated!\")\n\n200 OK\n11/site-packages/langchain_google_genai/chat_\n\nbe deprecated!\")\n\nINFO: 127.0.@.1:65532 - \"POST /generate HTTP/1.1\" 200 OK\nACINFO: Shutting down\n\nINFO: Waiting for application shutdown.\n\nINFO: Application shutdown complete.\n\nINFO: Finished server process [12570]\n\nINFO: Stopping reloader process [11332]\n\n@ (.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % git add excuse_api.py README.md\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % u\n\nNot Committed Yet (Staged) Q  Ln69, Col 27\nMeee be pe OOcUente pal Teper 234.3 MB\n08:54\nPrevious 30 Days \u00ae\nB= \u2014 1 = | EB \u2014,\n\n\u00a9\u00b0seSE20 \u00a98008 B\n\n100%) fF Q\n\nG6 FBO sS @ Wed Jul2 12:42PM\n\n\u00a9\n\nJayant Allen Bits\nIf you want to use this app\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\neocoe MO GG\n\nyew\u201d Uo W\n\nok now lets update this on git\n\nThought for a second\n\nLooked at Code\nLooked at Code\n\nHere's the exact sequence of commands to commit your latest code (with language support) and push it to GitHub.\n\nMake sure you run these inside your project folder and the virtual-env is optional (not required for Git operations).\n\nbash \u00a9 Copy\n\ngit add excuse_api.py README.md\n\ngit commit -m \"feat: add multi-language support (language field) and keep apology mode\"\n\ngit push\n\nAfter the push finishes, refresh\nhttps: //github.com/Bhuvan\u2014Arora-1313/excuse-generator\nand you'll see the new commit listed.\n\nThat's it\u2014your latest working version is now on GitHub.\n\nOvad gy\n\n\u00a9 excuse_api.py x\nMessage Bhuvan\n+ \u00ae v&\na\n\n_\u2014 | Pass | Ee"
}