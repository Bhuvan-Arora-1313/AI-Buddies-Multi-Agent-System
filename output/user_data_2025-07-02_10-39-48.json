{
  "timestamp": "2025-07-02_10-39-48",
  "active_window": "ChatGPT",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "python - <<'PY'\nimport os, dotenv, google.generativeai as genai, pathlib, sys\ndotenv.load_dotenv('.env', override=True)\n\nprint(\"SDK version  :\", genai.__version__)\nprint(\"API key prefix:\", os.getenv(\"GEMINI_KEY\")[:10] if os.getenv(\"GEMINI_KEY\") else \"MISSING\")\n\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\ntry:\n    print(\"\\nModels visible to this key:\")\n    for m in genai.list_models():\n        print(\"  \u2022\", m.name)\nexcept Exception as e:\n    print(\"\\n\u26a0\ufe0f  list_models() raised:\", e.__class__.__name__, e)\n    sys.exit(1)\nPY",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "ChatGPT File Edit View Window\u2019 Help q me) Ff Q BS Wed Jul 2 10:39AM\n+\n\n\u00a9 List of research =) Artificial intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Cc BB Launcue Glot \u2122 Launched - Artif Artificial_Intelligence (B\u00ae al-05-BBLena \u00a9 Openal @ apikeys - Open \u00a9 Gemini API refer 96 Get API key | GX\n\nC\u20ac > G @\u00e9 O 8 \u00ae aistudio.google.com/apikey eee OG Intelligent Excuse Generator Plan > Gl =\n\nBhuvan\n\noO\n6 <> P\u00a3 excuse-generator By oO wa wv uw\n\n| o EXPLORER + J Welcome \u00ae excuse_api.py 4,U X %.env U Dy\n\n\\ EXCUSE-GENERATOR \u00ae excuse_api.py > \u00a9 generate\n\n\u00a9\n\nP| > \u2014pyeache_ 37. # ---------- /generate ----------\n\nVV venv\n\n\u00bb \u201c 38 @app.post(\"/generate\") ss\n> include PROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS. tyes A x\n\nS > lib | =\nEe & pyvenv.cfg models/gemini-1.5-flash-002 1 | 2s\n\nmodels/gemini-1.5-flash-8b >.) zsh\nmodels/gemini-1.5-f lash-8b-001\nmodels/gemini-1.5-flash-8b-latest\nmodels/gemini-2.5-pro-preview-03-25\nmodels/gemini-2.5-flash-preview-04-17\nmodels/gemini-2.5-f lash-preview-@5-20\nmodels/gemini-2.5-flash\nmodels/gemini-2.5-f lash-preview-04-17-thinking\nmodels/gemini-2.5-f lash-lite-preview-06-17\nmodels/gemini-2.5-pro-preview-05-06\nmodels/gemini-2.5-pro-preview-6-05\nmodels/gemini-2.5-pro\nmodels/gemini-2.0-f lash-exp\nmodels/gemini-2.0-flash\nmodels/gemini-2.0-f lash-01\nmodels/gemini-2.0-f lash-exp\u2014image-generation\nmodels/gemini-2.0-flash-lite-001 I\nmodels/gemini-2.0-flash-lite\nmodels/gemini-2.0-f lash-preview-image-generation\nmodels/gemini-2.0-flash-lite-preview-02-05\nmodels/gemini-2.0-f lash-lite-preview\nmodels/gemini-2.0-pro-exp\nmodels/gemini-2.@-pro-exp-02-05\nmodels/gemini-exp-1206\nmodels/gemini-2.0-f lash-thinking-exp-01-21\nmodels/gemini-2.0-f lash-thinking-exp\nmodels/gemini-2.0-f lash-thinking-exp-1219\nmodels/gemini-2.5-flash-preview-tts\nmodels/gemini-2.5-pro-preview-tts\nmodels/learnlm-2.0-f lash-experimental :\nmodels/gemma-3-1b-it\nmodels/gemma-3-4b-it\nmodels/gemma-3-12b-it\nmodels/gemma-3-27b-it\nmodels/gemma-3n-e4b-it\nmodels/gemma-3n-e2b-it\nmodels/embedding-001 1\nmodels/text-embedding-004\nmodels/gemini-embedding-exp-03-07\nmodels/gemini-embedding-exp\nmodels/aga\nmodels/imagen-3.@-generate-002\nmodels/imagen-4.@-generate-preview-06-06\nmodels/imagen-4. @-ultra-generate-preview-06-06 |\n@ models/veo-2.0-generate-001\nmodels/gemini-2.5-f lash-preview-nat ive-audio-dialog\nmodels/gemini-2.5-f lash-exp-nat ive-audio-thinking-dialog\n> OUTLINE models/gemini-2.0-flash-live-001\n$03 models/gemini-live-2.5-flash-preview A\n> TIMELINE (.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % [] \u20ac excuse_api.py x\n\nwy % main* \u00ae@ @oA4 Ln 42,Col63 Spaces:4 UTF-8 LF {} Python & 3.13.264-bit (\n\n= bs bss w = e\u2019 Le _\noe)\nwv a)\n\nB file.pdf ITRV (1).pdf ITRV.pdf AIEUTIR EAI EY Iko to mtj Iko to MTJ (1).pdf = Iko to MTJ-s.\n\nU\n\u00a9 .env U\nES @ excuse_api.py 4,U\nU\nU\n\n{} history.json\nA = requirements.txt\n\n9880\u00b0E68E20 e270 ae\n\n. ."
}