{
  "timestamp": "2025-07-02_10-55-21",
  "active_window": "pycharm",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "(.venv) bhuvanarora@Bhuvans-MacBook-Pro excuse-generator % uvicorn excuse_api:app --reload \nINFO:     Will watch for changes in these directories: ['/Users/bhuvanarora/excuse-generator']\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [5095] using StatReload\nINFO:     Started server process [5097]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     127.0.0.1:65276 - \"POST /generate HTTP/1.1\" 500 Internal Server Error\nERROR:    Exception in ASGI application\nTraceback (most recent call last):\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n    result = await app(  # type: ignore[func-returns-value]\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n    return await self.app(scope, receive, send)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/fastapi/applications.py\", line 1054, in __call__\n    await super().__call__(scope, receive, send)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/applications.py\", line 112, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 187, in __call__\n    raise exc\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py\", line 165, in __call__\n    await self.app(scope, receive, _send)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py\", line 62, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 714, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 734, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 288, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 76, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/routing.py\", line 73, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 301, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/fastapi/routing.py\", line 214, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/starlette/concurrency.py\", line 37, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n    result = context.run(func, *args)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 43, in generate\n    out = json.loads(model.generate_content([full_prompt]).text)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/generativeai/generative_models.py\", line 331, in generate_content\n    response = self._client.generate_content(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\", line 835, in generate_content\n    response = rpc(\n               ^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n    return wrapped_func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\", line 294, in retry_wrapped_func\n    return retry_target(\n           ^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\", line 156, in retry_target\n    next_sleep = _retry_error_helper(\n                 ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\", line 214, in _retry_error_helper\n    raise final_exc from source_exc\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\", line 147, in retry_target\n    result = target()\n             ^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/timeout.py\", line 130, in func_with_timeout\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py\", line 78, in error_remapped_callable\n    raise exceptions.from_grpc_error(exc) from exc\ngoogle.api_core.exceptions.NotFound: 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content([full_prompt]).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "PyCharm File Edit View Navigate Code Refactor Run Tools\u2019 Git Window\u2019 Help 3 34%&%) F Q & Wed Jul 2 10:55AM\n+\n\n= = co co |] M re] S \u00a9 \u00a9 9 Get API key| GX\nO<\u00a2\u00ab vr coe O & \u00a9 aistudio.google.com/apikey Intelligent Excuse Generator Plan > - =\nBhuvan\nS use:model =\no Google Al Studio i 8 8 genai.GenerativeModel (\"gemini- Bo\nra . =\nee0e@ \u00ae Buddy v {9 main v Current File v : a Q 6 pro\")out =\n\u00a9 json. loads (model.generate_content(\nA | Project v \u00a9 X ! \u2014  @ activity_analyzer.py 6) screenshot_2025-07-01_17-28-01.png @ gatheruserdata.py \u00ae@outp v OA full_prompt) .text)\nVW IIVE_UULPUL SUIT\n-o- ue : a 11 3,840x2,160 PNG (32-bit color) 2.34 MB : A A Q\n- {} prediction_output.json eo a ( ) @ 2pen-source model via 1.pip install openrouter (or pip No qu\n89, &) screenshot_2025-07-01_17-28-01 sro Google setup) install requests).2. Sign up at confic\nc &) screenshot_2025-07-01_17-30-0( huggingface.co > Settings > Access tokens \u2014_ HF tol\n0 &) screenshot_2025-07-01_17-30-2\u00a2 > New token (free).3. Replace the LLM call\n00 3 -07- 7 _ . .\n& screenshot_2025-07-01_17-30-4\u00a2 uu tuk uae wa um onoueo mu ea ge uaisnm with a simple POST to the HF Inference\noe & screenshot_2025-07-01.17-31-11. so, =~ \u2014_\u2014 = ~ - endpoint for mistralai/Mistral-7B-\n{} user_data_2025-07-01.17-27-36, \\ a Instruct-v@.2 (free community tier).4.\n_ _ _ - i 8 4.\n{} user_data_2025-07-01_17-28-01,j 7 Gare Parse its JSON reply the same way.\n{} user_data_2025-07-01_17-30-00. OB > see <> onpr\n( user_data_2025-07-01.17-30-05, \"0! wo a B Gigi GS Go Ge EA OCD NAP\n4 6 16 a5 not defined \u2014\n{3 user_data_2025-07-01.17-30-24, ree oe citian ccna ecumenism mean the 0 mole wasn\u2019 inpotedinthesame fle were youre\n28 29 30 oat -06-27.,.0-13,pnd -06-27-36pnd -06-27,.-58pna-06-27..1-22.9n0 deleting the screenshot.\n{} user_data_2025-07-01_17-30-28. rn.) E en\n\u2014 \u00b0 Path A (enable v1\n{} user_data_2025-07-01_17-30-48. : a ee eee eee | \u2018Add this line at the top of your gatheruserdata.py file (or wherever ( )\n{} user_data_2025-07-01_17-30-52. > brane : rosiesemaoe-reanee . .\n; a Ei python 8 Cony | API as described above (takes < 2 min).\n{} user_data_2025-07-01_17-31-11,js = 2 Kloud Din Enron Loe none OES Som OER Sty 08 ong 08 ora ime\n{} user_data_2025-07-01.17-31-15,} -|d ~ 4D coeaemman money ey In -env.\n> Btext Oe eS eas Canes ees FR |. moors tues ety\n@ = ay a & 8 wom a @ = 5 or 9 te i Oeininerin im pi.py use the simple model ID and string, not the list:\n\u00ae activity _analyzer.py \u00a9 Handouts Seana \u201conto Oowe Seong ane Seong Oeaee ore 20 85g owes\n<S : oe : | \u00a9) Copy\nY- \u00a9@ gatheruserdata.py EAE ieee = CTD CRT\na 7 een BONA \u201cSSR ong GOES \u201cSOIR Slgng GOIN Sigg \u201cSOIR ag Nees stuian [ . _.\ni)  output_popup.py a a eae +o8 \u00b0@ ai.GenerativeModel(\"gemini-pro\")\n= requirements.txt : =\na 2) user_text_extracter.py @S80\u00b0eGGE820 OO80\u00b0 B=! loads (model. generate_content(full_prompt) .text) ,\n> tb External Libraries\n\u00a9 -0 rn and test with curl. You sh.\u201c J finally see a JSON excuse\n= Scratches and Consoles . . .\n\u00a9 Buddy > output > & screenshot_2025-07-01_17-28-01.png Indexing... 1! Python 3.13 (Buddy) Gg\nView stat ll go main* \u00ae@ @O0A4 Q_ 1n43,Col36 Spaces:4 UTF-8 LF {} Python @ 3.13.2 64- Lv \u00a5\n\n\u2014 a \u2014\n280%\u00b0eGee820 Of\n\n. . . . . .\n\n. .\n\n\u2014\u2014\u2014 |\nPC\na\u00ae"
}