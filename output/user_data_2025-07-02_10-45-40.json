{
  "timestamp": "2025-07-02_10-45-40",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "python - <<'PY'\nimport os, dotenv, google.generativeai as genai, json\ndotenv.load_dotenv('.env', override=True)\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nm = genai.GenerativeModel(\"models/gemini-pro\")\nprint(json.loads(m.generate_content('Respond with JSON: {\"hello\":\"world\"}').text))\nPY",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"gemini-pro\")\nprint(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "\u00e9\n\no\nS\n\n\u00a9\n\nCode File Edit Selection\n= List of research\n\u20ac > CG @\n\n| oO EXPLORER\n\n\\Y EXCUSE-GENERATOR\n\nP > __pycache__\nv .venv\n> bin\noe > include\n> lib\n\nL&\n\n\u00a9 pyvenv.cfg U\n\u00a9 .env U\nES @ excuse_api.py 4,U\n\nU\nU\n\n{} history.json\n= requirements.txt\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nGE & maine @0A4\n\nView Go\n\nRun Terminal Window\u2019 Help\n\n1B al-05-BBLEN4\n\nG\u00a9@ FR OCOO 8S 2wH F\n\n\u00a9 OpenAl coy API keys - Open/ [G) Gemini API refer:\n\nQs\n\n96 Get API key | G X\n\n& Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Cc ca LAUNCHED Glok M Launched - Artif Artificial_Intelligence\nO @& = aistudio.google.com/apikey\n\u20ac 5 \u00a3 excuse-generator By 08 OD\nJ Welcome \u00ae excuse_api.py 4,U X %.env U Dy %\n@ excuse_api.py > ...\n7 Ly\n8\n9 from fastapi import FastAPI |\n10 from pydantic import BaseModel yy\n11\n12 import google.generativeai as genai\n13 genai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\n14 model = genai.GenerativeModel(\"models/gemini-pro\")\n15 print(\">>> model being used:\", model._name)\n16 # ---------- simple \u201cDB\u201d -\u2014---------\n17 DATA = Path(\"history. json\")\n18 if not DATA.exists():\n19 DATA.write_text(\"[]\") # seed empty list\n20\n21\n22\n23) 4p SS FastAPI app \u2014---------\n24 app = FastAPI()\n25\nPROBLEMS @ OUTPUT DEBUGCONSOLE TERMINAL PORTS. tv A xX\nmodule = importlib. import_module(module_str) | 2-] python3.11\nFile DASA NTCMERCTEY HEALY EEOTS/ EL ALTE YUL IME ETOYS line 126, in apc I zsh\nreturn _bootstrap._gcd_import(name[level:], package, level) |\nBll erry econ kere), Tia TED, ip reel se I\nFile \u201c<frozen importlib._bootstrap>\", line 1176, in _find_and_load 1.\nFile \u201c<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked be\nFile \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\nFile \u201c<frozen importlib._bootstrap_external>\", line 940, in exec_module Le\nEiht yes Ene na ISR NIP amy (el ee (iy ea cs /\nprint(\">>> model being used:\", model._name) L\nAttributeError: 'GenerativeModel' stiles Gos Ge attribute '_name'\nQ_ Ln 15,Col44 Spaces:4 UTF-8 LF {} Python @& 3.13.264-bit (2\nfile.pdf ITRV (1).pdf ITRV.pdf JETIR2101184 Iko to mtj Iko to MTJ (1).pdf Iko to MTJ-s.-=-\n\nS80\u00b0EGE20 ODE\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\nfor\nmodels/gemini-pro, which that old endpoint can't serve.\n\nWith the new SDK (0.8.5) you should pass the plain model ID (\"gemini-pro\") when you build\n\nthe model object \u2014not the full \u201cmodels/...\u201d path.\n\nQuick 2-line fix\n\npython\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\nmodel = genai.GenerativeModel(\"gemini-pro\" )\n\n(Make sure there\u2019s only one import / configure / model block in the file.)\n\nThen restart everything cleanly\n\nbash\n\nCtr1-C\npkill -f \"uvicorn.*excuse_api\" 2>/dev/null\n\nsource .venv/bin/activate\nuvicorn excuse_api:app --reload\n\nYou should now see the temporary line we added:\n\nv\n\n\u00a9 excuse_api.py x\nMessage Bhuvan\n+ \u00ae &\n\n.\n\n\u00a9) Copy\n\n\u00a9) Copy\n\n\u00a9) Copy\n\n=]\n\n@ Wed Jul 2 10:45AM"
}