{
  "timestamp": "2025-07-02_09-19-21",
  "active_window": "firefox",
  "focused_text": "0",
  "clipboard": "A UAV Patrol System Using Panoramic Stitching and Object Detection\n",
  "vscode_text": "<!DOCTYPE html>\n<html>\n  <body style=\"margin: 0; background: rgba(0,0,0,0.7); color: white; font-family: sans-serif;\">\n    <div style=\"-webkit-app-region: drag; padding: 10px; background: rgba(0,0,0,0.8);\">\n      <pre id=\"output\" style=\"white-space: pre-wrap; word-wrap: break-word;\">Waiting for data...</pre>\n    </div>\n    <script>\n      const { ipcRenderer } = require('electron');\n      ipcRenderer.on('update-prediction', (event, data) => {\n        document.getElementById('output').textContent = data;\n      });\n    </script>\n  </body>\n</html>",
  "ocr_text": "@ Firefox File Edit View History Bookmarks Tools Window Help 6 \u20ac8 \u00a9G O S 428) F Q BS \u00a9 Wed Jul2 9:19AM\neee (ica) =} List of research papers - Google X @ Artificial Intelligence Doubt Clee X CO NLP_1.ipynb - Colab x CO NLP_1.ipynb - Colab x a 4) LAUNCHED Global x + v\nO<\u00ab - Cea O @ = colab.research.google.com/drive/1pvRqFF5KdhXRbgIThEDdUhZ_fDOAOjue?usp=sharing&authuser=2#scrollTo=krleBTfulwsB B\u00ae wv 4\u00bb \u00a9 * =\nAj Ch ill not b d _. \u00bb\n\u00a9 @NLP_1ipynb %& & Changes will not be save $63 2 Share + mart FF\nD File Edit View Insert Runtime Tools Help\n\u00a9 Q Commands + Code + Text > Runall v Copy to Drive v see v \u201ca\nLNLCK_Gata] vVOwnloading paCkKage woranet tO /frOOt/NLtK_data...\n\u2014 [nltk_data] Downloading package vader_lexicon to /root/nltk_data... Y?eoe#e8\n\u00b0\u2014 \u2014  I[nltk_data] Downloading package punkt_tab to /root/n\\ltk_data...\n2 [nltk_data] Unzipping tokenizers/punkt_tab.zip.\n{Q) True\n<> [ ] # Sample text\ntext = \"This is a sample text with some punctuation, numbers (123), and mixed case words. Let's see how we can preprocess it!\"\nCa\n# 1. Tokenization\noO tokens = nltk.word_tokenize(text)\nprint(\"Tokens:\", tokens)\n$4 Tokens: ['This', 'is', 'a', 'sample', 'text', \u2018'with', \u2018some', 'punctuation', ',', 'numbers', '(', '123', ')', ',', 'and', \u2018mixed', 'case', \u2018words', '.', 'Let', \"'s\", 'see', \u2018how', \u2018'we', \u2018can', 'preprocess',\n\u00a9 # 2. Lowercasing\nlower_tokens = [token.lower() for token in tokens]\nprint(\"Lowercase Tokens:\", lower_tokens)\n$4 Lowercase Tokens: ['this', 'is', 'a', 'sample', 'text', \u2018with', 'some', 'punctuation', ',', \u2018numbers', '(', '123', ')', ',', 'and', 'mixed', \u2018case', 'words', '.', 'let', \"'s\", 'see', 'how', \u2018we', \u2018can', \u2018pre\n[ ] # 3. Removing punctuation\ncleaned_tokens = [re.sub(r'[*\\w\\s]', '', token) for token in lower_tokens if token. isalnum() ]\nprint(\"Cleaned Tokens:\", cleaned_tokens)\n$4 Cleaned Tokens: ['this', 'is', 'a', \u2018sample', 'text', 'with', \u2018some', \u2018punctuation', \u2018numbers', '123', 'and', 'mixed', \u2018case', 'words', \u2018let', 'see', 'how', 'we', 'can', 'preprocess', 'it']\n[ ] # 4. Stop word removal\nstop_words = set(stopwords.words('english'))\nprint(\"Stop Words:\", stop_words)\nfiltered_tokens = [token for token in cleaned_tokens if token not in stop_words]\nprint(\"Filtered Tokens (no stop words):\", filtered_tokens)\n8 {} Variables Terminal & Python 3\n\n+\nS80\u00b0eEGE20 OOF B\u00ae"
}