{
  "timestamp": "2025-07-09_11-08-05",
  "active_window": "pycharm",
  "focused_text": "import json\nimport time\nimport os\nfrom typing import Dict, Any, List\nimport subprocess\nimport signal\n\n# Import Google Gemini\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Google Gemini API key setup\nimport os\n\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # Set this externally\n\n# Initialize Google Gemini LLM\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",\n    temperature=0.3,\n    convert_system_message_to_human=True\n)\n\n\ndef read_latest_user_data() -> Dict[str, Any]:\n    \"\"\"Read the latest user data from live_output.json\"\"\"\n    try:\n        with open(\"output/live_output.json\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return {}\n    except json.JSONDecodeError:\n        return {}\n\n\ndef read_user_data_file(filename: str) -> Dict[str, Any]:\n    \"\"\"Read a specific user data file\"\"\"\n    try:\n        with open(f\"output/{filename}\", \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        return {}\n    except json.JSONDecodeError:\n        return {}\n\n\ndef get_all_user_data_files() -> List[str]:\n    \"\"\"Get list of all user data files in output directory\"\"\"\n    try:\n        files = [f for f in os.listdir(\"output\") if f.startswith(\"user_data_\") and f.endswith(\".json\")]\n        return sorted(files)\n    except FileNotFoundError:\n        return []\n\n\ndef analyze_user_activity_from_json(user_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Analyze user data from JSON to determine what the user is doing\n    Returns JSON format with activity classification\n    \"\"\"\n    if not user_data:\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": \"No user data available\",\n            \"timestamp\": time.time()\n        }\n\n    # Extract relevant information from user data\n    active_window = user_data.get(\"active_window\", \"\")\n    focused_text = user_data.get(\"focused_text\", \"\")\n    clipboard_content = user_data.get(\"clipboard\", \"\")\n    # vscode_text = user_data.get(\"vscode_text\", \"\")\n    ocr_text = user_data.get(\"ocr_text\", \"\")\n    timestamp = user_data.get(\"timestamp\", \"\")\n\n    # Combine all text sources for analysis\n    #     combined_text = f\"\"\"\n    # Active Window: {active_window}\n    # Focused Text: {focused_text}\n    # Clipboard: {clipboard_content}\n    # VS Code Text: {vscode_text}\n    # Screen OCR: {ocr_text}\n    #     \"\"\".strip()\n    combined_text = f\"\"\"\nActive Window: {active_window}\nFocused Text: {focused_text}\nClipboard: {clipboard_content}\nScreen OCR: {ocr_text}\n    \"\"\".strip()\n\n    if not combined_text or combined_text.strip() == \"\":\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": \"No meaningful text data available\",\n            \"timestamp\": time.time()\n        }\n\n    system_prompt = \"\"\"You are an AI assistant that analyzes user activity data to determine what the user is currently doing. \n\n    You have access to multiple data sources:\n    - Active Window: The currently active application\n    - Focused Text: Text from the focused element\n    - Clipboard: Content in the clipboard\n    - VS Code Text: Text from VS Code editor (if available)\n    - Screen OCR: Text extracted from screen capture\n\n    Analyze this data and classify the user's activity into one of these categories:\n    - coding: Writing, editing, or reviewing code (Python, JavaScript, etc.)\n    - researching: Reading articles, papers, documentation, or searching for information\n    - browsing: General web browsing, social media, or casual internet use\n    - emailing: Composing, reading, or managing emails\n    - messaging: Using chat applications, messaging apps, or communication tools\n    - gaming: Playing video games or game-related activities\n    - watching: Watching videos, streams, or multimedia content\n    - writing: Writing documents, notes, or creative content\n    - designing: Working on design, graphics, or creative projects\n    - working: General work activities not covered by other categories\n    - unknown: Unable to determine the activity\n\n    Consider the following patterns:\n    - Coding: Look for code syntax, function definitions, imports, IDE elements\n    - Messaging: Look for chat interfaces, message bubbles, contact names\n    - Researching: Look for articles, documentation, search results\n    - Browsing: Look for web browser elements, URLs, navigation\n\n    Return your response in valid JSON format with these fields:\n    - activity: The classified activity (string)\n    - confidence: Confidence level 0.0-1.0 (float)\n    - description: Brief description of what you observed (string)\n    - details: Additional context or specific tools/applications detected (string)\n    - data_sources: Which data sources were most useful for classification (string)\n    - timestamp: Current timestamp (float)\n\n    Example response:\n    {\n        \"activity\": \"coding\",\n        \"confidence\": 0.85,\n        \"description\": \"User appears to be writing Python code in Cursor IDE\",\n        \"details\": \"Detected Python imports, function definitions, and Cursor IDE interface\",\n        \"data_sources\": \"VS Code text and active window\",\n        \"timestamp\": 1234567890.123\n    }\n\n    Only return valid JSON, no additional text.\"\"\"\n\n    human_prompt = f\"Here's the user activity data to analyze:\\n\\n{combined_text}\\n\\nPlease analyze this data and determine what the user is doing.\"\n\n    try:\n        messages = [\n            SystemMessage(content=system_prompt),\n            HumanMessage(content=human_prompt)\n        ]\n\n        response = llm(messages)\n        response_text = response.content.strip()\n\n        # Try to parse the JSON response\n        try:\n            # Handle markdown-wrapped JSON responses\n            if response_text.startswith(\"```json\") and response_text.endswith(\"```\"):\n                # Extract JSON from markdown code blocks\n                json_start = response_text.find(\"```json\") + 7\n                json_end = response_text.rfind(\"```\")\n                if json_start < json_end:\n                    response_text = response_text[json_start:json_end].strip()\n            elif response_text.startswith(\"```\") and response_text.endswith(\"```\"):\n                # Extract JSON from generic code blocks\n                json_start = response_text.find(\"```\") + 3\n                json_end = response_text.rfind(\"```\")\n                if json_start < json_end:\n                    response_text = response_text[json_start:json_end].strip()\n\n            result = json.loads(response_text)\n            # Ensure timestamp is current\n            result[\"timestamp\"] = time.time()\n            return result\n        except json.JSONDecodeError:\n            # Fallback if JSON parsing fails\n            return {\n                \"activity\": \"unknown\",\n                \"confidence\": 0.0,\n                \"description\": \"Failed to parse LLM response\",\n                \"details\": response_text,\n                \"data_sources\": \"LLM response parsing failed\",\n                \"timestamp\": time.time()\n            }\n\n    except Exception as e:\n        return {\n            \"activity\": \"unknown\",\n            \"confidence\": 0.0,\n            \"description\": f\"Error analyzing user data: {str(e)}\",\n            \"details\": \"\",\n            \"data_sources\": \"Error occurred during analysis\",\n            \"timestamp\": time.time()\n        }\n\n\ndef analyze_historical_data(num_files: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"Analyze the most recent user data files\"\"\"\n    files = get_all_user_data_files()\n    if not files:\n        return []\n\n    # Get the most recent files\n    recent_files = files[-num_files:] if len(files) > num_files else files\n    results = []\n\n    for filename in recent_files:\n        user_data = read_user_data_file(filename)\n        if user_data:\n            analysis = analyze_user_activity_from_json(user_data)\n            analysis[\"source_file\"] = filename\n            results.append(analysis)\n\n    return results\n\n\ndef main():\n    \"\"\"Main function to continuously monitor and analyze user activity\"\"\"\n    print(\"\ud83d\udd0d User Activity Monitor Started\")\n    print(\"Using Google Gemini LLM for activity analysis\")\n    print(\"Analyzing data from gatheruserdata.py JSON files\")\n    print(\"Press Ctrl+C to stop\\n\")\n\n    # Start gatheruserdata.py as a subprocess\n    gather_proc = subprocess.Popen([\n        \"python\", \"gatheruserdata.py\"\n    ])\n    print(\"\ud83d\ude80 Started gatheruserdata.py in the background (PID: {}), collecting user data...\".format(gather_proc.pid))\n\n    try:\n        last_timestamp = None\n        while True:\n            print(\"\ud83d\udcca Reading latest user data...\")\n            user_data = read_latest_user_data()\n\n            # Only analyze if new data is available\n            if user_data and user_data.get(\"timestamp\") != last_timestamp:\n                last_timestamp = user_data.get(\"timestamp\")\n                print(\"\ud83e\udd16 Analyzing user activity from JSON data...\")\n                result = analyze_user_activity_from_json(user_data)\n                # Pretty print the JSON result\n                print(\"\ud83d\udcca Activity Analysis:\")\n                print(json.dumps(result, indent=2))\n                try:\n                    with open(\"output/prediction_output.json\", \"w\", encoding=\"utf-8\") as f:\n                        json.dump(result, f, indent=2)\n                except Exception as e:\n                    print(f\"\u274c Failed to save prediction output: {e}\")\n                print(\"=\" * 60)\n            else:\n                print(\"\u23f3 Waiting for new user data...\")\n\n            # Wait before next check\n            time.sleep(5)\n\n    except KeyboardInterrupt:\n        print(\"\\n\ud83d\udc4b Activity monitor stopped by user\")\n    except Exception as e:\n        print(f\"\u274c Error: {e}\")\n    finally:\n        print(\"\ud83d\uded1 Terminating gatheruserdata.py subprocess...\")\n        gather_proc.terminate()\n        try:\n            gather_proc.wait(timeout=5)\n        except subprocess.TimeoutExpired:\n            gather_proc.kill()\n        print(\"\u2705 gatheruserdata.py stopped.\")\n\n\ndef analyze_single_file(filename: str):\n    \"\"\"Analyze a specific user data file\"\"\"\n    print(f\"\ud83d\udd0d Analyzing file: {filename}\")\n    user_data = read_user_data_file(filename)\n\n    if user_data:\n        result = analyze_user_activity_from_json(user_data)\n        print(\"\ud83d\udcca Activity Analysis:\")\n        print(json.dumps(result, indent=2))\n    else:\n        print(f\"\u274c Could not read file: {filename}\")\n\n\ndef analyze_recent_files(num_files: int = 5):\n    \"\"\"Analyze the most recent user data files\"\"\"\n    print(f\"\ud83d\udd0d Analyzing {num_files} most recent files...\")\n    results = analyze_historical_data(num_files)\n\n    for result in results:\n        print(f\"\\n\ud83d\udcc1 File: {result.get('source_file', 'Unknown')}\")\n        print(f\"\ud83c\udfaf Activity: {result.get('activity', 'Unknown')}\")\n        print(f\"\ud83d\udcc8 Confidence: {result.get('confidence', 0.0):.2f}\")\n        print(f\"\ud83d\udcdd Description: {result.get('description', 'No description')}\")\n        print(\"-\" * 40)\n\n\nif __name__ == \"__main__\":\n    import sys\n\n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"--file\" and len(sys.argv) > 2:\n            analyze_single_file(sys.argv[2])\n        elif sys.argv[1] == \"--recent\" and len(sys.argv) > 2:\n            analyze_recent_files(int(sys.argv[2]))\n        elif sys.argv[1] == \"--recent\":\n            analyze_recent_files()\n        else:\n            print(\"Usage:\")\n            print(\"  python activity_analyzer.py                    # Monitor live data\")\n            print(\"  python activity_analyzer.py --file <filename>  # Analyze specific file\")\n            print(\"  python activity_analyzer.py --recent [num]     # Analyze recent files\")\n    else:\n        main()",
  "clipboard": null,
  "vscode_text": "// Ensure firebase is available globally\nconst firebase = window.firebase;\nconst db = firebase.firestore();\nlet currentUser = null;\nconst SYSTEM_PROMPT = `\nYou are an elite alibi-creator.\nReturn a valid JSON with exactly these keys:\n- \"excuse\" (string, max 50 words)\n- \"believability_score\" (number between 0 and 1)\n- \"chat_log\" (array of 2\u20134 objects with keys: \"sender\" (string), \"message\" (string))\n\nEach chat log object must look like:\n{ \"sender\": \"You\", \"message\": \"your message here\" }\n\nDo not include explanations or markdown. Output raw JSON only.`;\n\nfunction getLocalHistory() {\n  return JSON.parse(localStorage.getItem(\"excuseHistory\") || \"[]\");\n}\n\nfunction saveToLocalHistory(entry) {\n  const history = getLocalHistory();\n  if (!history.find(e => e.id === entry.id)) {\n    history.push(entry);\n    localStorage.setItem(\"excuseHistory\", JSON.stringify(history));\n  }\n}\n\nwindow.signInWithGoogle = function () {\n  const provider = new firebase.auth.GoogleAuthProvider();\n  firebase.auth().signInWithPopup(provider)\n    .then((result) => {\n      const user = result.user;\n    currentUser = user;\n      document.getElementById(\"userInfo\").innerText = `Hello, ${user.displayName}!`;\n\n      const savedKey = localStorage.getItem(user.uid + \"-apiKey\");\n      if (savedKey) document.getElementById(\"apiKey\").value = savedKey;\n\n      document.getElementById(\"apiKey\").addEventListener(\"input\", (e) => {\n        localStorage.setItem(user.uid + \"-apiKey\", e.target.value);\n      });\n      renderTopExcuses();\n    })\n    .catch((error) => {\n      alert(\"Login failed: \" + error.message);\n    });\n};\n\nasync function generateExcuse() {\n  const apiKey = document.getElementById(\"apiKey\").value;\n  const scenario = document.getElementById(\"scenario\").value;\n  const urgency = document.getElementById(\"urgency\").value;\n  const mode = document.getElementById(\"mode\").value;\n  const language = document.getElementById(\"language\").value;\n  const voice = document.getElementById(\"voice\").checked;\n  const output = document.getElementById(\"output\");\n\n  output.innerHTML = \"\u23f3 Asking Gemini (via OpenRouter)...\";\n\n  const tone = mode === \"apology\"\n    ? \"Respond in a guilt\u2011tripping, heartfelt apology tone.\"\n    : \"Respond in a neutral, believable tone.\";\n\n  const langClause = (language === \"en\" || language === \"english\")\n    ? \"\"\n    : `Respond in ${language} language.`;\n\n  const userPrompt = `\n${SYSTEM_PROMPT}\nRespond only with raw JSON \u2014 no Markdown, no explanation.\n\nScenario: ${scenario}\nUrgency: ${urgency}\nTone: ${tone}\n${langClause}\n`.trim();\n\n  try {\n    const response = await fetch(\"https://openrouter.ai/api/v1/chat/completions\", {\n      method: \"POST\",\n      headers: {\n        \"Authorization\": `Bearer ${apiKey}`,\n        \"Content-Type\": \"application/json\",\n        \"HTTP-Referer\": \"http://localhost\",\n        \"X-Title\": \"Excuse Generator\"\n      },\n      body: JSON.stringify({\n        model: \"google/gemini-2.5-flash-lite-preview-06-17\",\n        messages: [\n          { role: \"system\", content: SYSTEM_PROMPT },\n          { role: \"user\", content: userPrompt }\n        ]\n      })\n    });\n\n    const data = await response.json();\n    const text = data.choices?.[0]?.message?.content || \"\";\n\n    const match = text.match(/{[\\s\\S]+}/);\n    if (!match) {\n      output.innerText = \"\u274c Gemini didn't return JSON:\\n\\n\" + text;\n      return;\n    }\n\n    const parsed = JSON.parse(match[0]);\n    const id = btoa(parsed.excuse).slice(0, 12);\n    const entry = { id, ts: Date.now(), ...parsed };\n    await saveToUserHistory(entry);\n \n   \n\n// Save to Firestore instead of localStorage\nasync function saveToUserHistory(entry) {\n  if (!currentUser) return;\n\n  try {\n    const docRef = db.collection(\"users\").doc(currentUser.uid).collection(\"topExcuses\").doc(entry.id);\n    await docRef.set({\n      excuse: entry.excuse,\n      score: entry.believability_score,\n      timestamp: firebase.firestore.FieldValue.serverTimestamp()\n    });\n    console.log(\"\ud83d\udd25 Excuse saved to Firestore:\", entry.excuse);\n  } catch (err) {\n    console.error(\"\u274c Failed to save to Firestore:\", err);\n  }\n}\n   \n\n\n    const chatLogHtml = Array.isArray(parsed.chat_log)\n      ? parsed.chat_log\n          .filter(entry => entry && entry.sender && entry.message)\n          .map(entry => {\n            const isUser = entry.sender.toLowerCase() === \"me\" || entry.sender.toLowerCase() === \"you\";\n            return `\n              <div class=\"chat-bubble ${isUser ? 'me' : 'other'}\">\n                <strong>${entry.sender}:</strong> ${entry.message}\n              </div>`;\n          }).join(\"\")\n      : \"<div class='chat-bubble other'>\u26a0\ufe0f Invalid chat log format</div>\";\n\n    output.innerHTML = `\n      <div class=\"excuse-text\"><strong>Excuse:</strong> ${parsed.excuse}</div>\n      <div class=\"score\"><strong>Believability:</strong> ${parsed.believability_score}</div>\n      <div class=\"chat-log\">${chatLogHtml}</div>\n    `;\n\n    if (voice) {\n      const utterance = new SpeechSynthesisUtterance(parsed.excuse);\n      utterance.lang = language || \"en\";\n      speechSynthesis.speak(utterance);\n    }\n\n  } catch (err) {\n    output.innerText = \"\u274c Error generating excuse:\\n\" + err.message;\n  }\n}\n\nfunction renderTopExcuses() {\n  const list = document.getElementById(\"topExcuses\");\n  list.innerHTML = \"\";\n\n  const user = firebase.auth().currentUser;\n  if (!user) {\n    list.innerHTML = \"<li class='list-group-item'>Login to see your top excuses.</li>\";\n    return;\n  }\n  firebase.firestore()\n    .collection(\"users\")\n    .doc(user.uid)\n    .collection(\"topExcuses\")\n    .orderBy(\"score\", \"desc\")\n    .limit(5)\n    .get()\n    .then(snapshot => {\n      if (snapshot.empty) {\n        list.innerHTML = \"<li class='list-group-item'>No excuses saved yet.</li>\";\n        return;\n      }\n\n      snapshot.forEach(doc => {\n        const data = doc.data();\n        const li = document.createElement(\"li\");\n        li.classList.add(\"list-group-item\");\n        li.textContent = `(${data.score}) ${data.excuse}`;\n        list.appendChild(li);\n      });\n    })\n    .catch(err => {\n      console.error(\"Error loading top excuses:\", err);\n      list.innerHTML = \"<li class='list-group-item text-danger'>Error loading excuses.</li>\";\n    });\n}\n\nfunction triggerEmergency() {\n  const number = document.getElementById(\"emergencyNumber\").value;\n  const message = document.getElementById(\"emergencyMessage\").value;\n  const status = document.getElementById(\"emergencyStatus\");\n\n  const entry = {\n    id: \"emergency-\" + Date.now(),\n    ts: Date.now(),\n    excuse: \"EMERGENCY TRIGGER\",\n    believability_score: 1.0,\n    chat_log: `Sent '${message}' to ${number}`\n  };\n\n  saveToLocalHistory(entry);\n  renderTopExcuses();\n  status.innerText = \"\u2705 Emergency logged locally!\";\n}\ndocument.addEventListener(\"DOMContentLoaded\", () => {\n  renderTopExcuses();\n});\nfunction copyExcuse() {\n  const text = document.querySelector(\".excuse-text\")?.innerText?.replace(\"Excuse:\", \"\").trim();\n  if (text) {\n    navigator.clipboard.writeText(text);\n    alert(\"Excuse copied to clipboard!\");\n  } else {\n    alert(\"No excuse to copy!\");\n  }\n}",
  "ocr_text": "@ = PyCharm File Edit View Navigate Code Refactor Run Tools Git Window\u2019 Help &\n\nEG\n2)\n0)\n0\nKe)\n3)\n@\nfe)\n80\n\u00ae\n=\nQa\n\u00a9\n3\n>\n<\n\n@e@e@ (BBudayy % mainv Current File v | Fed | : 42 QA se\n\n(0 _sProject ~ @ activity_analyzer.py & screenshot_2025-07-01_17-28-01.png @ gatheruserdata.py @ output_popup.py \u00ae@ cluelyClone.py Vi: A\n-O- v (Buddy import tkinter as| \u2014 You are sharing your entire screen. \u201cStop Sharing z wiay )\n> Cvenv import json\n3% > (.venv1 TIBEINE GE\nimport time\n> (output . . .\no import threading\noo > Otext\nsee = oy # Path to your prediction file\n\u00a9 activity_analyzer.py 8 PREDICTION_FILE = os.path.join(\"output\", \"prediction_output.json\")|\n@ gatheruserdata.py\n@ output_popup.py def load_prediction(): 1usage + Bhuvan Arora\n= requirements.txt try:\n@ user_text_extracter.py with open(PREDICTION_FILE, \"r\") as f:\n> th External Libraries data = json.load(f)\n=\u00b0 Scratches and Consoles formatted = (\nf\"@ Activity: {data.get('activity')}\\n\"\nRun \u00a9 activity_analyzer \u2014 output_popup\nG\no> \u00ae User Activity Monitor Started\nb Using Google Gemini LLM for activity analysis\nry v Analyzing data from gatheruserdata.py JSON files\n=2 Press Ctrl+C to stop\nS =v\na #@ Started gatheruserdata.py in the background (PID: 5053), collecting user data...\n\u00a9) , [Ml Reading latest user data...\noo\n@ Analyzing user activity from JSON data...\n/Users/bhuvanarora/Buddy/activity analyzer.py:160: LangChainDeprecationWarning: The method ~BaseChatModel.__call__\u00b0 was deprecated in langchain-core 0.1.7 and will be\nresponse = 1Lm(messages)\n\u00a9 /Users/bhuvanarora/Buddy/. venv1/lib/python3.13/site-packages/Langchain google genai/chat_models.py:483: UserWarning: Convert_system_message_to_human will be deprecate\n99 warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\nO Buddy > #@ output_popup.py 8:67. LF UTF-8 4spaces Python 3.13 (Buddy) Gf\n\nSe@eee20 \u00a98000 a7 =\n\na mr mh"
}