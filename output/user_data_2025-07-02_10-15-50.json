{
  "timestamp": "2025-07-02_10-15-50",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "pip install --upgrade google-generativeai",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "\u00e9\n\no\nS\n\n\u00a9\n\nCode File Edit Selection\n\nView Go Run Terminal Window\u2019 Help\n\n= List of research pape X Artificial Intelligence X CO NLP_1.ipynb - Colab X CO NLP_1.ipynb - Colab X ca LAUNCHED Global X M Launched - Artificiz\n\n\u20ac > CG @\nee@\n\n| oO EXPLORER\n\n\\Y EXCUSE-GENERATOR\n\nP > __pycache__\n\nv venv\n> bin\noe > include\n> lib\nrod \u00a9 pyvenv.cfg\n\u00a9 .env\nHS @ excuse_api.py\n{} history.json\nA = requirements.txt\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nWE & mains @0A4\n\n4\n\nU\nU\nU\nU\nU\n\nO 8 = platform.openai.com/settings/organization/api-keys\n\n<> \u00a3 excuse-generator By 08 Oo la\n\nx Welcome @ excuse_api.py 4,U X % .env U Dy %\n\n@ excuse_api.py > ...\n\n1 # excuse_api.py\n\n2 import os, json, time, hashlib =\n3 from pathlib import Path\n4 from dotenv import load_dotenv\n5 load_dotenv() # \u2014 NEW: pulls OPENAI_API_KEY from .env\n6 from fastapi import FastAPI\n7 from pydantic import BaseModel\n8 from openai import OpenAI\n9 # ---------- OpenAI client ----------\n10 client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\") )\n11\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS. +y sr NX\n\nRequirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic->goog\u201d 2-] zsh\nle-generativeai) (0.4.1) at BJzsh\nDownloading google_generativeai-@.8.5-py3-none-any.whl (155 kB)\nDownloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\nSs 1.3/1.3 MB 3.9 MB/s eta 0:00:00\nUsing cached google_api_core-2.25.1-py3-none-any.whl (162 kB)\nUsing cached google_auth-2.4@.3-py2.py3-none-any.whl (216 kB)\nUsing cached cachetools-5.5.2\u2014py3-none-any.whl (1@ kB)\nUsing cached googleapis_common_protos-1.70.@-py3-none-any.whl (294 kB)\nUsing cached grpcio-1.73.1-cp311-cp311-macosx_11_@_universal2.whl (10.6 MB)\nDownloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\nUsing cached proto_plus-1.26.1-py3-none-any.whl (5@ kB)\nDownloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\nUsing cached requests-2.32.4\u2014py3-none-any.whl (64 kB)\nUsing cached charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl (198 kB)\nUsing cached rsa-4.9.1-py3-none-any.whl (34 kB)\nUsing cached urllib3-2.5.@-py3-none-any.whl (129 kB)\nUsing cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\nUsing cached pyasn1_modules-@.4.2-py3-none-any.whl (181 kB)\nDownloading google_api_python_client-2.174.0-py3-none-any.whl (13.7 MB)\n\u2014_\u2014_\u2014_\u2014_\u2014<\u2014<\u2014<\u2014_\u2014_\u2014_\u2014_\u2014_\u2014_\u2014_\u2014_\u2014\u2014\u2014S = 13.7/13.7 MB 10.2 MB/s eta 0:00:00\nUsing cached google_auth_httplib2-@.2.0-py2.py3-none-any.whl (9.3 kB)\nUsing cached httplib2-0.22.@\u2014py3-none-any.whl (96 kB)\nUsing cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\nUsing cached uritemplate-4.2.@-py3-none-any.whl (11 kB)\nInstalling collected packages: urllib3, uritemplate, pyparsing, pyasni, protobuf, grpcio, charset_normalizer, cachet\nools, rsa, requests, pyasni-modules, proto-plus, httplib2, googleapis\u2014common-protos, grpcio-status, google-auth, goo\ngle-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai '\nSuccessfully installed cachetools-5.5.2 charset_normalizer-3.4.2 google-ai-generativelanguage-0.6.15 google-api-core\n-2.25.1 google-api-python-client-2.174.@ google-auth-2.4@.3 google-auth-httplib2-0.2.@ google-generativeai-0@.8.5 goo\ngleapis\u2014common-protos-1.70.@ grpcio-1.73.1 grpcio-status-1.71.2 httplib2-0.22.@ proto-plus-1.26.1 protobuf-5.29.5 py\nasn1-@.6.1 pyasni-modules-0.4.2 pyparsing-3.2.3 requests-2.32.4 rsa-4.9.1 uritemplate-4.2.@ urllib3-2.5.@\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % | |\n\nQ _Ln10,Col53 Spaces:4 UTF-8 LF {} Python & 3.13.264-bit O\n\n6 \u20ac8 \u00a9GD O 8S wD F Q S \u00a9 Wed Jul2 10:15AM\n\nArtificial_Intelligence_Ce X  {B) Al-05-BBLEN4 xX \u00a9 OpenAl x @ aptkeys - OpenAl Ai X\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\n1 Stop the old server\n\nIn the VS Code terminal that's running uvicorn ..., hit Ctrl +C.\n\n2 Install the Gemini SDK\nbash O) Copy\n\nsource .venv/bin/activate\npip install --upgrade google-generativeai\n\n(leave openai installed for now; you can remove it later if you like)\n\n3 Add your Gemini key\n1. Get a free key at https://aistudio.google.com > API keys > Create.\n\n2. Open\u2014or create\u2014your local . env and add a new line:\n\u00a9) Copy\n\nGEMINI_KEY=AI\u2014XXXXXXXXXXXXXXXXXXXXXXXXK\n\n(keep OPENAI_API_KEY-... too; it won\u2019t be used but no harm in keeping it)\n\n4 Edit excuse_api.py\n\nMessage Bhuvan\n\n+O & OT)\n\nS800eEGE820 \u00a9O8F\u00b010 &*"
}