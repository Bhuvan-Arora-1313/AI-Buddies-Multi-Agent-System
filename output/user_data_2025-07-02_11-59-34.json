{
  "timestamp": "2025-07-02_11-59-34",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"deadline\",\"urgency\":\"medium\",\"mode\":\"humorous\"}'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# --- Gemini via LangChain (REST v1) ---\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.schema import SystemMessage, HumanMessage\n\n# expose key for LangChain wrapper\nos.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")  # must be in .env\n\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",          # free\u2011tier model\n    temperature=0.8,\n    convert_system_message_to_human=True\n)\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n    mode: str = \"normal\"   # \"normal\" | \"apology\"\n\nclass EmergencyRequest(BaseModel):\n    number: str\n    message: str\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    # Tone selection based on mode\n    tone_map = {\n        \"normal\": \"Respond in a neutral, believable tone.\",\n        \"apology\": \"Respond in a guilt-tripping, heartfelt apology tone.\",\n        \"humorous\": \"Respond in a lighthearted, witty style.\",\n        \"professional\": \"Use formal business language and keep it concise.\",\n        \"sarcastic\": \"Answer with brief, dry sarcasm.\",\n        \"emergency\": \"Sound panicked and extremely urgent; maximum 20 words.\"\n    }\n    style_clause = tone_map.get(r.mode.lower(), tone_map[\"normal\"])\n    full_prompt = (\n        f\"{SYSTEM_PROMPT}\\nTone: {style_clause}\\n\"\n        f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    )\n    messages = [\n        SystemMessage(content=SYSTEM_PROMPT),\n        HumanMessage(content=full_prompt)\n    ]\n    response_text = llm(messages).content.strip()\n    # LangChain may wrap JSON in ``` blocks \u2013 strip them\n    if response_text.startswith(\"```\"):\n        response_text = response_text.strip(\"`\").lstrip(\"json\").strip()\n    out = json.loads(response_text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]\n\n# ---------- /emergency ----------\n@app.post(\"/emergency\")\ndef emergency(req: EmergencyRequest):\n    \"\"\"\n    Simulate sending an emergency SMS/call.\n    For the demo we just log the request and append an entry to history.json.\n    \"\"\"\n    entry = {\n        \"id\": f\"emergency-{int(time.time())}\",\n        \"ts\": time.time(),\n        \"excuse\": \"EMERGENCY TRIGGER\",\n        \"believability_score\": 1.0,\n        \"chat_log\": f\"Sent '{req.message}' to {req.number}\"\n    }\n    history = json.loads(DATA.read_text())\n    history.append(entry)\n    DATA.write_text(json.dumps(history, indent=2))\n    return {\"status\": \"sent\", \"to\": req.number, \"msg\": req.message}",
  "ocr_text": "Code File Edit Selection View Go  Run_ Terminal Window\u2019 Help 3 1%A FF QQ JS Wed Jul 2 11:59AM\n+\n\noO Le}\n\u00bb \u2122 B 6 coy (S) 9 Get API key| G X\nw 94 OA \u201c=\nIntelligent Excuse Generator Plan >\nBhuvan\nvy PLY CSSLVUIIaGL \u00ab YVse IULIdL VUSLIICSS Laliyuaye diiu Keep LL LUTILLSt. ,\neco e (PD excuse-generator Be cog \": \"Answer with brief, dry sarcasm.\", Review &@ Revert\n\u2014 SS \": \"Sound panicked and extremely urgent; maximum 2@ words.\"\noO EXPLORER 990 @ excuse_api.py5 X  {} history.json @ README.md env u Dy\n\\ EXCUSE-GENERATOR \u00ae excuse_api.py > @ emergency\n\u2014_ tone_map.get(r.mode.lower(), tone_map[\"normal\"])\n> \u2014pycache_ def generate(r: Req): \u2014\u2014\u2014 ae =\nVv wvenv ti enltryh 10 J MOL Ath TL 40 J TOF Th 1th MNLSLOTys. t Ue\u2014UUpeE r]\n> bin 7 = PROMPT}\\nTone: {style_clause}\\n\"\n\u00ae include history. append(ent ry) |e\n> Iib DATA.write_text(json.dumps(history, indent=2) )\npyvenv.cfg\n.env U\n@ excuse_api.py 5 return entry\n{} history.json\n@ README.md Cr /top?n=5 a\n= i its.txt\nrequirements.txt @app.get(\"/top\")\ndef top(n: int = 5):\nhistory = json. loads(DATA. read_text())\nhistory.sort(key=lambda x: x[\"believability_score\"], reverse=True)\nreturn history[:n]\n0 \u2014\u2014 /emergency -\u2014---------\u2014\n@app. post (\"/emergency\")\ndef emergency(req: EmergencyRequest): \u00a9 Copy\n101 Tanna\nSimulate sending an emergency SMS/call. 27.@.@.1:8000/generate \\\n\n: application/json\" \\\n\nFor the demo we just log the request and append an entry to history.jso \"deadline\", \"urgency\": \"medium\", \"mode\": \"humorous\"}'\n\ne\n\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS +v nN OX\n\npyth... (0 ty [and you're ready.\n\n>-| zsh\n\n.\n.\nfd\n\nout = json. loads(response_text)\n\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/1lib/python3.11/json/__init__.py\", line 346, in loads }\nreturn _default_decoder.decode(s) h\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/json/decoder.py\", line 337, in decode\nobj, end = self.raw_decode(s, idx=_w(s, @).end()) }\nFile \"/Users/bhuvanarora/.pyenv/versions/3.11.13/lib/python3.11/json/decoder.py\", line 355, in raw_decode\n> OUTLINE raise JSONDecodeError(\"Expecting value\", s, err.value) from None iu\nx json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\nTIMELINE\n\nLx maint O @0A5 9 Bhuvan Arora (29 minutes ago) Q  Ln101,Col8 Spaces:4 UTF-8 LF {} Python & 3.13.264-bit QO\n\nCm oe Sl As A we aaa r @\u00ae w 2 @\u00ae\nPrevious 30 Days 7, oS\nS@0\u00b0eGS\"2\u00b0 O80082 \u00a3*\n\n.\nB= \u2014 1 = | | _\u2014 | EB\n\niy"
}