{
  "timestamp": "2025-07-02_08-37-33",
  "active_window": "firefox",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "Smart Border Patrol Using Drones and Wireless Charging System Under Budget Limitation\n",
  "vscode_text": "<!DOCTYPE html>\n<html>\n  <body style=\"margin: 0; background: rgba(0,0,0,0.7); color: white; font-family: sans-serif;\">\n    <div style=\"-webkit-app-region: drag; padding: 10px; background: rgba(0,0,0,0.8);\">\n      <pre id=\"output\" style=\"white-space: pre-wrap; word-wrap: break-word;\">Waiting for data...</pre>\n    </div>\n    <script>\n      const { ipcRenderer } = require('electron');\n      ipcRenderer.on('update-prediction', (event, data) => {\n        document.getElementById('output').textContent = data;\n      });\n    </script>\n  </body>\n</html>",
  "ocr_text": "\u00e9\n\nFirefox File Edit View History\n\nBookmarks\n\nee (ica) =) List of research papers - Google X\n\nowe 6 OD\n\nC a\n\nnN w- 8 of 9\n\n\u00b0\n\u00b0\nlill\n\nIme\n\nv A UAV patrol system using\npanoramic stitching and\nobject detection\n\n1 Introduction\nv 2 Related work\n2.1 Image stitching\n\n2.2 Motion ghost\nelimination\n\n2.3 Object detection\nVv 3 UAV patrol system\n\n3.1 System\narchitecture\n\n3.2 Image stitching\n\n3.3 Motion ghost\nelimination\n\nVv 3.4 Object detection\n3.4.1 Scene\nparsing\n\n3.4.2 Quantifying\nthe object-scene\nrelationship\n\n3.4.3 Model\nstructure\n\nv 4 Experiments\n\nv 4.1 Dataset and\nexperiment settings\n\n4.1.1 Dataset\n\n4.1.2 Experiments\nsettings\n\n4.2 Image stitching\nevaluation\n\n4.3 Object detection\nevaluation\n\n4.4 Results\n5 Conclusion\n\nDeclaration of\nCompeting Interest\n\nReferences\n\n98\n\nTools Window Help 6 & \u00a9OO SS 4s er Q BB\nA UAV patrol system using pano X * A UAV patrol system using par X Smart border patrol using drone X +\nsciencedirectassets.com, Ww (2)\n\u2014 + 200% v ky 2\n\nHighlight colour\n\n@\u00a9@ee0ee0e\n\nThickness\n\nShow all\n\npipe AALS\n2 yeaa sepsis oN\n\nFig. 9. Stitch-and-detect result of test video 2.\n\nmany objects in the video dataset are completely occluded, is used to train the Faster R-CNN model. Faster R-CNN is further\nconfigured to use the VGG16 model. With the scene parsing output ready, the detector runs at roughly 7 FPS on a computer\nwith an Intel Core i7-8700k, 16GB RAM and an nVidia GeForce GTX1080Ti GPU.\n\nWe use mAP (mean average precision, IOU = 0.50) and AR (average recall, max = 100) as metrics for the detection\naccuracy, as shown in Table 2, to evaluate detection result of the original Faster R-CNN and the proposed version including\nscene parsing. Both models are trained on the VisDrone DET training set and tested on the VisDrone VID evaluation set. They\nare run under the same configuration of Faster R-CNN parameters with VGG as backbone. The results show that utilizing\nscene parsing evidently improves Faster R-CNN\u2019s performance.\n\n4.4, Results\n\n7D\n\n\u00a7G6EE20 O92 i\n\n6\nIII\n\n6&& \u00bb"
}