{
  "timestamp": "2025-07-02_10-37-13",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\nout = json.loads(model.generate_content(full_prompt).text)",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\n{prompt}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "\u00e9\n\no\nS\n\n\u00a9\n\nCode File Edit Selection\n= List of research\n\u20ac>C@\n\n| \\Y EXCUSE-GENERATOR\n\nP > __pycache__\nVv wenv\n\n> bin\n2\n\nEXPLORER\n\n> include\n\n> lib\n\n\u00a9 pyvenv.cfg\n\u00a9 .env\n\nES @ excuse_api.py 4,\n\n{} history.json\n\nU\nU\nU\nU\nA = requirements.txt U\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nGE & maine @0A4\n\nView Go\n\nRun Terminal Window\u2019 Help\n\n@ Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co ca LAUNCHED Glob M Launched - Artif Artificial_Intelligence\n\nO 8 =\n\naistudio.google.com/apikey\n\n<> PP excuse-generator By Cob WwW\nx Welcome @ excuse_api.py 4,U X % .env U Dy %\n\u00ae excuse_api.py > \u00a9 generate\nS/o Ye \u2014===eSsSe= /generate \u2014---\u2014---\u2014\u2014\n\n38 @app.post(\"/generate\")\n\n39 def generate(r: Req):\n\n40 prompt = f\"Scenario: {r.scenario}\\nUrgency:\n41 \u00a9  full_prompt =: f\"{SYSTEM_PROMPT}\\n{prompt}\"\n42 ~--- out = json. loads(model.generate_content(full_prompt) . text)\n43 entry = {\n\n{r.urgency}\"\n\n44 \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n\n45 \"ts\": time. time(),\n\n46 **\u00abOUt,\n\n47 }\nPROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS + v ~ xX\n5.0->google-generativeai) (5.5.2) a | Bzsh\nRequirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.11/site-packages (from google-auth>=2.15 . >] zsh\n\n-@->google-generativeai) (0.4.2)\n\nRequirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.11/site-packages (from google-auth>=2.15.@->goog\nle-generativeai) (4.9.1)\n\nRequirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3.0.005\n,>=2.18.0->google-api-core->google-generativeai) (3.4.2) i\nRequirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.18.0->g\n00gle-api-core->google-generativeai) (3.10)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.1,\n8.0->google-api-core->google-generativeai) (2.5.0)\n\nRequirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.1\n8.0->google-api-core->google-generativeai) (2025.6.15)\n\nRequirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-aut\"\nh>=2.15.0->google-generativeai) (0.6.1)\n\nRequirement already satisfied: httplib2<1.0.0,>=0.19.@ in ./.venv/lib/python3.11/site-packages (from google-api-pyth\non-client->google-generativeai) (@.22.0)\n\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./.venv/lib/python3.11/site-packages (from goog!\nle-api-python-client->google-generativeai) (0.2.0)\n\nRequirement already satisfied: uritemplate<5,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from google-api-python\u00a7\n-client->google-generativeai) (4.2.0)\n\nRequirement already satisfied: pyparsing!=3.0.0, !=3.0.1, !=3.0.2, !=3.0.3,<4,>=2.4.2 in ./.venv/lib/python3.11/site-pa\nckages (from httplib2<1.0.0,>=0.19.@->google-api-python-client->google-generativeai) (3.2.3)\n\nRequirement already satisfied: annotated\u2014-types>=0.6.0 in ./.venv/lib/python3.11/site\u2014-packages (from pydantic->google,\n-generativeai) (0.7.0)\n\nRequirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.11/site-packages (from pydantic->google-\ngenerativeai) (2.33.2)\n\nRequirement already satisfied: typing-inspection>=0.4.@ in ./.venv/lib/python3.11/site-packages (from pydantic->goog\nle-generativeai) (@.4.1)\n\nDownloading google_generativeai-@.8.5-py3-none-any.whl (155 kB)\n\nInstalling collected packages: google-generativeai all\nSuccessfully installed google-generativeai-0.8.5\n\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % o\n\nLn 42, Col 63 (105 selected) Spaces:4 UTF-8 LF\n\nQ\n\nITRV (1).pdf\n\n{} Python & 3.13.264-bit\nP| =\n\nIko to MTJ (1).pdf\n\nfile.pdf\n\nITRV.pdf\n\nIko to mtj\n\nJETIR2101184\n\n880068820 OD\n\nIko to MTJ-\\-\n\nG@ROTO8\n\ncoy API keys - Open/\u00e9\n\n2%0) FQ SB\n\n[| Al-05-BBLEN4 \u00a9 OpenAl [G) Gemini API refer: +\u201d Get API key | G X\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\n\u00a9) Copy\n\nGEMINI_KEY=AI\u2014XXXXXXXXXXXXXXXXXXXXXXXXK\n\n' (Keep OPENALAPL KEY if it\u2019s still there; it\u2019s simply ignored.)\n\n4 Edit excuse_api.py\n\n1. Exactly one import/config block\u2014place it near the top (after load_dotenv):\n\npython \u00a9) Copy\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\") )\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n\n2. Call the model (replace your old OpenAl stanza) :\n\npython \u00a9) Copy\n\nfull_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urge\nout = json.loads(model.generate_content(full_prompt).text)\n\n(No duplicate genai.configure lines elsewhere in the file.)\n\nSave the file (3S / Ctrl S).\n\n\u00a9 excuse_api.py x\nMessage Bhuvan\n+ \u00ae &\n\nF ==\n{ | f \u00a2\ne : \u00a9)\n\u2014- ~~\n. . .\n\n@ Wed Jul 2 10:37AM"
}