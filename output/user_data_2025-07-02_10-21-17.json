{
  "timestamp": "2025-07-02_10-21-17",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"missed class\", \"urgency\":\"panic\"}'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"gemini-pro\")\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\n{prompt}\"\n    out = json.loads(model.generate_content(full_prompt).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "Code File Edit\n\nSelection\n\nView\n\nGo Run_ Terminal Window\u2019 Help\n\nG6 OTOS8\n\n2x8) FQ Ss\n\n@ Wed Jul 2 10:21AM\n\nOw \u00ae 0\n\n=} List of research 5\n\n. i en OE)\n\n& Artificial Intellige CO NLP_1.ipynb - Co CO NLP_1.ipynb - Co [a LAUNCHED Glob \u2122 Launched - Artif\n\nO 8 =\n\naistudio.google.com/apikey\n\nArtificial_Intelligence\n\n(BB al-05-BBLena \u00a9 Openal @ api keys - Open: \u00a9 Gemini APirefere\u2019 | 9 Get API key| GX\n\nee@\n2\noO\nx\n\ni>\n8\n\nEXPLORER\n\n> __pycache__\nv venv\n\n> bin\n\n> include\n\n> lib\n\n\u00a9 pyvenv.cfg\n .env\n\n@ excuse_api.py\n{} history.json\nA = requirements.txt\n\n@\n$03 > OUTLINE\n\n> TIMELINE\n\nGE & maine @0A4\n\n\\Y EXCUSE-GENERATOR\n\n4,U\nU\nU\n\nJ Welcome\n\nG&S 2 excuse-generator\n\n@ excuse_api.py 4,U X\n\u00ae excuse_api.py > \u00a9 generate\n33\n34 # /generate\n35 @app.post(\"/generate\")\n36 def generate(r: Req):\n37 prompt = f\"Scenario: {r.scenario}\\nUrgency:\n38 full_prompt = f\"{SYSTEM_PROMPT}\\n{prompt}\"\n39 out = json. loads(model.generate_content(full_prompt) .text)\n\nan a c\n\nPROBLEMS @\n\n{r.urgency}\"\n\nOUTPUT DEBUG CONSOLE TERMINAL PORTS.\n\nenv U By\n\nLJ pyth...\n\nFile \"/Users/bhuvanarora/excuse-generator/excuse_api.py\", line 39, in generate\nout = json. loads (model. generate_content(full_prompt) .text)\n\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/generativeai/generative_models\n-py\", line 331, in generate_content\nresponse = self._client.generate_content(\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/ai/generat ive language_: vibeta/s .\nervices/generative_service/client.py\", line 835, in generate_content\nresponse = rpc(\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/gapic_v1/method. py\",\nline 131, in __call__\nreturn wrapped_func(xargs, **kwargs) L\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\"\n, line 294, in retry_wrapped_func\nreturn retry_target(\nFile \"/Users/bhuvanarora/excuse-generator/.venv/1ib/python3.11/site-packages/google/api_core/retry/retry_unary.py\" |\n, line 156, in retry_target 4\n\nnext_sleep = LI\n\n_retry_error_helper( t\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_base.py\",\nline 214, in _retry_error_helper\nraise final_exc from source_exc\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py\"\n, line 147, in retry_target '\nresult = target()\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/timeout.py\", line 130\n, in func_with_timeout\nreturn func(*args, +kkwargs)\nFile \"/Users/bhuvanarora/excuse-generator/.venv/lib/python3.11/site-packages/google/api_core/grpc_helpers.py\", lin\ne 78, in error_remapped_callable\nraise exceptions. from_grpc_error(exc) from exc\ngoogle.api_core.exceptions.NotFound: 404 models/gemini-pro is not found for API version vibeta, or is not supported\nfor generateContent. Call ListModels to see the list of available models and their supported methods.\n\nQ  n39,Col63 Spaces:4 UTF-8 LF {} Python\n\nfile.pdf\n\nITRV (1).pdf\n\nITRV.pdf AIEUTIR EAI EY Iko to mtj Iko to MTJ (1).pdf\n\nS80%\u00b0GeGS882S O82\u00b00\n\nzsh\n\n&8 3.13.264-bit\n\nIko to MTJ-5.-\n\nIntelligent Excuse Generator Plan >\nBhuvan\n\nTF TULL_pLUIpe = 1\u00b0 LOTOIeM_rnumr is \\iipLompes~\n+ out = json.loads(model.generate_content(full_prompt) .text)\n\n(Everything else\u2014history file, FastAPI routes\u2014stays the same.)\n\nSave the file.\n\n5 Restart & test\n\nbash O) Copy\n\nuvicorn excuse_api:app \u2014-reload\n\nOpen a second terminal tab:\n\nbash O) Copy\n\ncurl -X POST http://127.0.0.1:8000/generate \\\n-H \"Content-Type: application/json\" \\\n-d '{\"scenario\":\"missed class\", \"urgency\":\"panic\"}'\n\nYou should get a JSON payload like:\n\njson \u00a9) Copy\n\n\"id\": \"9ce7..\",\n\"ts\": 1751559512.6,\n\"excuse\":\n\"believability_score\": 0.83,\n\"chat_log\": \"Mum: Any update? ..\"\n\nv\n(If you see json. decoder. JSONDecodeErrux, add a quick print() of the raw Gemini\n\nMessage Bhuvan\n\nen\n\n\"Professor, my metro line was closed due to a gas-leak drill...\n\n+ \u00ae\n\nWw\n\nae\n\n."
}