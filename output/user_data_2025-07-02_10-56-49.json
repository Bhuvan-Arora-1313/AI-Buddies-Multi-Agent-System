{
  "timestamp": "2025-07-02_10-56-49",
  "active_window": "Electron",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "source .venv/bin/activate\npip install --upgrade langchain_google_genai langchain-core",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv, find_dotenv\nload_dotenv(find_dotenv(), override=True)\n\n\n\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\nimport google.generativeai as genai\ngenai.configure(api_key=os.getenv(\"GEMINI_KEY\"))\nmodel = genai.GenerativeModel(\"models/gemini-pro\")\n#print(\">>> model being used:\", model._name) \n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    out = json.loads(model.generate_content([full_prompt]).text)\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "@ Code File Edit\n\nSelection View Go Run Terminal Window\u2019 Help\n\n37%*B) FQ BS\n\n\u00a9 fF OO 8\n\n@ Wed Jul 2 10:56AM\n\no\nS\n\n\u00a9\n\n& List of research 2) Artificial intelligen CO NLPA.ipynb-Col CO NLPt.ipynb- Col [i LAUNCHED Glob \u2122 Launched - Artif\n\nArtificial_Intelligence\n\n[| Al-05-BBLEN4 \u00a9 OpenAl coy API keys - Open/ [G) Gemini API refers +\u201d Get API key | G X\n\n\u20ac7xC 8 O @ & aistue\u2014\u2014+\u2014\u2014 + Intelligent Excuse Generator Plan >\nBhuvan\nwasn Ur vupy\nGoo leAl Studio PyCh Qs i New |\ng gFe] PyCharm source .venv/bin/activate\neee@ <5 PP excuse-generator By BHW pip install --upgrade langchain_google_genai langchain-core\nx Welcome @ excuse_api.py 4,U X % .env U Dy %\n\n| oO EXPLORER\n\n\\ EXCUSE-GENERATOR \u00ae excuse_api.py > \u00a9 generate\n\n{> \u2014Pycache_ 40 def generate(r: Req):\nes 41 prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\nne > include 42 full_prompt = f\"{SYSTEM_PROMPT}\\nScenario: {r.scenario}\\nUrgency:\n| 2b 43 out = json. loads(model.generate_content([full_prompt] ).text)\n& \u00a9 pyvenv.cfg U\nony 44 entry = {\nSSM Ocemacion ou 45 \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n{} history.json U\nA _ . ontra 7 PROBLEMS @ OUTPUT DEBUG CONSOLE TERMINAL PORTS\n= requirements.tx' a\n\nRequirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith>=0.3.45->lan \u2014\ngchain-core) (0.28.1)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.3.45->langchain-core)\nUsing cached orjson-3.10.18-cp311-cp311-macosx_15_@_arm64.whl.metadata (41 kB)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.3.45->langchain-core)\nUsing cached requests_toolbelt-1.@.0-py2.py3-none-any.whl.metadata (14 kB)\nCollecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.3.45->langchain-core) ao\nUsing cached zstandard-@.23.@-cp311-cp311-macosx_11_@_arm64.whl.metadata (3.@ kB)\nRequirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.\n45->langchain-core) (4.9.0) :\nRequirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=.23.0->langsmi\u00ae\nth>=0.3.45->langchain-core) (1.0.9)\nRequirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.+*->httpx<1,>=0.23\n-Q->langsmith>=0.3.45->langchain-core) (0.16.0)\nRequirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->1\nangsmith>=0.3.45->langchain-core) (1.3.1)\nDownloading Langchain_google_genai-2.1.6-py3-none-any.whl (47 kB) 1\nDownloading langchain_core-0.3.67-py3-none-any.whl (44@ kB)\nUsing cached filetype-1.2.@-py2.py3-none-any.whl (19 kB)\nUsing cached google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\nUsing cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nUsing cached packaging-24.2-py3-none-any.whl (65 kB)\nUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\nUsing cached jsonpointer-3.0.@-py2.py3-none-any.whl (7.6 kB)\nUsing cached langsmith-@.4.4\u2014py3-none-any.whl (367 kB)\nUsing cached orjson-3.10.18-cp311-cp311-macosx_15_@_arm64.whl (133 kB)\nUsing cached requests_toolbelt-1.@.0-py2.py3-none-any.whl (54 kB)\nUsing cached zstandard-@.23.@-cp311-cp311-macosx_11_@_arm64.whl (633 kB)\nUsing cached PyYAML-6.@.2-cp311-cp311-macosx_11_@_arm64.whl (172 kB)\nInstalling collected packages: filetype, zstandard, tenacity, PyYAML, packaging, orjson, jsonpointer, requests-toolb,\nelt, jsonpatch, langsmith, langchain-core, google-ai-generativelanguage, langchain_google_genai\nAttempting uninstall: google-ai-generativelanguage\nFound existing installation: google-ai-generativelanguage @.6.15\nUninstalling google-ai-generativelanguage-@.6.15:\nSuccessfully uninstalled google-ai-generativelanguage-0.6.15\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This beha\nviour is the source of the following dependency conflicts. 1:\n(2) google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0\n-6.18 which is incompatible.\nSuccessfully installed PyYAML-6.0.2 filetype-1.2.@ google-ai-generativelanguage-0.6.18 jsonpatch-1.33 jsonpointer-3.\n> OUTLINE @.@ langchain-core-@.3.67 langchain_google_genai-2.1.6 langsmith-@.4.4 orjson-3.10.18 packaging-24.2 requests\u2014toolbe\n$03 1t-1.0.0@ tenacity-9.1.2 zstandard-@.23.0\n> TIMELINE\n| maint @ @Wo0A4\nView status\n\n(.venv) bhuvanarora@Bhuvans\u2014-MacBook-Pro excuse-generator % | |\n\na |\n\n98065680\n\nQ  1n43,Col36 Spaces:4 UTF-8 LF {} Python & 3.13.2 64-bit\n\n1 2. Replace the current google-generativeai code in excuse_api.py\nwith the same pattern you used in activity_analyzer.py.\n\n_ python \u00a9) Copy\n\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nus from langchain.schema import SystemMessage, HumanMessage\n\nllm = ChatGoogleGenerativeAI (\nmodel=\"gemini-2.5-flash\",\ntemperature=0.8,\nconvert_system_message_to_human=True\n\n3. Use that LLM inside /generate:\n\npython \u00a9) Copy\n\nmessages = [\nSystemMessage(content=SYSTEM_PROMPT) ,\nHumanMessage(content=full_prompt)\n\n]\nraw = 1lm(messages).content.strip()\nout = json.loads(raw)\n\n(No list-wrapper needed, no gRPC, no 404.)\n\n4. Delete all google.generativeai imports / cv \\ s0 there's only one Gemini client in the file.\n\n\u00a9 excuse_api.py x\nMessage Bhuvan\n\na + @ &\n\nco}\n\n| :\n\u00a9 e 2] | ~\n. . .\n\n\u00ae"
}