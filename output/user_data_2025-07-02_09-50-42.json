{
  "timestamp": "2025-07-02_09-50-42",
  "active_window": "firefox",
  "focused_text": "Could not extract AXValue from focused element",
  "clipboard": "curl -X POST http://127.0.0.1:8000/generate \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"scenario\":\"missed class\",\"urgency\":\"panic\"}'",
  "vscode_text": "# excuse_api.py\nimport os, json, time, hashlib\nfrom pathlib import Path\nfrom dotenv import load_dotenv\nload_dotenv()          # \u2190 NEW: pulls OPENAI_API_KEY from .env\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\n# ---------- simple \u201cDB\u201d ----------\nDATA = Path(\"history.json\")\nif not DATA.exists():\n    DATA.write_text(\"[]\")          # seed empty list\n\n# ---------- OpenAI client ----------\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n# ---------- FastAPI app ----------\napp = FastAPI()\n\nclass Req(BaseModel):\n    scenario: str  # e.g. \"missed class\"\n    urgency: str   # \"low\" | \"medium\" | \"panic\"\n\nSYSTEM_PROMPT = \"\"\"\nYou are an elite alibi-creator.\nReturn a JSON with:\n  excuse               (\u2264 50 words),\n  believability_score  (0-1),\n  chat_log             (short WhatsApp-style proof)\n\"\"\"\n\n# ---------- /generate ----------\n@app.post(\"/generate\")\ndef generate(r: Req):\n    prompt = f\"Scenario: {r.scenario}\\nUrgency: {r.urgency}\"\n    res = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\",   \"content\": prompt},\n        ],\n        temperature=0.8,\n    )\n    out = json.loads(res.choices[0].message.content)\n\n    entry = {\n        \"id\": hashlib.md5(out[\"excuse\"].encode()).hexdigest(),\n        \"ts\": time.time(),\n        **out,\n    }\n\n    history = json.loads(DATA.read_text())\n    if entry[\"id\"] not in {h[\"id\"] for h in history}:   # de-dupe\n        history.append(entry)\n        DATA.write_text(json.dumps(history, indent=2))\n\n    return entry\n\n# ---------- /top?n=5 ----------\n@app.get(\"/top\")\ndef top(n: int = 5):\n    history = json.loads(DATA.read_text())\n    history.sort(key=lambda x: x[\"believability_score\"], reverse=True)\n    return history[:n]",
  "ocr_text": "Firefox File Edit View History Bookmarks Tools Window _ Help 3 3%8) FQ S Wed Jul 2 9:50AM\n+\n\nee@ (ica) =} List of research pape X * Artificial Intelligence X CO NLP_1.ipynb - Colab X CO NLP_1.ipynb - Colab X a LAUNCHED Global X \u2122@ Launched - Artificial X Artificial_Intelligence_Ce X | Al-05-BBLEN4 x \u00a9 Opendl x Ss Overview - OpenAl 4 X + Vv\nO <-> C@ O @& = platform.openai.com/docs/overview on 4\u00bb @ \u00ae=\nS OpenAl Platform Docs API reference - Start building &\n2\n\u00a9 Q Search % OK\nOpenAl developer platform\n\nRemote MCP\n\nWeb search\n\nFile search\n\njavascript \u00a9 (a)\n\nImage generation import OpenAI from \u201copenai\";\n\n. Developer quickstart const client = new OpenAI();\nCode interpreter\n\nMake your first API request in\nminutes. Learn the basics of the\n\nOpenAl platform. : : : :\nAGENTS input: \"Write a one-sentence bedtime story about a unicorn.\",\n\n\u00a9 5min I) 9\n\nComputer use const response = await client. responses.create({\n\nmodel: \"\u201cgpt-4.1\",\n\nBuilding agents\n\nconsole. log( response. output_text) ;\nVoice agents\n\nAgents SDK Python @\n\nAgents SDK\nTypeScript\n\nBrowse models View all\nREALTIME API\n\nUsing the Realtime API\nRealtime conversations\nRealtime transcription\n\nVoice activity detection\n\nMODEL OPTIMIZATION\n\nOverview GPT-4.1 04-mini 03\nEvale Flagship GPT model for complex tasks Faster, more affordable reasoning model Our most powerful reasoning model\n</> Cookbook\n228 Forum a\nStart building\n\n\u00a9) Help\n\nplatform.openai.com/docs/guides/tools-web-search Read and aenerate text Use a model's vision capabilities\n\n9820%\u00b06862\u00b00 \u00a90920 ~AF"
}